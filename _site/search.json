[
  {
    "objectID": "articles.html",
    "href": "articles.html",
    "title": "@mjfrigaard",
    "section": "",
    "text": "Treating Covid-19 - When enthusiasm trumps evidence (2020). Martin Frigaard & Aleszu Bajak. OjoPublico.\nScreening for CKD To Improve Processes of Care among Nondiabetic Veterans with Hypertension (2020). Carmen A Peralta, Martin Frigaard, Leticia Rolon, Karen Seal, Delphine Tuot, Josh Senyak, Lowell Lo, Neil Powe, Rebecca Scherzer, Shirley Chao, Phillip Chiao, Kimberly Lui, Michael G Shlipak, and Anna D Rubinsky. Clinical Journal of the American Society of Nephrology.\nValidating laboratory defined chronic kidney disease in the electronic health record for patients in primary care (2019). Martin Frigaard, Anna Rubinsky, Lo Lowell, Anna Malkina, Leah Karliner, Michael Kohn, Carmen A Peralta. BMC Nephrology.\nThe Associations Between CKD Diagnosis and Guideline Driven Care (2018). Martin James Frigaard, Leah Karliner, Carmen Peralta. American Journal of Kidney Diseases.\nComparison of Historical Lab CKD and Clinician Chart Review (2018). Martin James Frigaard, Leah Karliner, Carmen Peralta. American Journal of Kidney Diseases.\nImplementation of a pragmatic randomized trial of screening for chronic kidney disease to improve care among non-diabetic hypertensive veterans (2017). Carmen A Peralta, Martin Frigaard, Anna D Rubinsky, Leticia Rolon, Lowell Lo, Santhi Voora, Karen Seal, Delphine Tuot, Shirley Chao, Kimberly Lui, Phillip Chiao, Neil Powe, Michael Shlipak. BMC Nephrology.\nBehavioral economics and social marketing campaign increases selection and consumption of school lunch garden bar Items among elementary school students (2014). Joshua Andre, Cindy Wolff, Keiko Goto, Stephanie Bianco, Martin Frigaard, Garth Hansen, Rachel Riley, Sheila St. Cin The Federation of American Societies for Experimental Biology.\n“We can make a difference”: The Nourish Curriculum facilitates middle‐school students’ sustainable and healthy food choices (2014). Keiko Goto, Emily Ramsey, Cindy Wolff, Alyson Wylie, Stephanie Bianco‐Simeral, Rachel Riley, Martin Frigaard, Joshua Andre. The Federation of American Societies for Experimental Biology.\nThe nutritional moral of the story: An examination of storybooks used to promote healthy food-choice behavior (2014). Ben Seipel, SE Carlson, Stephanie Bianco-Simeral, Martin Frigaard, Cindy Wolff, K Goto. Psychology and Education: An Interdisciplinary Journal.\nThe Harvest of the Month (HOTM) program successfully promotes vegetable selection and consumption among first graders from low‐income schools (2013). Qiong Chen, Amanda Gerson, Keiko Goto, Cindy Wolff, Stephanie Bianco‐Simeral, Garth Hansen, Martin Frigaard, Ben Armstrong. The Federation of American Societies for Experimental Biology.\nThe impact of a multicomponent school-based program on fruit and vegetable selection from school salad bars among K-6 grade students (2012). Keiko Goto, Cindy Wolff, Martin Frigaard, Stephanie Bianco-Simeral. Journal of Nutrition Education and Behavior.\nTeachers’ perceptions indicate success for harvest of the month nutrition education program (2012). Kristen Evans, Keiko Goto, Cindy Wolff, Martin Frigaard, Stephanie Bianco-Simeral. California Journal of Health Promotion.\nDiscrepancies Among Student School Lunch Preferences, Menu Options, and Consumption Patterns in a Low-Income Northern California High-School (2011). Kelly Fiori, Cindy Wolff, Keiko Goto, Martin Frigaard, Kenny Chan, Stephanie Bianco-Simeral. California Journal of Health Promotion.\nIdentifying Red Flags: Using Anthropometry Measures to Screen for Elevated Blood Pressure Risk in Children (2013). Martin Frigaard, Keiko Goto, Cindy Wolff, Stephanie Bianco-Simeral, Thomas Fahey. ICAN: Infant, Child, & Adolescent Nutrition.\nAssociations Between Obesity and Elevated Blood Pressure Among Children in Five Low-Income Northern California Elementary Schools (2012). Martin Frigaard, Stephanie Bianco-Simeral, Cindy Wolff, Thomas D. Fahey, George David Swanson, Kevin G. Patton. Masters Thesis, California State University, Chico.\nA longitudinal study of overweight, elevated blood pressure, and acanthosis nigricans among low-income middle school students (2012). Dana Kopping, Holly Nevarez, Keiko Goto, Irene Morgan, Martin Frigaard, Cindy Wolff. The Journal of School Nursing."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "@mjfrigaard",
    "section": "",
    "text": "Hi! I am Martin Frigaard. Welcome to my personal blog where I write about projects I’m currently working on (or topics I’m thinking about)."
  },
  {
    "objectID": "about.html#this-site",
    "href": "about.html#this-site",
    "title": "@mjfrigaard",
    "section": "",
    "text": "Hi! I am Martin Frigaard. Welcome to my personal blog where I write about projects I’m currently working on (or topics I’m thinking about)."
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "@mjfrigaard",
    "section": "Background",
    "text": "Background\nFor my MAS (University of California, San Francisco: 2015-2017), I investigated the prediction and diagnosis of chronic kidney disease (CKD) using electronic health records. This research examined using historical eGFRs (a lab test that measures how well kidneys filter waste) for diagnosis (it tends to overestimate the prevalence) and if a CKD diagnosis in charts indicates provider awareness (it usually does). Before that, I studied the association between hypertension and obesity in adolescents for my thesis as part of a Masters in Kinesiology degree at California State University, Chico (2009-2011).\nI currently work as a Posit System Administrator on the CDC’s Enterprise Data, Analytics, and Visualization, a program within the larger Data Modernization Initiative. I also develop Shiny applications, R packages, and create training materials and workshops on data management, visualizations, and reproducible research. I have 15+ years of experience with data analysis, statistics, and research. I’m also an RStudio Education Certified Instructor tidyverse specialization."
  },
  {
    "objectID": "code.html#r-packages",
    "href": "code.html#r-packages",
    "title": "@mjfrigaard",
    "section": "R Packages",
    "text": "R Packages\n\n\nQuickly access the Shiny applications in the Shiny App-Packages (book) with the shinypak package. [Repo]\nMastering Shiny shinytest2 app-package (msst2ap) demonstrates how to test a Shiny app-package using testthat and shinytest2. All examples come from the Modules chapter of Mastering Shiny. [Repo]\nMastering Shiny testServer() app-package (mstsap) is a collection of tests using testthat and shiny::testServer() The modules and application in mstsap come from the Shiny modules chapter of Mastering Shiny [Repo]\ndopingdata contains data from the United States Anti-Doping Agency for exploration, modeling, and visualizations. The datasets in this package are derived from the USADA website and the World Anti-Doping Agency (WADA) banned substances list [Repo]\nGood enough R practices (gerp). [Repo]"
  },
  {
    "objectID": "code.html#sites",
    "href": "code.html#sites",
    "title": "@mjfrigaard",
    "section": "Sites",
    "text": "Sites\n\n\nShiny Frameworks: Shiny app demos with three popular frameworks (golem, leprechaun, and rhino) [Repo]"
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html",
    "href": "posts/p3-test-shiny-module-tests/index.html",
    "title": "Testing Shiny modules",
    "section": "",
    "text": "This is the third post in a series on testing shiny applications. I’ll cover testing shiny module server functions using the testhat package and shiny’s testServer() function."
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#testing-shiny-modules",
    "href": "posts/p3-test-shiny-module-tests/index.html#testing-shiny-modules",
    "title": "Testing Shiny modules",
    "section": "Testing shiny modules",
    "text": "Testing shiny modules\n\n\n\nShiny functions pose a couple of unique challenges for testing. First, we can’t execute shiny server functions in the console. Second, as Shiny apps become more complex, it’s highly recommended to break up the code base into modules. Modules have additional challenges due to their reactivity being split between interconnected UI and server functions.\nThe shiny package doesn’t provide a direct, built-in way to test modules, but the testServer() function addresses these challenges by testing “reactive interactions” in module server functions. testServer() also works with testthat, which means we can structure these ‘reactive interaction’ tests just like other unit tests (for non-application functions)."
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#a-shiny-app-package",
    "href": "posts/p3-test-shiny-module-tests/index.html#a-shiny-app-package",
    "title": "Testing Shiny modules",
    "section": "A Shiny App-Package",
    "text": "A Shiny App-Package\ntestthat is designed to work within an R package, and the mstsap branch of sapkgs has a Mastering Shiny testServer app-package to demonstrate writing tests with testServer().\nThe functions, modules, and applications in mstsap come from the Shiny Modules chapter of Mastering Shiny.1 If you haven’t read this chapter–start there.\n\n# to get the mstsap package used in this post:\ndevtools::load_all()\nlibrary(mstsap)\n\n\n\n\n\n\n\nTipWhy create an app-package?\n\n\n\n\n\n\nA shiny app-package is a shiny application that’s been developed as (or converted to) an R package. The benefits of storing shiny apps in R packages have been well documented, but I’ll summarize just a few that are specific to testing:\n\nStandardized folder structure:\n\nIf unit tests are performed with testthat, minimal setup is required to perform tests.\nusethis::use_testthat() sets up test files in the tests/testthat/ folder (to test the code in the R/ folder)\n\nRead more about using testthat with R packages here.\n\nTest extras:\n\nTest data can be placed in tests/testthat/&lt;test dir&gt;/&lt;test_data.rds&gt;\n\nThe code used to create the test data should be placed in make_&lt;test_data.rds&gt;\n\nAdditional testing functions can be stored in tests/testthat/helpers.R\n\nRead more about test helpers here.\n\nDevelopment tools:\n\nIf you’re using RStudio, tests can be run individually (testthat::test_file()) or collectively (devtools::test()), and code helpers and data are loaded using devtools::load_all()\n\nTests created with testthat remain isolated during development\n\nRead more about developing packages with RStudio in the R Packages text."
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#modules",
    "href": "posts/p3-test-shiny-module-tests/index.html#modules",
    "title": "Testing Shiny modules",
    "section": "Modules",
    "text": "Modules\nIn a previous post, I used the following definition for unit tests,\n\n“A unit test is a piece of code that invokes a unit of work and checks one specific end result of that unit of work.” - The Art of Unit Testing, 2nd edition\n\nShiny modules can also be broken into discrete ‘units of work’ with expected ‘end results.’ Modules are ‘a pair of UI and server functions’ designed to compartmentalize input and output IDs into distinct namespaces.2\n\n\n\n\n\n\nNoteShiny module refresher\n\n\n\n\n\nModule UI functions typically wrap the layout, input, and output functions in tagList(). Module server functions contain the ‘backend’ code that typically goes in a shiny server function. Both the UI and server module functions are linked by an id argument, which is created using NS() (namespace) in the UI function, and called in the server function with moduleServer().\n\nModule UI functions\nBelow is an example module UI function:\n\nmod_fun_ui &lt;- function(id) {\n  tagList(\n    numericInput(inputId = NS(namespace = id, id = \"num_input\")),\n    uiOutput(outputId = NS(namespace = id, id = \"num_out\"))\n  )\n}\n\n\nmod_fun_ui creates a dedicated namespace for one inputId and one outputId with shiny::NS():\n\n█─mod_fun_ui \n├─id \n└─█─tagList \n  ├─█─numericInput \n  │ └─inputId = █─NS \n  │             ├─namespace = id \n  │             └─id = \"num_input\" \n  └─█─uiOutput \n    └─outputId = █─NS \n                 ├─namespace = id \n                 └─id = \"num_out\" \n\n\n\n\nModule server functions\nThe corresponding module server function is below:\n\nmod_fun_server &lt;- function(id) {\n        moduleServer(id, function(input, output, session) {\n            ns &lt;- session\n          output$num_out &lt;- uiOutput(outputId = input$num_input)\n      })\n}\n\n\nThe code to render the reactive input$num_input with output$num_out is contained in the nested call to moduleServer()\n\n█─mod_fun_server \n├─id \n└─█─moduleServer \n  ├─id = id \n  ├─server = █─`function(input, output, session)` \n  │          ├─`ns &lt;- session` \n  │          ├─`output$num_out &lt;-` \n  │          └─█─renderUI \n  │            └─`input$num_input` \n  └─session = session \n\n\n\n\nUsing modules\nBoth module functions are combined in the ui and server arguments of shinyApp():\n\nshinyApp(\n    ui = fluidPage(\n          mod_fun_ui(id = \"mod\")\n        ),\n   server = function(input, output, session) \n          mod_fun_server(\"mod\")\n  )\n\n\nThe id arguments connect the UI and server functions to communicate between the UI and backend of the app:\n\n█─shinyApp \n├─ui = █─fluidPage \n│      └─█─mod_fun_ui \n│        └─id = \"mod namespace\" \n└─server = █─`function(input, output, session)` \n           └─█─mod_fun_server \n             └─id = \"mod namespace\" \n\n\nI recommend creating test files when you create module files (i.e., with usethis::use_r() & usethis::use_test()).\n\n\n\n\nHowever, the ‘unit of work’ for a Shiny module might be accomplished with a combination of a module UI and server functions, and a helper/utility function.\nmstsap contains three modules: dataset, selectVar, and selectDataVar. If you’re like more information on these modules, click on the links below.\n\n1) Dataset input module\n\n\n\n\n\n\n\n\n\n\ndatasetInput/datasetServer: loads and returns data object from the datasets package (filtered by data frames or matrices)\n\n\n\nThe objects from datasets are filtered in the UI module function with a filter argument that can be used to “limit the options to built-in datasets that are either data frames (filter = is.data.frame) or matrices (filter = is.matrix)”. The names are passed to the choices in the selectInput():\n\n\nshow/hide choices in datasetInput()\nnames &lt;- ls(\"package:datasets\")\n  if (!is.null(filter)) {\n    data &lt;- lapply(names, get, \"package:datasets\")\n    names &lt;- names[vapply(data, filter, logical(1))]\n  }\n\n\nThe datasets object is returned with get() (wrapped in reactive()). See below:\n\n\nshow/hide returned data from datasetServer()\nshiny::reactive(\n      get(input$dataset, \"package:datasets\")\n    )\n\n\n\n\n2) selectVar module\n\n\n\n\n\n\n\n\n\n\nselectVarInput/selectVarServer: displays a selectInput() that “allows the user to select variables of specified type from a given reactive dataset.”\n\n\n\nThe data argument in selectVarServer() is the returned value from datasetServer(). The data() is used with the filter argument in the find_vars() function:\n\n\nshow/hide find_vars()\nfind_vars &lt;- function(data, filter) {\n # I've included the updated version with the 'stopifnot()' checks!\n  stopifnot(is.data.frame(data))\n  stopifnot(is.function(filter))\n  names(data)[vapply(data, filter, logical(1))]\n}\n\n\nThe filter argument can be used to return variables by class/type (using is.* functions like is.numeric() or is.character()).\nWhen data() changes, the output from find_vars() updates the choices in the variable selectInput() (i.e., input$var). See below:\n\n\n\n\n\nselectVarServer() also returns the selected variable (input$var) as a reactive value (var())\n\n\n3) selectDataVar module\n\n\n\n\n\n\n\n\n\n\nselectDataVarUI/selectDataVarServer: The selectDataVar module is from the section titled, “Modules inside of modules”, so here we see the dataset and selectVar modules placed inside the selectDataVar module (each with a new namespace (NS())).\n\n\n\n\n\n\n\n\n\nNoteNaming modules\n\n\n\n\n\n\nWhen creating an app-packages, modules are stored in the R/ folder as a single file, typically following a naming convention that differentiates modules from the other package functions. The modules in this post use camelCase, with suffix variations (i.e., Input/Server and UI/Server) for each functions. Other options come from the golem and leprechaun packages.\ngolem modules are created with golem::add_module()\n\n\n\nexpand to see golem::add_module(“inputs”)\nmod_inputs_ui &lt;- function(id){\n  ns &lt;- NS(id)\n  tagList(\n  )\n}\nmod_inputs_server &lt;- function(id){\n  moduleServer( id, function(input, output, session){\n    ns &lt;- session$ns\n \n  })\n}\n## To be copied in the UI\n# mod_inputs_ui(\"inputs_1\")\n    \n## To be copied in the server\n# mod_inputs_server(\"inputs_1\")\n\n\n\ngolem modules the following naming convention:\n\nAll new module functions have a mod_ prefix\ngolem module functions are differentiated with either a _ui or _server suffix\nNew golem module files are named R/mod_&lt;name&gt;.R\n\nleprechaun modules are also created with a leprechaun::add_module() function.\n\n\n\nexpand to see leprechaun::add_module(“inputs”)\ninputsUI &lt;- function(id){\n    ns &lt;- NS(id)\n    tagList(\n        h2(\"inputs\")\n    )\n}\ninputs_server &lt;- function(id){\n  moduleServer(id, function(input, output, session) {\n                ns &lt;- session$ns\n                send_message &lt;- make_send_message(session)\n                # your code here\n        }\n    )\n}\n# UI\n# inputsUI('id')\n\n# server\n# inputs_server('id')\n\n\n\nleprechaun modules have a slightly different naming convention:\n\nAll new UI module functions have a UI suffix\nAll new module server functions have a _server suffix\nleprechaun module functions do not have a prefix\nNew leprechaun modules named module_&lt;name&gt;.R\n\nShiny app-packages often require multiple modules and utility functions, so uniform names will make it easier to manage (and test!) your code."
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#standalone-app-functions",
    "href": "posts/p3-test-shiny-module-tests/index.html#standalone-app-functions",
    "title": "Testing Shiny modules",
    "section": "Standalone App Functions",
    "text": "Standalone App Functions\nmstsap contains three standalone functions for running each set of module functions.\nI’ve made a small change to each standalone app function–each app has a call to reactiveValuesToList() that displays in the UI.\n\n\nprint reactive values\n  shiny::verbatimTextOutput(\"vals\")\n\n  output$vals &lt;- shiny::renderPrint({\n    x &lt;- shiny::reactiveValuesToList(input,\n                            all.names = TRUE)\n    print(x)\n  })\n\n\n\ndatasetApp\n\n\n\n\n\n\n\n\n\n\ndatasetApp() contains a call to the dataset module, and includes a tableOutput() to render the selected data object:\n\n\n\nWhen datasetApp() is run, the app displays the dataset object in the tableOutput(), and the verbatimTextOutput() renders the reactive values as a text:\n\n\n\n\n\n\nFigure 1\n\n\n\nThe output above shows what NS() does in the dataset module–it appends the module id argument to the inputId (which is why we see dataset-dataset).\n\ndataset-: the module id\ndataset-dataset the inputId from the selectInput()\n\n\n\nselectVarApp\n\n\n\n\n\n\n\n\n\n\nselectVarApp() includes both dataset and selectVar modules, but instead of rendering the output in a table, the UI renders the variable output in a verbatimTextOutput().\n\n\n\nNote that selectVarApp() contains namespaces for two modules:\n\n\"data\": the namespace for the datasetnput() and datasetServer() modules, inheriting the filter argument and creating the data object\n\"var\": the selectVar modules are linked with the \"var\" id. selectVarServer() uses the data object created by datasetServer() (and also inherits the filter argument).\n\nThese namespaced IDs are rendered below with reactiveValuesToList():\n\n\n\n\n\nThere’s a lot happening in selectVarApp(), so I’ve created the figure below to display the code for the modules with their displayed outputs:\n\n\n\n\n\n\n\nAs we can see, the data output from the dataset module is used to generate the vars() reactive for the verbatimTextOutput() in selectVarApp(). Note that both dataset and selectVar modules don’t contain any output functions–these have been provided in the UI for both datasetApp() and selectVarApp().\n\n\nselectDataVarApp\n\n\n\n\n\n\n\n\n\n\nThe final app in mstsap is selectDataVarApp(). Here the inputs from dataset and selectVar have been moved into the sidebarPanel(), and the output is rendered in the mainPanel().\n\n\n\nThe reactive values here show how the ‘Modules inside of modules’ work–by adding the additional call to NS() in the datasetInput() and selectVarInput() functions within selectDataVarUI() and selectDataVarServer(), an additional namespace is appended to the reactive values (input$dataset and input$var):\n\n\n\n\n\n\n\n\n\n(a) selectDataVarApp with reactive values\n\n\n\n\n\nFigure 2: selectDataVarApp with reactiveValuesToList()\n\n\n\nBelow is a figure that displays the contents of the selectDataVar modules (I’ve removed the tagList() and moduleServer() for simplicity), the selectDataVarApp(), and the rendered outputs:\n\n\n\n\n\n\n\n\n\n\n(a) selectDataVarApp schema\n\n\n\n\n\nFigure 3: dataset and selectVar modules inside selectDataVar module with rendered outputs"
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#testserver",
    "href": "posts/p3-test-shiny-module-tests/index.html#testserver",
    "title": "Testing Shiny modules",
    "section": "testServer()",
    "text": "testServer()\nModule server functions can be tested the same way as a traditional shiny server function, as long as you provide the inputs and verify the correct outputs. Below I’ll cover some general advice on module server tests (and the arguments in testServer()).\n\nWhat should I test?\nThe best bit of advice I’ve found helpful when writing tests comes from R Packages,\n\n“focus your time on code that you’re not sure about, is fragile, or has complicated interdependencies”\n\nThe quote isn’t in reference to testing modules or Shiny application functions, but I’ve found it’s easy to fall into the trap of trying to test everything when a targeted approach is more efficient (and equally valid).\nThe items below have been compiled from Mastering Shiny, R Packages, and Engineering Production-Grade Shiny Apps:\n\nDo the inputs/outputs behave as expected?\n\nThese tests verify the module server function inputIds and outputIds are properly namespaced and accessible\n\nDoes the module contain the expected reactive values/objects?\n\nTests should verify it’s reactivity–module server functions will automatically recompute the outputs when it’s inputs change, so tests should verify changes to inputs produce the expected behaviors and outputs. This includes any returned values from the module (and any additional function arguments).\n\nAre the calculations correct?\n\nIf the module server function performs calculations or data manipulations, the tests should verify the module produces the correct result (ideally for a variety of inputs and edge cases).\n\nHow are errors handled in the module?\n\nWhat errors are displayed from the module? Tests should simulate scenarios that can test if the module: 1) returns errors that are informative, 2) fails silently (when appropriate), or 3) falls back to the correct default behavior.\n\n\nThe first test I’ll perform is for datasetServer(), the module used to return a data object from the datasets package.\n\n\nArguments\ntestServer() has the following arguments:\n\napp can be a module server function (i.e., datasetServer), or any shiny.appobj\nexpr is where I’ll add the testthat expectations and other test code\nargs is a list() I can use to include any module server function arguments\n\n\n\nTesting inputs\nI’ll start by testing if the initial input value (input$dataset) in datasetServer() is set to NULL. The module server function is the first argument in testServer():\n\ntestServer(app = datasetServer, expr = {\n  expect_equal(input$dataset, NULL)\n  cat(\"\\ndatasetServer: dataset$input is NULL\", \"\\n\")\n})\n\n\nAdd custom messages with cat() and the inputId we’re testing. Then load, document, and install the package\ndevtools::load_all()\nℹ Loading mstsap\ndevtools::document()\nℹ Updating mstsap documentation\nℹ Loading mstsap\n\nRestarting R session...\n\nlibrary(mstsap)\n\nAnd run the test with testthat::test_file():\n\n\ntest_file(\"tests/testthat/test-datasetServer.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\ndatasetServer: dataset$input is NULL \n\ntitle-meta: “Creating test messages with testServer()”\n\ncallout-icon: false\nfreeze: true\nexecute: echo: true message: false warning: false eval: false —\n\n\n\n\n\n\nNoteTest comments with testServer()\n\n\n\n\n\n\nThe testServer() documentation has examples of using cat() to create custom messages. I put a function for creating testServer() messages (test_cmt()) in the helper.R file (read more about test helpers here).\nIt has two arguments (test and msg), and makes it easy to print messages to the console while I’m developing tests.\n\ntest_cmt(test = \"mod_server_function\", msg = \"test contents\")\n\n       mod_server_function: test contents \n\n\n\n\n\n\nSetting test inputs\ntestServer() allows us to mimic changing application (or module) inputIds with session$setInputs() like so:\n\nsession$setInputs(inputId = \"value\")\n\nI’ll demonstrate with a test for input$dataset in datasetServer():\n\n  session$setInputs(dataset = \"faithful\")\n  expect_equal(\n    object = input$dataset,\n    expected = \"faithful\")\n  test_cmt(\"datasetServer\", \"dataset$input\")\n\n\n\n\nReturned values\nAny returned values from module server functions can be accessed in testServer() with session$returned(). I’ll verify input$dataset returns an object from datasetServer() by testing the class of session$returned():\n\n\nshow/hide test with session$returned()\n  session$setInputs(dataset = \"airquality\")\n  expect_equal(\n    object = class(session$returned()),\n    expected = \"data.frame\")\n  test_cmt(\"datasetServer\", \"class(session$returned())\")\n\n  session$setInputs(dataset = \"WorldPhones\")\n  expect_true(\n    object = is.matrix(session$returned()))\n  test_cmt(\"datasetServer\", \"is.matrix(session$returned())\")\n\n\nNote that both methods above can be used to check the class of the returned object.\n\nI can also use the typeof(datasets::mtcars) for a direct comparison:\n\n\nshow/hide test with session$returned()\n  session$setInputs(dataset = \"mtcars\")\n  expect_equal(\n    # app value...\n    object = typeof(session$returned()), \n    # ...compared to actual output\n    expected = typeof(datasets::mtcars)) \n  test_cmt(\"datasetServer\", \"typeof(session$returned())\")\n\n\n\n\n\nServer function arguments\nIf the module server function has additional arguments beyond id, then it has additional functionality to verify with unit tests. To test additional module server arguments, pass these to testServer(args = list()). The args list should include named arguments from the module server function, i.e., list(param1 = \"value1\", param2 = \"value2\").\nFor example, selectVarServer() has data and filter arguments:\n\ndata is the returned reactive object from datasetServer()\nfilter is the function passed to the find_vars() utility function\n\n\n\n\n\n\n\n\n\n\n\n(a) dataset() -&gt; selectVar()\n\n\n\n\n\nFigure 4: Object returned from datasetServer() and passed to selectVarServer()\n\n\n\n\nBelow is a test for selectVarServer() using args to verify the reactive data() is datasets::mtcars:\n\ntestServer(selectVarServer,\n  args = list(data = mtcars,\n              filter = is.numeric), expr = {\n  expect_true(\n    object = is.reactive(data))\n  test_cmt(\"selectVarServer\", \"is.reactive(data())\")\n})\n\n\nBut this fails with the following error:\n\n\ntest_file(\"tests/testthat/test-selectVarServer.R\")\n\n[ FAIL 1 | WARN 0 | SKIP 0 | PASS 0 ]\n── Error (test-selectVarServer.R:1:1): (code run outside of `test_that()`) ───\nError in `(function (id, data, filter = is.numeric) \n\nWhat happened?\n\nI’ve included this example because it’s not in the testServer() documentation, and it’s common to pass values between modules (see here in Engineering Production-Grade Shiny Apps and here in Mastering Shiny)\n\nTesting module communication\nThe error message above tells me the issue is originating from the stopifnot() calls in selectVarServer().\n\n\n\n\n\n\nImportantUpdating selectVarServer() and find_vars()\n\n\n\n\n\n\nBoth selectVarServer() and find_vars() are updated from their original versions to include stopifnot() checks for is.reactive(), is.data.frame() and is.function():\n\nOriginal versions:\n\nfind_vars &lt;- function(data, filter) {\n  names(data)[vapply(data, filter, logical(1))]\n}\n\n\nselectVarServer &lt;- function(id, data, filter = is.numeric) {\n  moduleServer(id, function(input, output, session) {\n    observeEvent(data(), {\n      updateSelectInput(session, \"var\", choices = find_vars(data(), filter))\n    })\n\n    reactive(data()[[input$var]])\n  })\n}\n\nUpdated versions:\n\nselectVarServer &lt;- function(id, data, filter = is.numeric) {\n\n  stopifnot(is.reactive(data))\n  stopifnot(!is.reactive(filter))\n\n  moduleServer(id, function(input, output, session) {\n    observeEvent(data(), {\n      updateSelectInput(session = session, \n        inputId = \"var\", \n        choices = find_vars(data(), filter)\n        )\n    })\n\n    reactive(data()[[input$var]])\n  })\n}\n\n\nfind_vars &lt;- function(data, filter) {\n  stopifnot(is.data.frame(data))\n  stopifnot(is.function(filter))\n  names(data)[vapply(data, filter, logical(1))]\n}\n\n\n\n\n\n\nI’ll stop a moment here to address what’s happening in each module:\n\nThe datasetServer() returns the results of input$dataset as a reactive (data())\ndata() enters selectVarServer() in the data argument\nInside selectVarServer(), two stopifnot() functions evaluate the reactivity of data and filter with shiny::is.reactive()\n\nIn datasetServer(), the return object is wrapped in the reactive() function, so the items args = list() also need to be wrapped in reactive().\nI’ll re-write the test above to a more basic test using is.reactive():\n\ntestServer(selectVarServer,\n  args = list(data = reactive(mtcars), \n              filter = is.numeric), expr = {\n  expect_true(\n    object = is.reactive(data()))\n  test_cmt(\"selectVarServer\", \"is.reactive(data())\")\n})\n\n\ntest_file(\"tests/testthat/test-selectVarServer.R\")\n\n[ FAIL 1 | WARN 0 | SKIP 0 | PASS 0 ]\n       selectVarServer: is.reactive(data()) \n── Failure (test-selectVarServer.R:1:1): (code run outside of `test_that()`) ───\nis.reactive(data()) is not TRUE\n\n`actual`:   FALSE\n`expected`: TRUE \n\nAnother failure???\n\nThe results of this test might seem confusing given my advice to wrap the args list in reactive(), but some reading of the x argument in is.reactive() will clear up the error:\n\nFor is.reactive(), an object to test. For reactive(), an expression.\n\nRemoving the parentheses from data() will result in the proper test results:\n\ntestServer(selectVarServer,\n  args = list(data = reactive(mtcars), \n              filter = is.numeric), expr = {\n  expect_true(\n    object = is.reactive(data))\n  test_cmt(\"selectVarServer\", \"is.reactive(data())\")\n})\n\n\ntest_file(\"tests/testthat/test-selectVarServer.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\n       selectVarServer: is.reactive(data()) \nNow that I have a reactive data() input, I can explore how this value is used inside selectVarServer(). To update input$var, the data() input is passed to find_vars() (a function that uses a filter argument “used to select which variables to list”). See the example below:\n\nfind_vars(\n  data = chickwts, \n  filter = is.factor)\n\n#&gt; [1] \"feed\"\nI’ll write an expectation that captures the behavior of find_vars() in selectVarServer():\n\ntestServer(selectVarServer,\n  args = list(data = reactive(chickwts),\n              filter = is.numeric), expr = {\n  expect_equal(\n    object = find_vars(data(), is.factor),\n    expected = \"feed\")\n  test_cmt(\"selectVarServer\", \"find_vars()\")\n})\n\nThe results are below:\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ]\n       selectVarServer: find_vars()\nTo verify that the returned object from selectVarServer() is the selected column, I’ll need to simulate the application behavior in the tests:\n\nCreate a reactive data() input in selectVarServer():\n\n\nsetting args = list()\n  testServer(selectVarServer,\n    args = list(data = reactive(chickwts),\n                filter = is.numeric), expr = {\n\n    # include expectations below...\n\n  })\n\n\nSet the input$var and verify the input$var:\n\n\nverify input$var\n  session$setInputs(var = \"weight\")\n  expect_equal(object = input$var,\n      expected = \"weight\")\n  test_cmt(\"selectVarServer\", \"input$var\")\n\n\nSet the input$var and verify the session$returned()\n\n\nverify session$returned()\n  session$setInputs(var = \"feed\")\n  expect_equal(object = session$returned(),\n    expected = datasets::chickwts[[\"feed\"]])\n  test_cmt(\"selectVarServer\", \"session$returned()\")\n\n\n\nThe results from these tests are below:\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 3 ]\n       selectVarServer: input$var \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 4 ]\n       selectVarServer: session$returned() \n\n\n\nModule outputs\nRendered outputs can be accessed in testServer() just like inputs (i.e., with output$outputId). But the modules in mstsap don’t have outputs–these are included in the standalone app functions (datasetApp(), selectVarApp(), and selectDaraVarApp()).\nFortunately, app functions can also be passed to the app argument of testServer(). I’ll use datasetApp() to demonstrate.\n\n\n\n\n\n\n\n\n\n\nds_app &lt;- datasetApp()\n  testServer(ds_app, \n    expr = {\n\n  })\n\n\n\nTesting a standalone app function is similar to testing a module server function, but with a few minor differences. First, the output from the standalone app function is assigned to an object (ds_app), then placed in the app argument.\nTo use session$setInputs() need to include the namespace for the inputId. The output from reactiveValuesToList() in datasetApp() shows me how to access the inputId in the datasetServer() module (i.e., input$`dataset-dataset`):\n\n\n\n\n\n\n\n\n\n\nds_app &lt;- datasetApp()\ntestServer(ds_app, \nexpr = {\n  session$setInputs(\n  `dataset-dataset` = \"chickwts\")\n})\n\n\n\n\nOutput testing strategy\nTesting outputs with testServer() is different than testing outputs in regular unit tests, because Shiny outputs are executed in the server, but then rendered as HTML in the UI. testServer() outlines a testing strategy for complex outputs:\n\n*The goal for your tests should be to ask “is the code that I wrote producing the plot I want?” There are two components to that question:\n\nDoes the plot generate without producing an error?\nIs the plot visually correct?\n\ntestServer is great for assessing the first component here. By merely referencing output$plot in your test, you’ll confirm that the plot was generated without an error.\n\nIf we replace plot with table in the advice above, the tests for datasetApp() should confirm output$data is generated without producing an error.\nInstead of writing an expectation, we’ll use cat() to display the contents of output$data after setting the `dataset-dataset` input:\n\nds_app &lt;- datasetApp()\ntestServer(ds_app, expr = {\n  session$setInputs(`dataset-dataset` = \"chickwts\")\n  cat(\"\\n\\toutput$data:\\n\", output$data, \"\\n\")\n})\n\nThe results from the test is below:\n\ntest_file(\"tests/testthat/test-datasetApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 0 ]\n    output$data:\n &lt;table  class = 'table shiny-table table- spacing-s' style = 'width:auto;'&gt;\n  &lt;thead&gt; \n      &lt;tr&gt; \n        &lt;th style='text-align: right;'&gt; weight &lt;/th&gt; \n        &lt;th style='text-align: left;'&gt; feed &lt;/th&gt;  \n     &lt;/tr&gt; \n    &lt;/thead&gt; \n      &lt;tbody&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 179.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 160.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 136.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 227.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 217.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 168.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n   &lt;/tbody&gt; \n &lt;/table&gt; \nThe output is the HTML used to render the table in the UI. This doesn’t add a passing test, but it confirms that the table is being generated from the data() reactive.\nThe tests for datasetApp() will confirm the inputId, and verify the class and names of the data() reactive (which will be passed to the renderTable() function):\n\n  expect_equal(\n    object = input$`dataset-dataset`,\n    expected = \"chickwts\")\n  test_cmt(\"datasetApp\", \"input$`dataset-dataset`\")\n\n  expect_true(\n    object = is.data.frame(data()))\n  test_cmt(\"datasetApp\", \"is.data.frame(data())\")\n\n  expect_equal(\n    object = names(data()),\n    expected = names(datasets::chickwts))\n  test_cmt(\"datasetApp\", \"names(data())\")\n\nI can include a test for the class of output$data, but note that this is a character output:\n\nexpect_equal(\n  object = class(output$data),\n  expected = \"character\")\ntest_cmt(\"datasetApp\", \"class(output$data)\")\n\nThe results from test_file() are below:\n\ntest_file(\"tests/testthat/test-datasetApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\n       datasetApp: input$`dataset-dataset` \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ]\n       datasetApp: is.data.frame(data()) \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 3 ]\n       datasetApp: names(data()) \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 4 ]\n       datasetApp: class(output$data) \nThe same method can be used to test the selectVarApp(), but note this app requires passing both inputIds to session$setInputs():\n\n\nshow/hide selectVarApp() tests\nsv_app &lt;- selectVarApp()\ntestServer(app = sv_app, expr = {\n  session$setInputs(`var-var` = \"Ozone\",\n                    `data-dataset` = \"airquality\")\n  # confirm contents of output$out\n  cat(\"\\n\\toutput$out:\\n\", output$out, \"\\n\")\n  \n  # confirm var is reactive \n  expect_true(object = is.reactive(var))\n  # confirm var input\n  expect_equal(\n    object = input$`var-var`,\n    expected = \"Ozone\")\n  # confirm data is reactive\n  expect_true(object = is.reactive(data))\n  # confirm data() is a data.frame\n  expect_true(\n    object = is.data.frame(data()))\n  # confirm 'data' can be subsetted with 'var'\n  expect_equal(\n    object = data()[[input$`var-var`]],\n    expected = airquality[[\"Ozone\"]])\n})\n\n\n\n\nTesting nested modules\nI highly recommend viewing the output of reactiveValuesToList() if your application has nested modules. It’s easy to lose track of ids if they span multiple layers.\nWe know selectDataVarApp() contains ‘modules inside other modules’, and these layers are reflected in the namespaces:\n\n\n\n\n\nTo access the inputIds in the nested modules, we need to pass the full ‘appended’ namespace:\n\ndv_app &lt;- selectDataVarApp()\ntestServer(app = dv_app, expr = {\n  session$setInputs(`var-var-var` = \"Ozone\",\n                    `var-data-dataset` = \"airquality\")\n})\n\nAfter setting the inputs, I can confirm the contents of output$out\n\ndv_app &lt;- selectDataVarApp()\ntestServer(app = dv_app, expr = {\n  session$setInputs(`var-var-var` = \"Ozone\",\n                    `var-data-dataset` = \"airquality\")\n  cat(\"\\n\\toutput$out:\\n\", output$out, \"\\n\")\n})\n\n\ntest_file(\"tests/testthat/test-selectDataVarApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 0 ]\n    output$out:\n   [1]  41  36  12  18  NA  28  23  19   8  NA   7  16  11  14  18\n [16]  14  34   6  30  11   1  11   4  32  NA  NA  NA  23  45 115\n [31]  37  NA  NA  NA  NA  NA  NA  29  NA  71  39  NA  NA  23  NA\n [46]  NA  21  37  20  12  13  NA  NA  NA  NA  NA  NA  NA  NA  NA\n [61]  NA 135  49  32  NA  64  40  77  97  97  85  NA  10  27  NA\n [76]   7  48  35  61  79  63  16  NA  NA  80 108  20  52  82  50\n [91]  64  59  39   9  16  78  35  66 122  89 110  NA  NA  44  28\n[106]  65  NA  22  59  23  31  44  21   9  NA  45 168  73  NA  76\n[121] 118  84  85  96  78  73  91  47  32  20  23  21  24  44  21\n[136]  28   9  13  46  18  13  24  16  13  23  36   7  14  30  NA\n[151]  14  18  20 \nAfter confirming output$out, I’ll test the inputs:\n\n  expect_equal(\n    object = input$`var-var-var`,\n    expected = \"Ozone\")\n  test_cmt(\"selectDataVarApp\", \"input$`var-var-var`\")\n\n  expect_equal(\n    object = input$`var-data-dataset`,\n    expected = \"airquality\")\n  test_cmt(\"selectDataVarApp\", \"input$`var-data-dataset`\")\n\n\ntest_file(\"tests/testthat/test-selectDataVarApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\n       selectDataVarApp: input$`var-var-var` \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ]\n       selectDataVarApp: input$`var-data-dataset`\nI can also verify the contents of the reactive var() inside the test:\n\n  expect_true(object = is.reactive(var))\n  test_cmt(\"selectDataVarApp\", \"is.reactive(var)\")\n  cat(\"\\n\\tvar:\\n\", var(), \"\\n\")\n\n\ntest_file(\"tests/testthat/test-selectDataVarApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 3 ]\n       selectDataVarApp: is.reactive(var) \n\n    var:\n 41 36 12 18 NA 28 23 19 8 NA 7 16 11 14 18 14 34 6 30 11 1 11 4 32 NA NA NA 23 \n    45 115 37 NA NA NA NA NA NA 29 NA 71 39 NA NA 23 NA NA 21 37 20 12 13 NA NA NA\n    NA NA NA NA NA NA NA 135 49 32 NA 64 40 77 97 97 85 NA 10 27 NA 7 48 35 61 79 \n    63 16 NA NA 80 108 20 52 82 50 64 59 39 9 16 78 35 66 122 89 110 NA NA 44 28 \n    65 NA 22 59 23 31 44 21 9 NA 45 168 73 NA 76 118 84 85 96 78 73 91 47 32 20 23\n    21 24 44 21 28 9 13 46 18 13 24 16 13 23 36 7 14 30 NA 14 18 20"
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#recap",
    "href": "posts/p3-test-shiny-module-tests/index.html#recap",
    "title": "Testing Shiny modules",
    "section": "Recap",
    "text": "Recap\nThis post has shown how shiny’s testServer() function allows you to isolate and test module server functions, which makes it easier to ensure that your server function behaves as expected (and locate and fix bugs).\nI hope you have a better understanding of how you can use testServer() to test a modules inputs/outputs, reactivity, calculations, and errors.\nIn the next post I’ll cover performing integration tests with shinytest2!"
  },
  {
    "objectID": "posts/p3-test-shiny-module-tests/index.html#footnotes",
    "href": "posts/p3-test-shiny-module-tests/index.html#footnotes",
    "title": "Testing Shiny modules",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSpecifically, the applications come from sections 19.3 through 19.3.4.↩︎\nThe help files for NS() include the following description for a module namespace: “a namespace is to an ID as a directory is to a file.”↩︎"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html",
    "href": "posts/quarto-shiny-rpkg/index.html",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "",
    "text": "This post was prompted by a new chapter I’ve been working on for Shiny App-Packages. I’ve recently been building a Shiny application in a Quarto document1, and noticed quite a few deviations from the standard app-package practices that deserve some attention.\nI’ll cover various dashboard/html layout options, including modules in a Quarto document, and how to create a standalone function to launch your Quarto + Shiny app from an app-package."
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#set-up",
    "href": "posts/quarto-shiny-rpkg/index.html#set-up",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Set up",
    "text": "Set up\nThe Quarto document (index.qmd) is placed inside the inst/ folder with a _quarto.yml project file:\n└── inst\n     └── quarto\n          ├── _quarto.yml\n          └── index.qmd\n\n_quarto.yml\n_quarto.yml contains metadata on the format, style, and rendering options for the dashboard.\ntitle: \"Quarto Movies App\"\n\nformat:\n  html:\n    embed-resources: true\nThis file includes options for the entire Quarto project (i.e., all .qmd files in the folder). In our case it’s simply the dashboard file: index.qmd.\n\n\nindex.qmd\nThe index.qmd file contains the title of our application and the format of the document in the YAML frontmatter.\n---\ntitle: \"Movies App\"\nformat: html\nserver: shiny\n---\n\n\nwww/\nTo include resources (like images or stylesheets), we’ll also add a www/ folder:\n└── inst\n     └── quarto\n          ├── _quarto.yml\n          ├── index.qmd\n          └── www/\n              └── quarto.png\n\n\ncontext: setup\nThe first code chunk in index.qmd should include a context: setup option and load the necessary packages. If we want the dashboard to have access to the resources in www/, we need to include the addResourcePath() function and pass the path with the installed version of our application.\n```{r}\n#| context: setup\n# pkgs -------\nlibrary(sap)\nlibrary(thematic)\nlibrary(ragg)\n# resources --------\naddResourcePath(\n    prefix = 'quarto',\n    directoryPath = system.file('www', package = 'sap'))\n```"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#dashboards",
    "href": "posts/quarto-shiny-rpkg/index.html#dashboards",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Dashboards",
    "text": "Dashboards\nDashboard layouts are covered extensively in the Quarto documentation2 and elsewhere3, and I’ve included example layouts in the code repo. Key things to remember about Quarto dashboard layouts:\n\nformat: dashboard\n\nDashboard layouts are configured using a combination of YAML fields and markdown headings. By default, the orientation field is set to rows, but multiple code chunks will add new columns:\nformat: \n  dashboard:\n    orientation: columns\nLevel 1 headers create pages (with titles)\n# Page 1\nLevel 2 and 3 headers create columns and rows (with height and width options)\n## Row {height=20%}\n\n### Column {width=35%}\nTabsets can be created {.tabset}:\n### Column {.tabset}\nInside the columns and rows, cards provide a flexible, grid-based structure for presenting different types of content. Cards are automatically created with text or a code chunk, and they can be labeled with a title. Cards can also be included using {.card} inside a div (:::):\n#| title: Cost per week\n::: {.card title=\"Cost per week\"}\n\n:::\nTo customize the navigation bar in a Quarto dashboard, we can incorporate elements such as a logo and nav-buttons.\nformat:\n  dashboard:\n    nav-buttons:\n      - text: About\n        href: https://quarto.org/\n      - icon: github\n        href: https://github.com/mjfrigaard/quarto-dash-r\n      - icon: wikipedia\n        target: _blank\n        href: https://en.wikipedia.org/wiki/RStudio#Reproducible_analyses_with_vignettes\n\n\n\n\nView various layouts in the GitHub repository. for this post.\nBelow is an example dashboard layout with most of the features mentioned above. Note that the standard code chunk options are also available (i.e., code echo/folding):\n\n\n\nQuarto layout options page 1 (click to enlarge)\n\n\n\n\n\nQuarto layout options page 2 (click to enlarge)\n\n\nView the code used for the layout above (and others) in the GitHub repository.4"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#reactivity",
    "href": "posts/quarto-shiny-rpkg/index.html#reactivity",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Reactivity",
    "text": "Reactivity\nQuarto documents can be converted into Shiny’s apps using the server option in the YAML header. In our index.qmd file, we’ll set server to shiny:\n\nserver: shiny\n---\ntitle: \"Movies App\"\nformat: html\nserver: shiny\n---\n```{r}\n#| context: server\n```"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#modules",
    "href": "posts/quarto-shiny-rpkg/index.html#modules",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Modules",
    "text": "Modules\nIf you’re developing a Quarto + Shiny application using modules (and you should5 be6), the module functions can be placed in the code blocks like regular Shiny code.\nThe code below is used to implement the UI functions from the mod_var_input.R and mod_scatter_display_ui.R modules:\n```{r}\n#| panel: input\nmod_var_input_ui(\"vars\")\n```\n\n```{r}\n#| panel: center\nmod_scatter_display_ui(\"plot\")\n```\nThe panel: input creates a ‘div with class .panel-input and panel: center will’leave some horizontal margin around its content.’7\nWe can also include regular shiny code in code chunks:\n```{r}\n#| panel: fill\ntags$br()\ntags$em(\n  \"Built using \",\n  tags$a(\n    img(\n      src = \"www/quarto.png\",\n      height = 25,\n      width = 90,\n      style = \"margin:10px 10px\"\n    ),\n    href = \"https://quarto.org/docs/interactive/shiny/\"\n  ),\n  \"and data from the \",\n  tags$a(\"Building web applications with Shiny\", \n    href = \"https://rstudio-education.github.io/shiny-course/\"),\n  \"tutorial.\"\n)\n```\npanel: fill will ‘fill all available space’ in the dashboard.8\n\ncontext: server\nThe server: shiny in the YAML frontmatter ensures the document will render the UI inputs (i.e., the contents of mod_var_input_ui()). To differentiate the server (running on the back-end) code from user inputs and outputs, we need to add the module server functions in code blocks with the context: server option:\n```{r}\n#| context: server\n\nselected_vars &lt;- mod_var_input_server(\"vars\")\n\nmod_scatter_display_server(\"plot\", var_inputs = selected_vars)\n```"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#styling",
    "href": "posts/quarto-shiny-rpkg/index.html#styling",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Styling",
    "text": "Styling\nSASS (Syntactically Awesome Style Sheets) or CSS (Cascading Style Sheets) can be powerful tools for customizing a Quarto dashboard’s appearance. Unlike standard CSS, SCSS introduces features like variables, nesting, and mixins, which help keep the code organized and modular.\n\nstyles.scss\nA dedicated .scss file keeps styles organized and separated from content, improving readability and maintainability.\n└── inst\n     └── quarto\n          ├── _quarto.yml\n          ├── index.qmd\n          └── www\n              ├── quarto.png\n              └── styles.scss\nWe will set some colors defaults in www/styles.scss:\n/*-- scss:defaults --*/\n\n// colors\n$body-bg: #070d35;\n$body-color: #FFFFFF;\n\n$link-color: #2ee3a4;\n$hover-color: lighten($link-color, 40%);\n\n$code-block-bg-alpha: -.8;\n\n/*-- scss:rules --*/\n\n\nthematic\nFor a broader, simplified approach to styling, we can install/use the thematic package:\n\ninstall.packages(\"thematic\")\n\nWe can add thematic_set_theme() to the context: setup code chunk in index.qmd:\n\nthematic::thematic_set_theme(\n  theme = thematic::thematic_theme(\n    bg = \"#070d35\", \n    fg = \"#FFFFFF\", \n    accent = \"#2ee3a4\"))\n\nThis also requires the shiny.useragg option:\n\noptions(shiny.useragg = TRUE)"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#launching",
    "href": "posts/quarto-shiny-rpkg/index.html#launching",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Launching",
    "text": "Launching\nTo launch our Quarto dashboard with a standalone app function, we can use quarto_preview() with system.file():\n\nlaunch_app &lt;- function() {\n  quarto::quarto_preview(\n    system.file(\"quarto\", \"index.qmd\", package = \"sap\" ), \n    render = \"all\")\n}\n\n\nlaunch_app()\n\n\n\n\n\n\n\n\nQuarto App (click to enlarge)"
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#recap",
    "href": "posts/quarto-shiny-rpkg/index.html#recap",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Recap",
    "text": "Recap\nIf you’re interested in learning more, check out the Quarto apps section of Shiny App-Packages and the Quarto documentation. Albert Rapp has a great video on building interactive apps with Quarto & Shiny and Isabella Velásquez also does a fantastic job covering python Quarto dashboards."
  },
  {
    "objectID": "posts/quarto-shiny-rpkg/index.html#footnotes",
    "href": "posts/quarto-shiny-rpkg/index.html#footnotes",
    "title": "Quarto Shiny Apps in R Packages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nShiny is covered in the Interactivity section of the Quarto documentation.↩︎\nQuarto dashboards.↩︎\nMine Çetinkaya-Rundel has an excellent three part tutorial on Posit’s YouTube channel (part 1, part 2, part 3).↩︎\nThe .qmd files ending in layout are examples of various dashboard layouts.↩︎\nSee the Modularizing Shiny app code in the Shiny documentation.↩︎\nSee the Shiny modules chapter of Mastering Shiny.↩︎\nRead more about Input Panel layouts↩︎\nRead more about Sidebar Panel layouts.↩︎"
  },
  {
    "objectID": "posts/py-vscode/index.html",
    "href": "posts/py-vscode/index.html",
    "title": "VS Code, meet Quarto.",
    "section": "",
    "text": "NoteNote\n\n\n\n\n\n\nI’ve been using VS Code to write more and more Python code lately, so I’ve decided make some notes on 1) installing Python, 2) working in VS Code, and 3) using Python code chunks in Quarto."
  },
  {
    "objectID": "posts/py-vscode/index.html#background",
    "href": "posts/py-vscode/index.html#background",
    "title": "VS Code, meet Quarto.",
    "section": "Background",
    "text": "Background\nI’d been an avid R/RStudio (now Posit Workbench) user for 10+ years, but lately I’ve been spending a lot of time with Python in VS Code. Transitioning from one programming language and development environment to another was daunting at first, but Quarto opens up a world of new opportunities for learning new languages. This post covers setting up Quarto and Python in VS Code, learning pains, tips, and early successes."
  },
  {
    "objectID": "posts/py-vscode/index.html#installing-vs-code",
    "href": "posts/py-vscode/index.html#installing-vs-code",
    "title": "VS Code, meet Quarto.",
    "section": "Installing VS Code",
    "text": "Installing VS Code\n\n\n\nYou can download VS Code from the official website. I recommend following the installation instructions for your particular operating system. After installing VS Code, you’ll want to install the Quarto extension and Python extension from Microsoft.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: VS Code Start\n\n\n\n\n\n\n\n\n\nWarningOS DISCLAIMER\n\n\n\n\n\n\nI’m using macOS Sonoma (14.4.1 (23E224)) with Bash and iTerm2.\n\n\n\n\nNow we’ll cover a few options for installing and using Python."
  },
  {
    "objectID": "posts/py-vscode/index.html#installing-python",
    "href": "posts/py-vscode/index.html#installing-python",
    "title": "VS Code, meet Quarto.",
    "section": "Installing Python",
    "text": "Installing Python\n\n\n\nInstalling Python was always a little fuzzy for me. There are multiple ways to install Python: from the official Python website; using a package manager like Chocolatey or Homebrew; or with an IDE like PyCharm or Anaconda. These options would often result in questions like:\n\n\n\n\n\n\n\n\n\n\nHow do I install Python on other operating systems (i.e., Windows and Linux)?\nWhat is the differences between Python versions? Which one should I install and use?\nHow do I manage multiple Python versions on my machine?\nShould I use anaconda or miniconda or pip for managing Python packages?\nThe safest way I found to install Python was to follow the following steps:\n\nGo to the Python website.\nClick on the “Downloads” tab and choose the appropriate version for your operating system (Windows, macOS, Linux).\n\n\n\n\n\n\n\nFigure 2: Python Downloads\n\n\n\n\nRun the installer and make sure to check the box that says “Add Python to PATH” during installation.\n\n\nHomebrew\nWhen using Homebrew, it’s important to note the different locations for Python installations. The which command is helpful here:\n\n\nIn Terminal\nwhich python3\n# /usr/bin/python3\n\n\n/usr/bin/python3 is the system-managed Python installation. It’s minimal and less likely to change, and is intended to ensure stability.\nIf you’re using Homebrew to install Python, you’ll probably notice there are other installations of Python in /usr/local/bin. This is because /usr/local/bin is commonly location for user-installed software, separate from the system’s default utilities.1\n\n\nIn Terminal\ntree -P \"python*\" /usr/local/bin -L 2\n# /usr/local/bin\n# ├── python3 -&gt; ../Cellar/python@3.12/3.12.4/bin/python3\n# ├── python3-config -&gt; ../Cellar/python@3.12/3.12.4/bin/python3-config\n# ├── python3.12 -&gt; ../Cellar/python@3.12/3.12.4/bin/python3.12\n# └── python3.12-config -&gt; ../Cellar/python@3.12/3.12.4/bin/python3.12-config\n# \n# 1 directory, 4 files\n\n\nThe output above shows the files and the symbolic links they are referencing. The links are pointing to the actual binaries located under the ../Cellar/python@3.12/ directory.2\nThe symbolic links in /usr/local/bin are a modular approach to updating Python. This is handy for user-installed environments where installations or updates can be managed flexibly without disrupting the system’s core functionality.\nThe Python tutorial offered by VS Code also clarified many of the previous questions I’d struggle with.3\n\n\nPython VS Code Extension\nLocate and install the Python VS Code extension using the search bar in the Extensions:\n\n\n\n\n\n\n\n\n\n\n\n(a) Search for ‘Python’\n\n\n\n\n\n\n\n\n\n\n\n(b) Python VS Code Extension\n\n\n\n\n\n\n\nFigure 3: Search for and install Python VS Code extension"
  },
  {
    "objectID": "posts/py-vscode/index.html#installing-quarto",
    "href": "posts/py-vscode/index.html#installing-quarto",
    "title": "VS Code, meet Quarto.",
    "section": "Installing Quarto",
    "text": "Installing Quarto\n\n\n\n\n\n\n\n\n\n\nQuarto can be downloaded and installed from its official website. Follow the platform-specific instructions to install it on your system. Make sure Quarto has been installed correctly and is available in your system’s PATH.\n\n\n\nCheck if Quarto is on PATH:\n\n\nIn Terminal\nquarto --version\n# 1.5.28\n\n\nIf it isn’t, you’ll need to add the location of your quarto installation to PATH. You can do that with the commands below (depending on your shell).\nFor Bash (common in Linux and older macOS versions):\necho 'export PATH=\"$PATH:/path/to/quarto\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nFor Zsh (default in newer macOS versions):\necho 'export PATH=\"$PATH:/path/to/quarto\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\nYou can also use which to locate quarto path:\n\n\nIn Terminal\nwhich quarto\n# /usr/local/bin/quarto\n\n\nNow that we have Quarto installed and configured, we’ll check our dependencies and install the VS Code extension to make sure VS Code can find Quarto and Python.\n\nQuarto Check\nI highly recommend running quarto check to confirm Python and the other dependencies have been installed. I’ve provided the output from my setup and a brief description below:\nQuarto installation displays the path to the installation of the current Quarto version.\nQuarto 1.5.28\n[✓] Checking versions of quarto binary dependencies...\n      Pandoc version 3.1.11: OK\n      Dart Sass version 1.70.0: OK\n      Deno version 1.41.0: OK\n      Typst version 0.10.0: OK\n[✓] Checking versions of quarto dependencies......OK\n[✓] Checking Quarto installation......OK\n      Version: 1.5.28\n      Path: /Applications/quarto/bin\ntools checks for a TinyTex installation (and installs it if its not there), Latex confirms the installation of LaTeX or TinyTex and displays the path (in this case, the path to the TinyTex installation), and basic markdown rendering is confirmed.\n[✓] Checking tools....................OK\n      TinyTeX: (external install)\n      Chromium: 869685\n\n[✓] Checking LaTeX....................OK\n      Using: TinyTex\n      Path: /Users/username/Library/TinyTeX/bin/universal-darwin\n      Version: 2023\n\n[✓] Checking basic markdown render....OK\nPython 3 installation returns the python and jupyter versions, the python installation path, and kernels.\n[✓] Checking Python 3 installation....OK\n      Version: 3.11.5 (Conda)\n      Path: /Users/username/miniconda3/bin/python\n      Jupyter: 5.7.2\n      Kernels: python3\n\n[✓] Checking Jupyter engine render....OK\nNotice Quarto is using the python version installed in /Users/username/miniconda3/bin/python, not the /usr/bin/python3 version above.\nR installation checks all the R stuff (LibPaths, knitr, rmarkdown)\n[✓] Checking R installation...........OK\n      Version: 4.3.2\n      Path: /Library/Frameworks/R.framework/Resources\n      LibPaths:\n        - /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\n      knitr: 1.46\n      rmarkdown: 2.26\n\n[✓] Checking Knitr engine render......OK\n\n\nQuarto VS Code Extension\nAfter installing Quarto, locate and install the Quarto VS Code Extension from VS Code by searching for ‘Quarto’:\n\n\n\n\n\n\n\n\n\n\n\n(a) Search for ‘Quarto’\n\n\n\n\n\n\n\n\n\n\n\n(b) Quarto VS Code Extension\n\n\n\n\n\n\n\nFigure 4: Search for and install Quarto VS Code extension\n\n\n\n\n\nQuarto (.qmd) files\nI’ve created a hello.qmd file in the py-quarto-hello folder to run the example code from the Quarto website.4 The document contains a YAML header, some markdown text, and a Python code chunk.\n\n\n\n\n\n\n\nQuarto document with Python code"
  },
  {
    "objectID": "posts/py-vscode/index.html#python-interpreter",
    "href": "posts/py-vscode/index.html#python-interpreter",
    "title": "VS Code, meet Quarto.",
    "section": "Python Interpreter",
    "text": "Python Interpreter\nWe can select a Python interpreter to run Python in VS Code by using the command palette. Below are the available Python interpreters I can select on my machine:5\n\n\nCommand Palette Keyboard Shortcut:\n\nCmd + Shift + P\n\n\n\n\n\n\n\nPython interpreter\n\n\nIf I select the recommended Python interpreter in the command palette and run which python3 in the terminal inside VS Code, I see the following:6\n\n\nInside VS Code Terminal\nwhich python3\n# /Users/&lt;username&gt;/.pyenv/versions/3.9.15/bin/python3\n\n\nBut when I run which python3 in a Terminal outside of VS Code, I see the following:\n\n\nOutside VS Code (in iTerm2)\nwhich python3\n# /Users/&lt;username&gt;/miniconda3/bin/python3\n\n\nThe differences in Python versions when running which python3 in the VS Code Terminal versus the iTerm2 Terminal are due to distinct Python environments being picked up by each terminal session.\n\npyenv\nIn the VS Code Terminal, which python3 identifies the Python version installed via pyenv. pyenv is a simple Python version management tool that allows you to easily switch between multiple versions of Python. It focuses primarily on managing different versions of the Python interpreter.7\npyenv modifies the PATH to prioritize its versions of Python over system-installed versions (like the one stored in /usr/bin/python3):\n\nPython Version: 3.9.15\nSource: pyenv environment\nPath: /Users/username/.pyenv/versions/3.9.15/bin/python3\n\n\n\nminiconda3\nThe output from which python3 in the iTerm2 terminal indicates it’s using Python from a Conda environment.–specifically, miniconda.\nminiconda is a popular package, dependency, and environment management system which is typically used for scientific computing and data science, where managing complex dependencies is crucial. The miniconda environment has its own isolated directory, separate from the system-wide installations (like /usr/bin/python3).\n\nPython Version: 3.11.5\nSource: Conda environment\nPath: /Users/&lt;username&gt;/miniconda3/bin/python3\n\nThe primary reason for the differences between the VS Code terminal and iTerm2 is how the PATH environment variable is set up in each terminal instance. VS Code’s terminal is configured to add the pyenv managed Python to the PATH ahead of the miniconda managed version, resulting in the pyenv version being used when which python3 is executed.\n\n\nKey Features\npyenv manages multiple Python versions by manipulating the PATH environment variable and does not concern itself with non-Python dependencies.\nminiconda generally creates and manages self-contained environments that include Python and other dependencies. It modifies the PATH within the shell it’s activated in, which might be automatically configured in your standard macOS Terminal.\nThe table below compares key features between pyenv and miniconda:\n\n\n\n\n\n\n\n\nFeature\nPyenv\nMiniconda\n\n\n\n\nPython Version Management\nYes\nYes\n\n\nVirtual Environment\nYes (with pyenv-virtualenv)\nYes\n\n\nPackage Management\nBasic (via pip)\nAdvanced (via Conda)\n\n\nCross-Language Support\nNo\nYes\n\n\nDependency Management\nLimited\nRobust\n\n\nIdeal for Simple Projects\nYes\nNo\n\n\nIdeal for Complex Projects\nNo\nYes\n\n\nMulti-Language Support\nNo\nYes"
  },
  {
    "objectID": "posts/py-vscode/index.html#vs-code-quarto-python",
    "href": "posts/py-vscode/index.html#vs-code-quarto-python",
    "title": "VS Code, meet Quarto.",
    "section": "VS Code + Quarto + Python",
    "text": "VS Code + Quarto + Python\nWe’re finally ready to render our Quarto document! Quarto documents can be rendered by clicking on the Preview icon:\n\n\nQuarto Render Keyboard Shortcut:\n\nShift+Cmd+K\n\n\n\n\n\nI’ve also added editor: render-on-save: and set the value to true so the document will automatically render in the Quarto preview pane.\n\n\n\n\n\n\n\nHello Quarto\n\n\n\nDependencies and metadata\nIf we continue adding the Python code 8 to our Quarto document, it’s a good practice to create and work within a virtual environment to manage project-specific dependencies. We can do this by entering the following in the VS Code terminal:\n\n\nIn VS Code Terminal\npython -m venv .venv\nsource .venv/bin/activate\n\n\nThe commands above uses the venv module that is included with Python to create a virtual environment. .venv is the directory where the virtual environment will be created. Inside this directory, a standalone Python environment is set up. This environment includes its own Python interpreter and a site-packages directory where Python packages can be installed independently of the global Python environment.\nThe source .venv/bin/activate command adjusts the environment variables so the shell uses the Python interpreter and libraries from the virtual environment instead of the global Python installation. Any Python packages installed using pip will be installed in the virtual environment’s site-packages directory.\n\n\nIn VS Code Terminal\npip install jupyter matplotlib plotly pandas\n\n\nOnce all the dependencies are installed, we should generate a list of all installed packages along with their versions in a requirements.txt file using the pip freeze command:\n\n\nIn VS Code Terminal\npip freeze &gt; requirements.txt\n\n\nWe should also include our virtual environment folder in the .gitignore file (because all of the dependencies are safely listed in the requirements.txt).\n\n\nIn .gitignore\n# Ignore the virtual environment directory\n.venv/\n\n\nWe can also add a _quarto.yml file to store project-level metadata like styling, outputs, and code cell configurations.\nproject:\n  title: \"Python in Quarto\"\n  output-dir: .\n\ntoc: true\ntoc-title: Contents\ntoc-location: left\ntoc-expand: true\nnumber-sections: false\n\nformat:\n  html:\n    code-fold: show\n\neditor: \n  render-on-save: true"
  },
  {
    "objectID": "posts/py-vscode/index.html#more-resources",
    "href": "posts/py-vscode/index.html#more-resources",
    "title": "VS Code, meet Quarto.",
    "section": "More resources",
    "text": "More resources\nRami Krispin also has a great guide for setting up Python and Docker in VS Code. The Quick Start Guide for Python in VS Code has a lot of information (and .gifs!). Eric Nantz also has a fantastic and thorough Setting up my Quarto adventures! video on the Shiny Developer Series YouTube channel, too."
  },
  {
    "objectID": "posts/py-vscode/index.html#footnotes",
    "href": "posts/py-vscode/index.html#footnotes",
    "title": "VS Code, meet Quarto.",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI display these below using the tree command.↩︎\nThis is typical of Homebrew installations on macOS, where Homebrew installs software under /usr/local/Cellar and creates symlinks in /usr/local/bin for easy execution.↩︎\nGetting Started with Python in VS Code.↩︎\nThe example code in hello.qmd comes from the Render and Preview section.↩︎\nThe path of the recommended interpreter is ~/pyenv/versions/3.9.15/bin/python.↩︎\nI’ve replaced my username with &lt;username&gt;.↩︎\nRead more about how pyenv works.↩︎\nThe Python code we’re using comes from the Computations section of the Quarto website.↩︎"
  },
  {
    "objectID": "posts/debugging/index.html",
    "href": "posts/debugging/index.html",
    "title": "Debugging in RStudio",
    "section": "",
    "text": "In this post I’ll cover using the browser() function with RStudio’s debugger. RStudio’s debugging tools are built into the IDE, which provides a seamless transition between writing, running, and debugging code."
  },
  {
    "objectID": "posts/debugging/index.html#getting-started",
    "href": "posts/debugging/index.html#getting-started",
    "title": "Debugging in RStudio",
    "section": "Getting started",
    "text": "Getting started\nI want to create a function that returns a table of ‘data structure’ columns that describe the available data.frame or tibble objects loaded with a package. Below is a small example of the desired return object from this function:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nDataset\nClass\nColumns\nRows\nLogical\nNumeric\nCharacter\nFactor\nList\n\n\n\n\ndplyr\nstarwars\ntbl_df, tbl, data.frame\n13\n19066\n0\n11\n1\n1\n0\n\n\ndatasets\nmtcars\ndata.frame\n11\n32\n0\n11\n0\n0\n0\n\n\n\n\n\n\nThis table shows the storms data from dplyr and the mtcars data from datasets. The columns include the Package the data came from, the dataset name (Dataset), the data Title from the documentation, the Class of the data object, the total number of Columns and Rows, and the number of columns by type (Logical, Numeric, Character, Factor and List).\nOne of the first steps for creating this function is to verify a package’s namespace is loaded. I’ve written the check_pkg_ns() to check this.\n\n\ncheck_pkg_ns()\ncheck_pkg_ns &lt;- function(pkg, quiet = FALSE) {\n  if (isFALSE(quiet)) {\n    # with messages\n    if (!isNamespaceLoaded(pkg)) {\n      if (requireNamespace(pkg, quietly = FALSE)) {\n        cat(paste0(\"Loading package: \", pkg, \"\\n\"))\n      } else {\n        stop(paste0(pkg, \" not available\"))\n      }\n    } else {\n      cat(paste0(\"Package \", pkg, \" loaded\\n\"))\n    }\n  } else {\n    # without messages\n    if (!isNamespaceLoaded(pkg)) {\n      if (requireNamespace(pkg, quietly = TRUE)) {\n      } else {\n        stop(paste0(pkg, \" not available\"))\n      }\n    }\n  }\n}\n\n\ncheck_pkg_ns() checks if a packages’s namespace is loaded, and if not, loads it. This function assumes the package (pkg) has been installed with install.packages() (I’ve also written check_pkg_inst() to check if the package has been installed.)\n\nExperiment\nBefore debugging, I’ll read the documentation and help files to find examples or use cases for ‘mini-experiments.’ These are designed to clarify any function arguments and learn how the code truly works. Experiments should produce predictable, definitive (preferably incompatible) outputs from each function.\n\nNamespace functions\nThe help file contains the following helpful statement on isNamespaceLoaded():\n\n“isNamespaceLoaded(pkg) is equivalent to but more efficient than pkg %in% loadedNamespaces()”\n\nFirst, I’ll check the loaded namespaces with loadedNamespaces(), then look for a package I know isn’t in the namespace with isNamespaceLoaded(). I’ll use the fs package because it isn’t loaded or attached to the search() list:\n\n# what's in the namespace? \nloadedNamespaces()\n\n [1] \"compiler\"   \"rsconnect\"  \"graphics\"  \n [4] \"tools\"      \"rstudioapi\" \"utils\"     \n [7] \"grDevices\"  \"stats\"      \"datasets\"  \n[10] \"methods\"    \"base\"\nCheck if fs is in the loaded namespace:\n\n# verify fs is not loaded\nisNamespaceLoaded(\"fs\")\n\n[1] FALSE\nThe help file tells me the following about requireNamespace:\n\n“requireNamespace is a wrapper for loadNamespace analogous to require() that returns a logical value.”\n\n…and…\n\n“requireNamespace returns TRUE if it succeeds or FALSE”\n\nI’ll load a package (\"fs\") with requireNamespace() and verify it’s in the namespace with isNamespaceLoaded().\n\n# add \"fs\" to the namespace\nrequireNamespace(\"fs\")\n\nLoading required namespace: fs\n[1] TRUE\n\n# verify it's been added \nisNamespaceLoaded(\"fs\")\n\n[1] TRUE\nFinally, I’ll unload the \"fs\" package from the namespace so it can be tested in the debugger.\n\n# remove fs\nunloadNamespace(\"fs\")\n# verify fs has been unloaded\nisNamespaceLoaded(\"fs\")\n\n[1] FALSE\nThe great thing about designing these mini experiments is that they can be quickly converted into testthat tests. I’m now confident I can use the namespace functions to:\n\nView loaded packages namespaces\n\nCheck for a specific package in the loaded namespaces\n\nRequire a package namespace is loaded\n\nRemove a loaded package namespace\n\nThese are the behaviors I want to confirm in check_pkg_ns() using the browser() function."
  },
  {
    "objectID": "posts/debugging/index.html#browser",
    "href": "posts/debugging/index.html#browser",
    "title": "Debugging in RStudio",
    "section": "browser()",
    "text": "browser()\nIf I want to explore the behaviors of the namespace functions in check_pkg_ns(), I need to add browser() somewhere I can ‘step into’ this function and then proceed through line-by-line. In this case, the top of the function makes sense:\n\n\n\n\n\n\n\n\n\n(a) browser() in check_pkg_ns()\n\n\n\n\n\nFigure 1: browser() placement in check_pkg_ns()\n\n\n\n\nDebug mode\nTo enter debugging mode, I’ll need to run check_pkg_ns() or source R/check_pkg_ns.R with the package I used in my experiments.\n\ncheck_pkg_ns(\"fs\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Debug mode\n\n\n\n\n\nFigure 2: RStudio IDE in debug mode\n\n\n\n\nThe browser() function is one of the multiple methods for using RStudio debugging tools (see the TIP callout box below for more).\n\n\n\n\n\n\nTipTIP: Other debugging methods\n\n\n\n\n\n\nIn this post, I focused on using the browser() function to enter debug mode, but RStudio has several built-in tools that can help you debug your R code:\n\nDebug function on error: You can set R to automatically enter the debugger when an error occurs by using options(error = utils::recover). Then, when an error occurs, you’ll be given a menu of places to browse, the most recent (the location where the error occurred) first.\nBreakpoints: Breakpoints can be set in your R scripts to pause execution at a particular line of code. You can add breakpoints by clicking to the left of the line number in the script editor or by pressing Shift+F9 with your cursor on the desired line. Then, run your code. Execution will stop just before the line with the breakpoint, allowing you to inspect the current state of the environment.\ndebug(): You can use debug(function_name) to flag a function for “debug” mode. When you call the function, the debugger will open and stop at the first line of the function, where you can step through the function line by line, inspect the environment, and see what’s happening at each step.\ntraceback(): When an error occurs, you can call traceback() to get a stack trace that shows you the sequence of calls that led up to the error.\nCode Diagnostics: RStudio provides real-time notifications about potential issues in your code, like syntax errors or unused variables. These are not technically part of the debugger, but diagnostics will help you avoid bugs before you run your code.\n\nYou should read this blog post and this chapter of Advanced R, 2nd Ed. for more information on the various debugging methods.\n\n\n\n\n\n\nConsole\nWhen the browser() function is called, the Console enters the ‘reactive browser environment,’ tells me where the debugging function was called from, and changes the prompt to Browse[1]&gt;:\nCalled from: check_pkg_ns(\"fs\")\nBrowse[1]&gt; \nI can use the Console to inspect variables and ‘step through’ the function code.\n\n\n\n\n\n\n\n\n\n\n(a) Debug mode in Console\n\n\n\n\n\nFigure 3: Debug mode with browser() in Console\n\n\n\n\nThe debugger toolbar is also placed at the top of the Console:\n\n\n\n\n\n\n\n\n\n(a) Debug toolbar Console\n\n\n\n\n\nFigure 4: Debug toolbar in Console\n\n\n\nI can use the toolbar or enter the following commands in the Console:\n\nn (next): execute the next step in the function\ns (step into): step into the function call on the current line\nc (continue): continue normal execution without stepping\nf (finish): execute the rest of the current loop or function\nQ (Quit): quit the debugger\n\nI’ll return to the Console in a bit (this is where most of the debugging is done), but let’s view the other changes to the IDE first.\n\n\nSource\nIn the Source pane, we can see the line with browser() has been highlighted with an arrow:\n\n\n\n\n\n\n\n\n\n\n(a) Debug mode in Source\n\n\n\n\n\nFigure 5: Debug mode with browser() in Source\n\n\n\n\nThe Source pane will continually update and highlight my execution position (i.e., what’s going to be executed next) as I ‘step through’ the code.\n*After we’ve finished debugging, it’s important to remember to remove the browser() function so it isn’t triggered the next time it is executed.\n\n\nEnvironment\nThe (Environment) pane is changed from the global environment to the environment of the function that’s currently being executed in the Console:\n\n\n\n\n\n\n\n\n\n\n(a) Debug mode in Environment\n\n\n\n\n\nFigure 6: Debug mode with browser() in Environment\n\n\n\n\nIn the case of check_pkg_ns(), I can see the Values section contains the pkg (\"fs\") and quiet (FALSE) arguments.\n\nOther environments\nThe drop-down list of environments above the Values is arranged in reverse hierarchical order: The Global Environment is listed under the drop-down list, but it’s above the check_pkg_ns() environment in the search path:\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Items in Environment debug mode\n\n\n\n\n\n\n\n\n\n\n\n(b) Package environments and the search path\n\n\n\n\n\n\n\nFigure 7: Environments with debugger\n\n\n\n\n\n\nTraceback\nThe traceback (or ‘call stack’) is the ‘stack’ of functions that have been run thus far:\n\n\n\n\n\n\n\n\n\n(a) Traceback in Environment\n\n\n\n\n\nFigure 8: Environment Traceback viewer\n\n\n\nClicking on an item in traceback will display the environment contents in the function’s code. Right now, it includes the call to source(\"R/check_pkg_ns.R\"), and ‘Debug source’ call to check_pkg_ns(\"fs\").\nIf the Show internals option is selected, the internal functions are shown (slightly subdued in gray).\n\n\n\n\n\n\n\n\n\n(a) Traceback internals\n\n\n\n\n\nFigure 9: Traceback internals\n\n\n\n\n\n\nArguments\nThe pkg argument can be printed to verify it’s contents.\nBrowse[1]&gt; pkg\n[1] \"fs\"\nThe debugger lets me view the state of a function’s values or variables at each execution step, which helps me understand any incorrect or unexpected values.\nBased on the help files and my experiments, check_pkg_ns() should be looking through the namespace to see if a pkg is loaded; if it isn’t, that pkg is loaded in the namespace.\nI can also check the code from the mini experiments inside the debugger Console to see if the fs namespace has been loaded:\nBrowse[1]&gt; isNamespaceLoaded(\"fs\")\n[1] FALSE\nAt my current location in check_pkg_ns(), the fs package hasn’t been loaded.\n\n\nStepping through\nI can begin ‘stepping through’ check_pkg_ns() by entering n in the Console:\nBrowse[1]&gt; n\nNotice after the entering n in the Console, the debugger tells me where the browser() function has paused execution (debug at /path/to/function/file.R), the line number (#27), and the check_pkg_ns() function is printed to console (I’ve omitted it here):\nBrowse[1]&gt; n\ndebug at ~/projects/apps/dbap/R/check_pkg_ns.R#27:\n\n&lt;...check_pkg_ns() function...&gt;\n\nBrowse[2]&gt;\nThe prompt also changes from Browse[1]&gt; to Browse[2]&gt; to let me know I’m inside the check_pkg_ns() function.\nI’ll use n (or Next) to continue following the path pkg takes through the function:\n\n\n\n\n\n\n\n\n\n\n(a) Use Console to step through function\n\n\n\n\n\nFigure 10: Use n to step through check_pkg_ns()\n\n\n\n\nWhen I land on the line after the call to requireNamespace(), I can check to see if the fs namespace has been loaded with isNamespaceLoaded(\"fs\")\nBrowse[2]&gt; isNamespaceLoaded(\"fs\")\n[1] TRUE\n\n\nInspect values\nNow that I’ve confirmed check_pkg_ns() works with fs, I should also confirm it works with a development package (i.e., not on CRAN). I can test this with the roxygen2Comment package–it contains an addin for pasting roxygen2 comment blocks.\nTo quit debug mode, I can enter Q in the Console or click on the red square (Stop) icon in the toolbar.\nBrowse[2]&gt; Q\nI’ll confirm roxygen2Comment is not loaded with isNamespaceLoaded(), then change the pkg argument in check_pkg_ns() and re-run the function\nisNamespaceLoaded(\"roxygen2Comment\")\n[1] FALSE\n&gt; check_pkg_ns(\"roxygen2Comment\")\nCalled from: check_pkg_ns(\"roxygen2Comment\")\nBrowse[1]&gt; \nThis time, when I step through check_pkg_ns(), I notice pkg takes an alternative path:\n\n\n\n\n\n\n\n\n\n\n(a) Alternative path through function\n\n\n\n\n\nFigure 11: Development package in check_pkg_ns()\n\n\n\n\nWhen the Source pane highlights the stop() function, I can check to confirm this package wasn’t loaded:\nBrowse[2]&gt; isNamespaceLoaded(\"roxygen2Comment\")\n[1] FALSE\nIf I enter n one more time in the Console, I see the stop() error from the function is returned:\nBrowse[2]&gt; n\nError in check_pkg_ns(\"roxygen2Comment\") : \n  roxygen2Comment not available\nI’ll perform one last check on check_pkg_ns(): what if I want to pass multiple packages to pkg? I’ll check this with fs and box.\n\n# First make sure these aren't loaded...\nunloadNamespace(\"fs\")\nunloadNamespace(\"box\")\n# Now combine into vector\npkgs &lt;- c(\"fs\", \"box\")\ncheck_pkg_ns(pkgs)\n\nAfter entering debug mode, I want to proceed to the control flow and verify the pkgs variable:\n&gt; check_pkg_ns(pkgs)\nCalled from: check_pkg_ns(pkgs)\nBrowse[1]&gt; n\nBrowse[2]&gt; pkgs\n[1] \"fs\"  \"box\"\nThis confirms both packages are in the pkg variable. If I use n to proceed through to end of check_pkg_ns(), I see the final line returns the successful loading message twice:\nBrowse[2]&gt; n\nLoading package: fs\nLoading package: box\n\n\nbrowser() recap\nOnce execution is paused with browser(), using the n command in the Console (or in the debugging toolbar at the top-right of the pane) lets me step through the code line-by-line.\n\n\n\n\n\n\n\n\n\n(a) Step through/over\n\n\n\n\n\nFigure 12: Step through/over code\n\n\n\nThis allows me to inspect the state of the variables at various points within a function."
  },
  {
    "objectID": "posts/debugging/index.html#nested-functions",
    "href": "posts/debugging/index.html#nested-functions",
    "title": "Debugging in RStudio",
    "section": "Nested functions",
    "text": "Nested functions\nThe check_pkg_ns() function is fairly basic in that it performs a single ‘unit of work’ (i.e., check if add-on packages package have been loaded and attached; if not, load and attach them). When functions become more complex, it’s more efficient to use nested functions–i.e., functions within other functions–which allow me to execute multiple commands simultaneously.\nAn example of this is the pkg_data_results() function below:\n\n\npkg_data_results()\npkg_data_results(\"dplyr\")\n## # A tibble: 5 × 3\n##   Package Item              Title              \n##   &lt;chr&gt;   &lt;chr&gt;             &lt;chr&gt;              \n## 1 dplyr   band_instruments  Band membership    \n## 2 dplyr   band_instruments2 Band membership    \n## 3 dplyr   band_members      Band membership    \n## 4 dplyr   starwars          Starwars characters\n## 5 dplyr   storms            Storm tracks data\n\n\npkg_data_results() returns a data.frame with three columns: Package, Item, and Title.\nThe output from pkg_data_results() comes from the data(package = \"pkg\") output:\n\n\n\n\n\n\n\n\n\n(a) Output from data(package = )\n\n\n\n\n\nFigure 13: data(package = \"dplyr\")\n\n\n\nThis output is normally opened in a separate window, but it’s created as a matrix.\n\n\nstructure of data(package =)\nstr(data(package = \"dplyr\"))\n## List of 4\n##  $ title  : chr \"Data sets\"\n##  $ header : NULL\n##  $ results: chr [1:5, 1:4] \"dplyr\" \"dplyr\" \"dplyr\" \"dplyr\" ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:4] \"Package\" \"LibPath\" \"Item\" \"Title\"\n##  $ footer : NULL\n##  - attr(*, \"class\")= chr \"packageIQR\"\n\n\npkg_data_results() converts the matrix output into a data.frame three columns in (Package, Title, Item).\nI’ve placed browser() at the top of pkg_data_results() and run it with the fivethirtyeight package.\npkg_data_results(\"fivethirtyeight\")\n\n\n\n\n\n\n\n\n\n(a) browser() in pkg_data_results(“fivethirtyeight”)\n\n\n\n\n\nFigure 14: browser() in pkg_data_results(\"fivethirtyeight\")\n\n\n\n\nStep into\nWhen the debugger lands on check_pkg_ns(), I can follow the fivethirtyeight package through this function by ‘stepping into’ this function by entering s in the Console (or the toolbar icon):\n\n\n\n\n\nStep into a function\n\n\n\n\n\n\n\n\n\n\n\n(a) browser() in pkg_data_results(“fivethirtyeight”)\n\n\n\n\n\nFigure 15: Step into in pkg_data_results(\"fivethirtyeight\")\n\n\n\n\n\nDebugging ‘at’ vs ‘in’\nIn the Console, there are now debugging in and debug at locations:\nBrowse[2]&gt; s\ndebugging in: check_pkg_ns(pkg = pkg, quiet = TRUE)\ndebug at /apps/dbap/R/check_pkg_ns.R#25: \nThe debug at location is the the we location of the initial call to browser(), and debugging in is the function I stepped into.\nThe prompt has also changed from Browse[2]&gt; to Browse[3]&gt;:\nBrowse[3]&gt;\n\n\n\n\n\n\n\n\n\n\n(a) Use s to step into check_pkg_ns()\n\n\n\n\n\nFigure 16: Use s to step through check_pkg_ns()\n\n\n\n\nThe R/check_pkg_ns.R file will open with the highlighted function. I can proceed through check_pkg_ns() using n until I reach requireNamespace():\n\n\n\n\n\n\n\n\n\n\n(a) Use n to step through check_pkg_ns()\n\n\n\n\n\nFigure 17: Use n to step through check_pkg_ns()\n\n\n\n\nWhen I reach the final line in check_pkg_ns(), I can use either method below verify the pkg namespace is loaded:\nBrowse[3]&gt; pkg %in% loadedNamespaces()\n[1] TRUE\nBrowse[3]&gt; isNamespaceLoaded(pkg)\n[1] TRUE\nAfter the last line of check_pkg_ns() has been evaluated, the debugger will automatically return to the pkg_data_results() function. The Source pane will highlight the final step (and the prompt returns to Browse[2]&gt;):\n\n\n\n\n\n\n\n\n\n\n(a) Step into/through check_pkg_ns() from pkg_data_results()\n\n\n\n\n\nFigure 18: Step into and through check_pkg_ns() from pkg_data_results()\n\n\n\n\nA final n command in the Console will return the output table:\nBrowse[2]&gt; n\n### A tibble: 129 × 3\n##    Package         Item                Title\n##    &lt;chr&gt;           &lt;chr&gt;               &lt;chr&gt;\n##  1 fivethirtyeight US_births_1994_2003 Some People Are Too Superstitious To …\n##  2 fivethirtyeight US_births_2000_2014 Some People Are Too Superstitious To …\n##  3 fivethirtyeight ahca_polls          American Health Care Act Polls\n##  4 fivethirtyeight airline_safety      Should Travelers Avoid Flying Airline…\n##  5 fivethirtyeight antiquities_act     Trump Might Be The First President To…\n##  6 fivethirtyeight august_senate_polls How Much Trouble Is Ted Cruz Really  …\n##  7 fivethirtyeight avengers            Joining The Avengers Is As Deadly As\n##  8 fivethirtyeight bachelorette        Bachelorette / Bachelor\n##  9 fivethirtyeight bad_drivers         Dear Mona, Which State Has The Worst …\n## 10 fivethirtyeight bechdel             The Dollar-And-Cents Case Against Hol…\n## # ℹ 119 more rows\n## # ℹ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "posts/debugging/index.html#put-it-all-together",
    "href": "posts/debugging/index.html#put-it-all-together",
    "title": "Debugging in RStudio",
    "section": "Put it all together",
    "text": "Put it all together\nThe initial pkg_data_str() function for returning a table of ‘package data structures’ is below.\n\n\nexpand to see initial pkg_data_str()\npkg_data_str &lt;- function(pkg) {\n\n  data_results &lt;- pkg_data_results(pkg = pkg)\n\n  ds_list &lt;- purrr::map2(\n    .x = data_results[[\"Item\"]], \n    .y = data_results[[\"Package\"]],\n    .f = pkg_data_object, .progress = TRUE\n  )\n\n  cols_tbl &lt;- dplyr::mutate(data_results,\n    Class = purrr::map(.x = ds_list, .f = class) |&gt;\n      purrr::map(paste0, collapse = \", \") |&gt; unlist(),\n    Columns = purrr::map(.x = ds_list, .f = ncol) |&gt;\n      purrr::map(paste0, \" columns\") |&gt; unlist(),\n    Rows = purrr::map(.x = ds_list, .f = nrow) |&gt;\n      purrr::map(paste0, \" rows\") |&gt; unlist(),\n    Logical = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"log\"\n    ) |&gt; unlist(),\n    Numeric = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"num\"\n    ) |&gt; unlist(),\n    Character = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"chr\"\n    ) |&gt; unlist(),\n    Factor = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"fct\"\n    ) |&gt; unlist(),\n    List = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"lst\"\n    ) |&gt; unlist(),\n  )\n\n  pkg_tbls_dfs &lt;- dplyr::filter(cols_tbl,\n    stringr::str_detect(Class, \"data.frame\")\n  )\n\n  return(pkg_tbls_dfs)\n}\n\n\npkg_data_str() uses nested functions to create the following intermediate objects I can check while developing with browser() (the example below uses the forcats package)\n\nData results\nThe output from pkg_data_results() is stored in data_results:\n\ndata_results &lt;- pkg_data_results(pkg = pkg)\n\nBrowse[2]&gt; data_results\n# A tibble: 1 × 3\n  Package Item    Title                                                           \n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;                                                           \n1 forcats gss_cat A sample of categorical variables from the General Social su...\n\n\nPackage data objects\nAfter extracting the Package, Title, and Type columns from pkg_data_results(), I use purrr:map2() to iterate over each Item and Package, which builds a list of datasets (ds_list). The .f argument is a nested pkg_data_object() function, which calls base::get().\n\nds_list &lt;- purrr::map2(\n  .x = data_results[[\"Item\"]],\n  .y = data_results[[\"Package\"]],\n  .f = pkg_data_object, .progress = TRUE\n)\n\nI’ll view the contents of the list with str()\nBrowse[2]&gt; str(ds_list)\nList of 1\n $ : tibble [21,483 × 9] (S3: tbl_df/tbl/data.frame)\n  ..$ year   : int [1:21483] 2000 2000 2000 2000 2000 2000 2000 2000 ...\n  ..$ marital: Factor w/ 6 levels \"No answer\",\"Never married\",..: 2 4 ...\n  ..$ age    : int [1:21483] 26 48 67 39 25 25 36 44 44 47 ...\n  ..$ race   : Factor w/ 4 levels \"Other\",\"Black\",..: 3 3 3 3 3 3 3 3 3 3 ...\n  ..$ rincome: Factor w/ 16 levels \"No answer\",\"Don't know\",..: 8 8 16 16 ...\n  ..$ partyid: Factor w/ 10 levels \"No answer\",\"Don't know\",..: 6 5 7 6  ...\n  ..$ relig  : Factor w/ 16 levels \"No answer\",\"Don't know\",..: 15 15 15 ...\n  ..$ denom  : Factor w/ 30 levels \"No answer\",\"Don't know\",..: 25 23 3 ...\n  ..$ tvhours: int [1:21483] 12 NA 2 4 1 NA 3 NA 0 3 ...\n\n\nColumn counts\nThe ds_list created above is used to add the Class, Columns, and Rows columns to data_results using the class(), ncol(), nrow(). The column counts are added with the col_type_count() function.\n\n  cols_tbl &lt;- dplyr::mutate(data_results,\n    Class = purrr::map(.x = ds_list, .f = class) |&gt;\n      purrr::map(paste0, collapse = \", \") |&gt; unlist(),\n    Columns = purrr::map(.x = ds_list, .f = ncol) |&gt;\n      purrr::map(paste0, \" columns\") |&gt; unlist(),\n    Rows = purrr::map(.x = ds_list, .f = nrow) |&gt;\n      purrr::map(paste0, \" rows\") |&gt; unlist(),\n    Logical = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"log\"\n    ) |&gt; unlist(),\n    Numeric = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"num\"\n    ) |&gt; unlist(),\n    Character = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"chr\"\n    ) |&gt; unlist(),\n    Factor = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"fct\"\n    ) |&gt; unlist(),\n    List = purrr::map(\n      .x = ds_list,\n      .f = col_type_count, \"lst\"\n    ) |&gt; unlist(),\n  )\n\nBrowse[2]&gt; cols_tbl\n# A tibble: 1 × 11\n  Package Item    Title          Class Columns Rows  Logical Numeric Character Factor  List\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt; &lt;int&gt;\n1 forcats gss_cat A sample of c… tbl_… 9 colu… 2148…       0       3         0      6     0\n\n\nRectangular objects\nFinally, cols_tbl is filtered to only those objects with a class() containing the string ‘data.frame’.\n\npkg_tbls_dfs &lt;- dplyr::filter(.data = cols_tbl,\n                  stringr::str_detect(Class, \"data.frame\"))\n\nThis is exactly the same as the previous tibble because forcats has only one data object (gss_cat), and it’s a tibble:\nBrowse[2]&gt; pkg_tbls_dfs\n# A tibble: 1 × 11\n  Package Item    Title          Class Columns Rows  Logical Numeric Character Factor  List\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt; &lt;int&gt;\n1 forcats gss_cat A sample of c… tbl_… 9 colu… 2148…       0       3         0      6     0\nI’m explicitly returning pkg_tbls_dfs to view it in the debugger. When I’m confident it’s behaving as expected, I’ll remove this final object and ‘rely on R to return the result of the last evaluated expression.’\n\n\nError!\nWhen I tried using the initial pkg_data_str() with a package that had zero data objects (fs), I get the following error:\n\npkg_data_str(\"fs\")\n\nError in `dplyr::filter()` at dbap/R/pkg_data_str.R:78:2:\nℹ In argument: `stringr::str_detect(Class, \"data.frame\")`.\nCaused by error in `vctrs::vec_size_common()`:\n! object 'Class' not found\nRun `rlang::last_trace()` to see where the error occurred.\nIn the debugger, I was able to pinpoint the source of this error (and the underlying condition causing it to occur).\n\nReplicate the error\nThe browser() beings at the top of pkg_data_str(), where I’ll step into pkg_data_results()\n\n\n\n\n\n\n\n\n\n\n(a) pkg_data_results() from pkg_data_str()\n\n\n\n\n\nFigure 19: Step into pkg_data_results() from pkg_data_str()\n\n\n\n\nWhen I’m inside pkg_data_results(), I’ll use n to verify the fs package namespace was loaded and the tibble was created:\n\n\n\n\n\n\n\n\n\n\n(a) Step through pkg_data_results()\n\n\n\n\n\nFigure 20: Step through pkg_data_results() (from pkg_data_str())\n\n\n\n\nBack in pkg_data_str(), the output from pkg_data_results() is stored as data_results. I can check the contents of data_results in the Console.\nBrowse[2]&gt; data_results\n# A tibble: 0 × 3\n# ℹ 3 variables: Package &lt;chr&gt;, Item &lt;chr&gt;, Title &lt;chr&gt;\nI see it’s empty. An empty data_results results in an empty list output from purrr::map2():\n\n\n\n\n\n\n\n\n\n\n(a) Step out of pkg_data_results()\n\n\n\n\n\nFigure 21: Step out of pkg_data_results() back into pkg_data_str()\n\n\n\n\nBrowse[2]&gt; ds_list\nlist()\nThe empty ds_list results in dplyr::mutate() being unable to create the Class column in cols_tbl:\n\n\n\n\n\n\n\n\n\n\n(a) dplyr::mutate() call in get_ds_strs()\n\n\n\n\n\nFigure 22: Create Class column in get_ds_strs()\n\n\n\n\nBrowse[2]&gt; cols_tbl\n# A tibble: 0 × 3\n# ℹ 3 variables: Package &lt;chr&gt;, Item &lt;chr&gt;, Title &lt;chr&gt;\nWhich triggers the error in dplyr::filter()\nBrowse[2]&gt; n\nError in `dplyr::filter()` at dbap/R/get_ds_str.R:60:2:\nℹ In argument: `stringr::str_detect(Class, \"data.frame\")`.\nCaused by error in `vctrs::vec_size_common()`:\n! object 'Class' not found\nRun `rlang::last_trace()` to see where the error occurred.\nThe full path for the fs package through the initial get_ds_str() is outlined in the figure below:\n\n\n\n\n\n\n\n\n\n\n(a) Error path in get_ds_strs()\n\n\n\n\n\nFigure 23: Replicate the error from get_ds_strs()\n\n\n\n\n\n\n\nSolution\nTo fix this error, I had to make some changes to both pkg_data_results() and pkg_data_str():\nIn pkg_data_results(), I added control flow to return a tibble of logical columns (all NA) if the package doesn’t have any data objects:\n\n\nExpand to view the updated pkg_data_results()\npkg_data_results &lt;- function(pkg) {\n  # load packages\n  check_pkg_ns(pkg = pkg, quiet = TRUE)\n\n  results &lt;- tibble::as_tibble(\n    data.frame(\n      Package = data(package = pkg)$results[, \"Package\"],\n      Item = data(package = pkg)$results[, \"Item\"],\n      Title = data(package = pkg)$results[, \"Title\"],\n      stringsAsFactors = FALSE,\n      check.names = FALSE,\n      row.names = NULL\n    )\n  )\n\n  if (nrow(results) == 0) {\n\n  data_results &lt;- tibble::as_tibble(\n    data.frame(\n        matrix(\n            nrow = 1, ncol = 11,\n            byrow = TRUE,\n            dimnames = list(NULL,\n              c(\"Package\", \"Item\", \"Title\",\n                \"Class\", \"Columns\", \"Rows\",\n                \"Logical\", \"Numeric\", \n                \"Character\", \"Factor\", \n                \"List\"))\n                ),\n        row.names = NULL))\n\n    return(data_results)\n\n\n  } else {\n\n    results\n\n  }\n\n}\n\n\nIn pkg_data_str(), I added two if statements:\n\nthe first if statement identifies the logical NA columns (indicating the results from data(package = pkg) didn’t have any data objects)\nthe second if statement creates the Class column first, then filters the rows to only those containing a data.frame string pattern. If none of the data objects have the data.frame string pattern in their class, an empty data_results table is returned\n\n\n\nExpand to view the updated pkg_data_str()\npkg_data_str &lt;- function(pkg) {\n  \n  data_results &lt;- pkg_data_results(pkg = pkg)\n  \n  if (!is.logical(data_results[[\"Item\"]])) {\n    # data_results contains data objects\n    ds_list &lt;- purrr::map2(\n      .x = data_results[[\"Item\"]], \n      .y = data_results[[\"Package\"]],\n      .f = pkg_data_object, .progress = TRUE\n    )\n\n    class_tbl &lt;- dplyr::mutate(data_results,\n      Class = purrr::map(.x = ds_list, .f = class) |&gt;\n        purrr::map(paste0, collapse = \", \") |&gt; unlist()\n    )\n\n    df_tbl &lt;- dplyr::filter(\n      class_tbl,\n      stringr::str_detect(Class, \"data.frame\")\n    )\n\n    if (nrow(df_tbl) == 0) {\n      # df_tbl does not contain 'data.frame' classes\n      data_results &lt;- tibble::as_tibble(\n        data.frame(\n          matrix(\n            nrow = 1, ncol = 11,\n            byrow = TRUE,\n            dimnames = list(\n              NULL,\n              c(\n                \"Package\", \"Item\", \"Title\",\n                \"Class\", \"Columns\", \"Rows\",\n                \"Logical\", \"Numeric\", \"Character\",\n                \"Factor\", \"List\"\n              )\n            )\n          ),\n          row.names = NULL\n        )\n      )\n\n      return(data_results)\n      \n    } else {\n      \n      # df_tbl contains 'data.frame' classes\n      dplyr::mutate(df_tbl,\n        Columns = purrr::map(.x = ds_list, .f = ncol) |&gt;\n          purrr::map(paste0, \" columns\") |&gt; unlist(),\n        Rows = purrr::map(.x = ds_list, .f = nrow) |&gt;\n          purrr::map(paste0, \" rows\") |&gt; unlist(),\n        Logical = purrr::map(\n          .x = ds_list,\n          .f = col_type_count, \"log\") |&gt; unlist(),\n        Numeric = purrr::map(\n          .x = ds_list,\n          .f = col_type_count, \"num\") |&gt; unlist(),\n        Character = purrr::map(\n          .x = ds_list,\n          .f = col_type_count, \"chr\") |&gt; unlist(),\n        Factor = purrr::map(\n          .x = ds_list,\n          .f = col_type_count, \"fct\") |&gt; unlist(),\n        List = purrr::map(\n          .x = ds_list,\n          .f = col_type_count, \"lst\") |&gt; unlist())\n      \n    }\n    \n  } else {\n    \n    # data_results does not contains data objects\n    return(data_results)\n    \n  }\n  \n}\n\n\nRather than go through the debugger process again, I’ll go through each of the the mini experiments I used to check the updated pkg_data_results() and pkg_data_str() functions:\n\nCheck single package without any data objects (box)\n\nknitr::kable(\n  pkg_data_str(\"box\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nItem\nTitle\nClass\nColumns\nRows\nLogical\nNumeric\nCharacter\nFactor\nList\n\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\nCheck single package with data objects, but none with classes that contain data.frame (stringr)\n\nknitr::kable(\npkg_data_str(\"stringr\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nItem\nTitle\nClass\nColumns\nRows\nLogical\nNumeric\nCharacter\nFactor\nList\n\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\nCheck single package with multiple data objects (dplyr)\n\nknitr::kable(\npkg_data_str(\"dplyr\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nItem\nTitle\nClass\nColumns\nRows\nLogical\nNumeric\nCharacter\nFactor\nList\n\n\n\n\ndplyr\nband_instruments\nBand membership\ntbl_df, tbl, data.frame\n2 columns\n3 rows\n0\n0\n2\n0\n0\n\n\ndplyr\nband_instruments2\nBand membership\ntbl_df, tbl, data.frame\n2 columns\n3 rows\n0\n0\n2\n0\n0\n\n\ndplyr\nband_members\nBand membership\ntbl_df, tbl, data.frame\n2 columns\n3 rows\n0\n0\n2\n0\n0\n\n\ndplyr\nstarwars\nStarwars characters\ntbl_df, tbl, data.frame\n14 columns\n87 rows\n0\n3\n8\n0\n3\n\n\ndplyr\nstorms\nStorm tracks data\ntbl_df, tbl, data.frame\n13 columns\n19537 rows\n0\n11\n1\n1\n0\n\n\n\n\n\nCheck multiple packages with multiple data objects (dplyr, forcats and lubridate)\n\nknitr::kable(\npkg_data_str(c(\"dplyr\", \"forcats\", \"lubridate\")))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nItem\nTitle\nClass\nColumns\nRows\nLogical\nNumeric\nCharacter\nFactor\nList\n\n\n\n\nforcats\ngss_cat\nA sample of categorical variables from the General Social survey\ntbl_df, tbl, data.frame\n9 columns\n21483 rows\n0\n3\n0\n6\n0\n\n\nlubridate\nlakers\nLakers 2008-2009 basketball data set\ndata.frame\n13 columns\n34624 rows\n0\n5\n8\n0\n0\n\n\ndplyr\nband_instruments\nBand membership\ntbl_df, tbl, data.frame\n2 columns\n3 rows\n0\n0\n2\n0\n0\n\n\ndplyr\nband_instruments2\nBand membership\ntbl_df, tbl, data.frame\n2 columns\n3 rows\n0\n0\n2\n0\n0\n\n\ndplyr\nband_members\nBand membership\ntbl_df, tbl, data.frame\n2 columns\n3 rows\n0\n0\n2\n0\n0\n\n\ndplyr\nstarwars\nStarwars characters\ntbl_df, tbl, data.frame\n14 columns\n87 rows\n0\n3\n8\n0\n3\n\n\ndplyr\nstorms\nStorm tracks data\ntbl_df, tbl, data.frame\n13 columns\n19537 rows\n0\n11\n1\n1\n0"
  },
  {
    "objectID": "posts/debugging/index.html#recap",
    "href": "posts/debugging/index.html#recap",
    "title": "Debugging in RStudio",
    "section": "Recap",
    "text": "Recap\nRStudio’s debugger is a powerful tool that can save tons of time when you’re developing new functions, discovering how a function’s code is executed, or dealing with errors. When you’ve finished debugging, remember to remove the browser() call from your function.\nThe steps above should help get you started, and if you’d like to learn more, check out the debugging chapter of Advanced R, and the documentation for browser(), debug()/debugonce()/undebug(), and traceback() functions."
  },
  {
    "objectID": "posts/positron-v1/index.html",
    "href": "posts/positron-v1/index.html",
    "title": "Positron",
    "section": "",
    "text": "I’ve been trying out Posit’s new Positron IDE for a few weeks, so I put together a post covering my initial impressions of developing Shiny apps and R packages."
  },
  {
    "objectID": "posts/positron-v1/index.html#why-switch",
    "href": "posts/positron-v1/index.html#why-switch",
    "title": "Positron",
    "section": "Why switch?",
    "text": "Why switch?\nI use RStudio daily for R development and have no complaints about the IDE’s capabilities. However, I’ve recently started using VS Code for Python and JavaScript. When I heard about Positron, I wondered if it would offer enough overlapping features to allow me to use a single IDE for all three languages.\nPositron was covered at posit::conf(2024), and the Getting Started article on the new website lists reasons you might (or might not) want to switch IDEs. I’ve summarized them below:\n\n\n\nSwitch\n\nYou use VS Code or JupyterLab for data science but want more features.\nYou want more customization in RStudio.\nYou program in languages other than R/Python.\n\n\n\nDon’t switch\n\nYou need reliable and fully functioning software (Positron is still a work-in-progress, so some features may not be stable or polished).\nYou need all RStudio’s features (i.e., inline output for Quarto and R Markdown, Sweave, Add-In support, profiling, etc.). Not all these features are implemented in Positron.\n\n\n\n\n\n\n\n\n\n\n\nTipDownload and Install Positron\n\n\n\n\n\n\nPositron now has a website with much of the information below (without the screenshots).\nPositron can be downloaded from it’s GitHub repository. I’m running it on my MacBook (2019, 2.6 GHz 6-Core Intel Core i7, macOS Sonoma Version 14.5), so this involved downloading the .dmg file from the releases page and installing it like I would any new application.1"
  },
  {
    "objectID": "posts/positron-v1/index.html#ide-layout",
    "href": "posts/positron-v1/index.html#ide-layout",
    "title": "Positron",
    "section": "IDE Layout",
    "text": "IDE Layout\n\n\n\n\n\n\nNoteNOTE\n\n\n\n\n\n\nThroughout this post, I’ll make the assumption the reader hasn’t spent much time in VS Code (if you have, Positron will be easier to navigate and use).\n\n\n\n\n\nAt first glance, Positron looks like VS Code, but with the four panes we’re used to seeing in RStudio. The default layout includes a Welcome pane with options for opening files and folders above the Panel, which displays the current version of R running:\n\n\n\n\n\n\n\n\n\n\n\nWelcome page\n\n\n\n\n\n\n\n\n\n\n\nConsole\n\n\n\n\n\n\nThe Panel is similar to the Console in RStudio but also includes tabs for Terminal, Problems, Output, etc.\n\n\n\n\n\n\n\n\n\n\nPositron’s panel (click to enlarge)\n\n\n\n\n\n\n\n\n\n\n\nRStudio’s console (click to enlarge)\n\n\n\n\n\nThe Session and Variables2 panes are open and initially empty, but we can see this where our Plots will be displayed.\n\n\n\n\n\n\n\n\nSession and Variables (click to enlarge)\n\n\n\n\nLayout options\nTo customize Positron’s panes, we can use the layout presets icon (in the upper-right corner of the IDE).\n\n\n\n\n\n\n\n\n\nLayout presets icon\n\n\n\n\n\n\n\n\n\nLayout outptions (click to enlarge)\n\n\nOr we can position each pane manually via View &gt; Appearance &gt; Panel Position …\n\n\n\n\n\n\n\nPositron’s view options (click to enlarge)\n\n\nWe’ll continue using the default ‘Stacked Layout’ configuration in this post, but I recommend exploring the other options to find a customization that fits your needs.\n\n\nR & Python versions\nI had R (R 4.4.1) and Python (3.11.5) previously installed, and Positron quickly located both R and Python versions (and displays them in multiple places in the IDE):\n\n\n\n\n\n\n\n\nR versions (click to enlarge)\n\n\n\nFor more information on detecting Python and R versions, see the Interpreter Selection section of the documentation.\n\n\nR Dependencies\nPositron’s documentation recommends installing the following packages:3\n\npak::pak(c(\"usethis\", \"cli\", \"crayon\", \n           \"rlang\", \"roxygen2\", \"pkgload\"))\n\n\n\nFiles, Folders and Projects\nI use the folder icon in the upper right corner of the IDE to locate and open project folders. Still, Positron has multiple options for opening project folders from the welcome page and with the explorer sidebar menu item:\n\n\n\n\n\n\n\n\nOpen folder (click to enlarge)\n\n\n\nI’ll be using my sap repository because it contains the following:\n\nVersion control\n\nAn R project (i.e., with an .Rproj file)\n\nA Shiny app\n\nAn R package4\n\n\n\nActivity bar\nOne of Positron’s major distinguishing factors is its activity bar. This sidebar lets us open and edit files, perform searches, access source control (like Git), and find/install extensions.\n\n\n\n\n\n\n\nPositron Layout (click to enlarge)\n\n\nI’ll briefly cover a few of Positron’s sidebar menu items in the sections below.\n\nExplorer\n\n\n\n \n\n\n\n\n\nAs noted above, the Explorer menu item can open project files and folders.\n\n\n\nThis closely resembles the Files pane in RStudio.\n\n\n\n\n\n\n\n\n\n\nShiny app files (click to enlarge)\n\n\n\n\n\n\n\n\n\n\n\nRStudio Files Pane (click to enlarge)\n\n\n\n\n\nClicking on files in the Explorer will open them in the Editor. After opening files, the cursor location will also display additional information on hover (i.e., version control information):\n\n\n\nHover information in Editor (click to enlarge)\n\n\n\n\nSearch\n\n\n\n \n\n\n\n\n\n\n\n\n\nThe Search menu item allows us to find and replace across all files.\n\n\n\nSimilar to the Find in Files (Ctrl + Shift + F) window in RStudio.\n\n\n\n\n\n\n\n\n\n\nSearch and replace (click to enlarge)\n\n\n\n\n\n\n\n\n\n\n\nRStudio ‘Find in Files’ (click to enlarge)\n\n\n\n\n\n\n\nSource Control\n\n\n\n \n\n\n\n\n\n\n\n\n\nThe Source Control menu can open local Git folders and clone repositories.\n\n\n\nWhen in a Git repo, it displays Git commits, branches, remotes, stashes, tags, work trees, and contributors (similar to the Git pane in RStudio).\n\n\n\n\n\n\n\n\n\n\nSource control menu (click to enlarge)\n\n\n\n\n\n\n\n\n\n\n\nRStudio Git Pane (click to enlarge)\n\n\n\n\n\nIn RStudio, I still use the Terminal for ~90% of my interactions with Git, but Positron also comes with a Source Control menu.5\n\n\n\n\n\n\n\nChecking out Git branch with Source Control (click to enlarge)\n\n\n\n\nExtensions\n\n\n\n \n\n\n\n\n\n\n\n\n\nWe can install Positron extensions from the Extensions menu item.\n\n\n\nPositron’s extensions are somewhat similar to RStudio Addins but with a few key differences:\n\nPositron extensions enhance the IDE’s capabilities by interacting with the VS Code API. They can range from language support (e.g., R, Python) to tools and features for general coding tasks (debugging, version control, syntax highlighting, code snippets, etc.)\nRStudio Addins are custom tools and features to extend IDE’s functionality, focusing on R-specific tasks (package development, customizing visualizations, R markdown document generation, etc.)\n\n\n\n\n\n\n\n\n\n\n\nPositron Extensions via Positron +1e (click to enlarge)\n\n\n\n\n\n\n\n\n\n\n\nRStudio Addins (click to enlarge)\n\n\n\n\n\nAt a minimum, be sure to install the Posit Publisher extension. I’ve also installed Positron +1e, a collection of extensions curated by Garrick Aden-Buie6 for ‘git-backed data science and dev work shared primarily on GitHub’.\n\n\n\n\n\n\nTipPositron Extensions\n\n\n\n\n\n\nExtensions can be installed from VS Code Marketplace or the Open VXS Registry. VS Code Marketplace is maintained by Microsoft, ensuring high-quality and secure extensions, whereas the Open VXS Registry is an open-source alternative for those looking to avoid vendor lock-in.7 Most extensions on Open VXS Registry are identical to those found on the VS Code marketplace, but with a focus on open-source principles.\nFor more Positron extensions, I recommend checking out this post from Andrew Heiss8 and this LinkedIn post from Veerle van Leemput.9"
  },
  {
    "objectID": "posts/positron-v1/index.html#shiny-apps",
    "href": "posts/positron-v1/index.html#shiny-apps",
    "title": "Positron",
    "section": "Shiny Apps",
    "text": "Shiny Apps\nI’ve checked out a branch of sap that’s in the early stages of development, so it’s a Shiny app (and not an R package yet).10 The image below highlights some of the IDE’s features after opening the app.R file:\n\n\n\n\n\n\n\nOpen app.R file (click to enlarge)\n\n\n\n\nPositron displays the current folder (or project) in a familiar location, and the active Git branch and Quarto version are conveniently placed in the footer.\nAs we can see from the image above, Positron displays much of the same information as the RStudio IDE but with a VS Codeish layout. The most notable change I had to adapt to was the new location of the project files in the file Explorer.\n\nRunning Applications\nPositron detects that I’m developing a Shiny application and places a Run Shiny App icon at the top of the app.R file. Clicking the Run Shiny App button launches our application in the Viewer pane.\n\n\n\n\n\n\n\nTerminal runs the Shiny app (click to enlarge)\n\n\n\n\n\n\n\n\n\nUnlike RStudio, Positron runs Shiny applications from the Terminal with a dedicated Shiny process when the Run Shiny App button is clicked.\nIn the Terminal, a message tells us that autoreload has been turned on (which means we can make live updates to our application):\n\n\n\n\n\n\n\n\nLive updates to Shiny app\n\n\n\nWe’re also told that the application runs with the ‘minified’ JavaScript file (shiny.min.js), which results in using --devmode. Both of these options are covered in the Shiny documentation.\n\n\n\n\n\n\nTipRun Shiny App Terminal Commands\n\n\n\n\n\n\nI’ve broken down the Shiny terminal commands below:\nThe first commands specifies the Rscript interpreter, the scripting front-end for R. Rscript allows the execution of R scripts directly from the command line.\n# Rscript interpreter \n$/usr/local/bin/Rscript \nThe next command is the path to an R script that comes with your Positron installation for running Shiny applications.\n# runShinyApp.R Positron Shiny extension  \n$/Users/username/.positron/extensions/posit.shiny-1.0.0-universal/rscripts/runShinyApp.R \nYou can view the contents of runShinyApp.R by passing the path into another Terminal window preceded by cat.\nThe final Terminal command is the path to the moviesApp Shiny application’s main app.R script (with two additional arguments):\n# moviesApp app.R file\n/Users/username/projects/apps/R/moviesApp/app.R 51146 --devmode \n\n51146 specifies the port on which the Shiny application will run.\n--devmode enables development mode for the Shiny application.11\n\n\n\n\n\n\n\nStopping Applications\nWe can stop the application like we would any other Terminal process:\n\n\n\n\nCtrl + C\n\n\n\n\nAfter stopping the application, you can clear the Viewer by clicking on the Clear the current URL icon in the upper-right corner.\n\n\n\n\n\n\n\nClear viewer (click to enlarge)\n\n\nThese changes make application development much more seamless, and now the app.R file also includes icon for editing our Shiny UI with the shinyuieditor package (provided it’s installed).\n\n\n\n\n\n\n\nRun Shiny App Options"
  },
  {
    "objectID": "posts/positron-v1/index.html#package-development",
    "href": "posts/positron-v1/index.html#package-development",
    "title": "Positron",
    "section": "Package Development",
    "text": "Package Development\nTransitioning from developing R packages in RStudio to Positron has been pretty smooth. For example, I wanted to change the display_type() function to check if the application runs in RStudio before setting the shiny.launch.browser option.12\n\n\n\n\n\n\nTipPositron tab-completion\n\n\n\n\n\n\nPositron also comes with IntelliSense for R functions. Place your cursor inside the parentheses and use ^+SPACE or tab:\n\n\n\n\n\n\n\nPositron function IntelliSense\n\n\n\n\n\n\n\nLoading & Documenting\nAfter making changes to R/display_type.R, I can use the same keyboard shortcuts from devtools to load and document the package:\n\n\n\n\n\nCmd / Ctrl + Shift + L = devtools::load_all()\n\n\n\n\n\n\n\n\nCmd / Ctrl + Shift + D = devtools::document()\n\n\n\n\n\nUnder the hood, Positron calls devtools::load_all() and devtools::document(), but instead of launching a Build pane, Positron displays the messages from in the Console:\n\n\n\n\n\n\n\nDocument R/display_type.R (click to enlarge)\n\n\nThe display_type.Rd in the Console is a hyperlink we can use to preview our updated help file.\n\n\n\n\n\n\n\n\nPreview help file for R/display_type.R (click to enlarge)\n\n\n\n\n\nInstalling\nPositron uses the same keyboard shortcut as RStudio for installing packages, but the underlying process differs slightly. Instead of calling devtools::install() in the Build pane, Positron launches the Terminal and runs pak::local_install(upgrade = FALSE):\n\n\n\n\n\nCmd / Ctrl + Shift + B = pak::local_install(upgrade = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nThe new package install Terminal commands are bookended with an asterick (*) and a message (click to enlarge)\n\n\n\n\n\n\n\n\n\nThe Terminal pane displays a dedicated Install R package task when a package is installed.\nlocal_install(upgrade = FALSE) updates the package with the minimum work needed, upgrading dependencies only if the package or one of its dependencies requires a higher version. It prefers binary packages to source packages, even if the binaries are older.\nlocal_install() also seems to takes a bit longer to run than devtools::install(), but the end result is the same (i.e., the package is installed, the R session restarts, and the package is loaded with library() in the Console).\n\n\n\n\n\n\nTipIntelliSense\n\n\n\n\n\n\n\nIn the Console, Positron’s tab completion and IntelliSense displays a large preview each function’s help file:\n\n\n\n\n\n\n\nPreview of help file with IntelliSense\n\n\n\n\n\n\n\n\nTesting\nPositron comes with a variety of options for testing code. We can use the standard keyboard shortcut to call devtools::test(). This will open a Terminal task with the test results:13\n\n\n\n\n\nCmd / Ctrl + Shift + T = devtools::test()\n\n\n\n\n\n\n\n\n\n\n\n\nRunning devtools::test() (click to enlarge)\n\n\n\n\n\n\n\n\n\n\n\n\nPositron also has a dedicated testing sidebar menu item that allows us to select or filter the test files in the tests/testthat/ folder.\n\n\n\n\n\n\n\n\n\n\nTest files in tests/testthat/ (click to enlarge)\n\n\nThe testing sidebar menu also displays the contents of each test file. If you’re using testthat’s behavior-driven development functions (describe and it), the descriptions are organized hierarchically under TESTING:\n\n\n\n\n\n\n\nBDD test descriptions (click to enlarge)\n\n\nIf test_that() is used, the function being tested is displayed each time an expect_* function is called:\n\n\n\n\n\n\n\ntest_that() test descriptions (click to enlarge)\n\n\n\n\nRunning tests\nThe  icon under the TESTING sidebar menu item can also be used to run all the tests in the testthat folder.\n\n\n\n\n\n\n\nRunning tests with icon (click to enlarge)\n\n\n\n\n\n\n\n\nTipPackage Development Keyboard Shortcuts\n\n\n\n\n\n\nTwo additional shortcuts I recommend adding are:  Cmd / Ctrl + T = devtools::test_active_file()  Cmd / Ctrl + Shift + R = devtools::test_coverage_active_file() \nCheck out Andrew Heiss’ Positron post for more information on changing keyboard shortcuts"
  },
  {
    "objectID": "posts/positron-v1/index.html#recap",
    "href": "posts/positron-v1/index.html#recap",
    "title": "Positron",
    "section": "Recap",
    "text": "Recap\nPositron brings a refined experience for RStudio users, blending powerful tools in a streamlined layout that promotes an efficient workflow. Here’s a recap of the features we’ve explored:\n\nIDE Layout: Positron’s design ensures smooth navigation. It focuses on customizable panels that allow developers to arrange code editors, data viewers, and debugging consoles based on their workflow.\nSupport for R & Python: The IDE accommodates multiple versions of R and Python, offering a consistent environment for both languages. Integrated version control helps manage and switch between environments seamlessly, making it ideal for teams working on cross-language projects.\nShiny App Development: Positron provides robust tools for developers to build, test, and deploy Shiny applications. The IDE simplifies UI-building with live previews and reactive programming support, enabling users to refine interactive components.\nPackage Development: Positron includes a comprehensive suite for R package development, with features that streamline code documentation, testing, and version management. These tools make it easier to follow best practices, ensuring well-organized, maintainable packages.\n\nPositron can enhance productivity for R and Python users, making it a strong choice for data science and development."
  },
  {
    "objectID": "posts/positron-v1/index.html#footnotes",
    "href": "posts/positron-v1/index.html#footnotes",
    "title": "Positron",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m using version 2024.07.0-107↩︎\nThe Variables pane is similar to the Environments pane in RStudio.↩︎\nThese packages are described in the R prerequisites section.↩︎\nsap is the Shiny app-package I used to demonstrate development in my Shiny-App-Packages book.↩︎\nI’m using a branch from sap, which is a collection of Shiny apps/R packages.↩︎\nRead more on Garrick’s blog↩︎\nThe Open VXS Registry is manages by the Eclipse Foundation.↩︎\nRead more on Andrew’s blog↩︎\nRead more on Veerle’s blog↩︎\nI’m demoing the 02.1_shiny-app, which is a boilerplate Shiny app project with the Old Faithful Geyser data.↩︎\nRead more about Shiny development mode here.↩︎\nThis is covered in the 08_launch-app branch of moviesApp, which is covered in the Launch chapter of Shiny-App-Packages.↩︎\nI’m demonstrating with the 12.3_tests-snapshots branch of sap, which is covered in the Test Tools chapter of Shiny-App-Packages.↩︎"
  },
  {
    "objectID": "series/shiny-frameworks/golem/index.html",
    "href": "series/shiny-frameworks/golem/index.html",
    "title": "golem shiny app-packages",
    "section": "",
    "text": "This post walks through building a shiny application using the golem framework. golem is a ’an opinionated framework for building production-grade shiny applications’–I’ll explore some of the opinions (and offer my opinion on adopting these opinions).\ninstall.packages(\"devtools\")\ndevtools::install_github(\"mjfrigaard/gap\")\nFor consistency, I’ll be using the application from the RStudio’s Building Web Applications with Shiny course. These materials are a great resource if you’re new to shiny–even if you’re aren’t, it’s still worth checking out–plus it’s free!\nThe golem text is also a fantastic resource, but I found myself using the golem website as a great ‘quick reference.’ If you’re unfamiliar with R package development, I recommend bookmarking R packages–this is a great resource you’ll return to often."
  },
  {
    "objectID": "series/shiny-frameworks/golem/index.html#outline",
    "href": "series/shiny-frameworks/golem/index.html#outline",
    "title": "golem shiny app-packages",
    "section": "Outline",
    "text": "Outline\nI’ve organized the app-package development process into three areas: Start, Build, and Use.\n\nStart covers the required steps to launch your golem project in the RStudio IDE, common R package files and folders, and other setup considerations.\nBuild covers the app-package development process, which includes writing and storing code, data, external resources (like CSS or JavaScript), testing, etc.\nUse shows how to launch a golem application locally (i.e., within the RStudio IDE), common workflow tips, and anything I found confusing while building the application.\n\n\ndev/ scripts\nNew golem apps automatically open the 01_start.R script from the dev/ folder. This is the first of three .R scripts that serve as a ‘guided tour’ of the golem framework (01_start.R, 02_dev.R, and 03_deploy.R):\n\n\n\n\n\n\n\ngolem dev/ scripts\n\n\nThe run_dev.R is also in the dev/ folder, but it’s for running a development version of your app (more on this later).\n\n\n\n\n\n\nNoteDevelopment scripts: Note\n\n\n\n\n\n\nIf you’re familiar with R application development, you should recognize most of the items in the dev/ scripts. I recommend going through these scripts even if you’re an experienced R package developer–you can think of these as a ‘shiny app-package development checklist.’"
  },
  {
    "objectID": "series/shiny-frameworks/golem/index.html#start",
    "href": "series/shiny-frameworks/golem/index.html#start",
    "title": "golem shiny app-packages",
    "section": "Start",
    "text": "Start\n\nTo create a new golem app from the console, enter the following:\n\ninstall.packages(\"golem\")\nlibrary(golem)\ngolem::create_golem(path = \"gap\")\n\nIf you’re creating a golem app using the New Project Wizard, the following defaults are available:\n\n\n\n\n\n\n\n\n\n\nIDE wizard golem setup\n\n\n\n\nFigure 1: Creating a new golem shiny app\n\n\n\n\n\n\n\n\n\nImportantgolem comments: Highly recommend\n\n\n\n\n\n\nI recommend using golem comments–they’re helpful and don’t change how the application code runs.\n\n\n\n\nWhen the new project opens, the initial folder structure for your new golem application is below:\n\n\nshow/hide golem folder structure\napp-name/\n  ├── DESCRIPTION\n  ├── NAMESPACE\n  ├── R\n  │   ├── app_config.R\n  │   ├── app_server.R\n  │   ├── app_ui.R\n  │   └── run_app.R\n  ├── dev\n  │   ├── 01_start.R\n  │   ├── 02_dev.R\n  │   ├── 03_deploy.R\n  │   └── run_dev.R\n  ├── [app-name].Rproj\n  ├── inst\n  │   ├── app\n  │   │   └── www\n  │   │       └── favicon.ico\n  │   └── golem-config.yml\n  └── man\n      └── run_app.Rd\n  \n  7 directories, 14 files\n\n\n\nBegin 01_start.R\nThe dev/01_start.R file is covered in the first few sections of the golem text, but I prefer the package website as a reference because it walks through each dev/ script (with links to the golem functions).\n\nFill the DESCRIPTION\n\n\n\n\n\n\nImportantgolem::fill_desc(): Highly recommend\n\n\n\n\n\n\nThe DESCRIPTION file plays and important role in R packages (probably why it’s the first item in the 01_start.R file).\n\n‘all a project needs to be a package is a directory of R/ files and a DESCRIPTION file.’ - Packages Chapter of Mastering Shiny\n\nThe golem::fill_desc() arguments are a great way to guarantee your DESCRIPTION file is set up correctly.\n\n\n\n\nThere are three files in a new golem app-package–NAMESPACE, DESCRIPTION, and [app name].Rproj. dev/01_start.R starts by building the DESCRIPTION file with golem::fill_desc()\n\n\n\n\n\ngolem DESCRIPTION\n\n\nfill_desc() is from the desc package, and the sections are entered in a key = \"value\" format\n\nExample DESCRIPTION file contents:\n\ngolem::fill_desc(\n  pkg_name = \"gap\",\n  pkg_title = \"An example goelm app\",\n  pkg_description = \"A working example of the golem package.\",\n  author_first_name = \"Martin\",\n  author_last_name = \"Frigaard\",\n  author_email = \"mjfrigaard@pm.me\",\n  repo_url = NULL # The URL of the GitHub Repo (optional)\n)\n\n\n\nshow/hide output from golem::fill_desc()\n✔ Setting `golem_version` to 0.0.0.9000\n✔ Setting `golem_name` to gap\n✔ DESCRIPTION file modified\n\n\n\n\n\n\n\n\n\nTipWhat if I need to edit the DESCRIPTION?\n\n\n\n\n\n\nIn dev/02_dev.R, attachment::att_amend_desc() will ‘Amend DESCRIPTION with dependencies read from package code parsing’. If attachment is not installed, use install.package('attachment')\n\n\n\n\n\n\nSet {golem} options\nThe golem::set_golem_options() wraps a collection of golem‘s ’opinionated’ application development and configuration options.\n\ngolem::set_golem_options()\n\n\n\nshow/hide output from golem::set_golem_options()\n── Setting {golem} options in `golem-config.yml` ────────────────────────────────────────────────────────────────────\n✔ Setting `golem_name` to gap\n✔ Setting `golem_wd` to golem::pkg_path()\nYou can change golem working directory with set_golem_wd('path/to/wd')\n✔ Setting `golem_version` to 0.0.0.9000\n✔ Setting `app_prod` to FALSE\n── Setting {usethis} project as `golem_wd` ──────────────────────────────────────────────────────────────────────────\n✔ Setting active project to '/projects/gap'\n\n\nset_golem_options() is a wrapper for a collection of golem option functions (I’ve included each function and a brief description of their behavior below):\n\n\nshow/hide golem options\ngolem::set_golem_options(\n  golem_name = golem::pkg_name(), # name of the app-package in DESCRIPTION\n  golem_version = golem::pkg_version(), # version in DESCRIPTION\n  golem_wd = golem::pkg_path(), # package root when starting a golem\n  app_prod = FALSE, # production mode?\n  talkative = TRUE, # Should the messages be printed to the console?\n  config_file = golem::get_current_config(golem_wd) # golem-config.yml location\n)\n\n\n\n\n\n\n\ngolem config file\n\n\nThe new config file is located in the inst/ folder.\n\n\n\n\n\n\n\nImportantgolem::set_golem_options(): Highly recommend\n\n\n\n\n\n\nTo fully understand the golem framework, I recommended running this function. The functions called for each argument in golem::set_golem_options() provide some insight into how a golem app is structured (i.e., where the name and version information is stored, the location of the root directory, etc.)\n\n\n\n\n\n\nInstall required dev dependencies\nThe golem::install_dev_deps() function makes sure the following packages are installed (I’ve grouped them into categories):\n\n\n\nDevelopment\n\ndevtools (loading, documenting, installing package)\n\npkgload (i.e., devtools::load_all())\n\nusethis (create package files)\nroxygen2 (document package functions and objects)\npkgbuild (create a .tar.gz file)\n\n\n\nDocumentation & testing\n\nattachment (deal with package dependencies)\ndesc (Parse DESCRIPTION files)\ntestthat (unit testing your code)\n\n\n\n\n\n\n\nInternals\n\nrstudioapi (interacting with RStudio IDE)\nprocessx (execute and control subprocesses from R)\n\n\n\nFiles & paths\n\nhere (file/folder path management)\nfs (file/folder path management)\n\n\n\nDeploy\n\ndockerfiler (deploying apps with docker)\nrsconnect (deploy shiny apps with RSConnect)\n\n\n\n\n\ngolem::install_dev_deps()\n\nBelow is an example with dockerfiler:\n\n\nshow/hide output from golem::install_dev_deps()\nℹ The package \"dockerfiler\" is required.\n✖ Would you like to install it?\n\n1: Yes\n2: No\n\nSelection: 1\n✔ Updated metadata database: 5.32 MB in 12 files.                         \n✔ Updating metadata database ... done                                     \n                                                                            \n→ Will install 1 package.\n→ Will download 1 CRAN package (104.29 kB).\n+ dockerfiler   0.2.1  ⬇ (104.29 kB)\nℹ Getting 1 pkg (104.29 kB)\n✔ Got dockerfiler 0.2.1 (x86_64-apple-darwin17.0) (104.29 kB)             \n✔ Downloaded 1 package (104.29 kB)in 1.1s                                 \n✔ Installed dockerfiler 0.2.1  (54ms)                                    \n✔ 1 pkg + 40 deps: kept 40, added 1, dld 1 (104.29 kB) [20.2s]  \n\n\n\n\n\n\n\n\nImportantgolem::install_dev_deps(): Highly recommned\n\n\n\n\n\n\nI recommend using golem’s options here–it’s efficient and let’s you know if a particular package isn’t installed:\n\n\n\n\n\n\nCreate Common Files\nThe ‘Create Common Files’ section of dev/01_start.R contains many of the functions and files covered in the ‘Whole Game’ section of R packages:\n\nLICENSE\n\nusethis::use_mit_license(\"Golem User\")\n\n\n✔ Adding 'MIT + file LICENSE' to License\n✔ Writing 'LICENSE'\n✔ Writing 'LICENSE.md'\n✔ Adding '^LICENSE\\\\.md$' to '.Rbuildignore'\n\n\n\n\n\n\n\n\n\n\n\n\ngolem LICENSE file\n\n\n\nREADME.Rmd\n\nusethis::use_readme_rmd()\n\n\n✔ Writing 'README.Rmd'\n✔ Adding '^README\\\\.Rmd$' to '.Rbuildignore'\n• Update 'README.Rmd' to include installation instructions.\n\n\nThe README.md is built with devtools::build_readme()\ndevtools::build_readme()\nℹ Installing gap in temporary library\nℹ Building /projects/gap/README.Rmd\n\n\n\n\n\n\n\n\n\n\n\ngolem README.Rmd file\n\n\n\nCODE_OF_CONDUCT.md\n\nusethis::use_code_of_conduct()\n\n\n✔ Writing 'CODE_OF_CONDUCT.md'\n✔ Adding '^CODE_OF_CONDUCT\\\\.md$' to '.Rbuildignore'\n• You may also want to describe the code of conduct in your README:\n  ## Code of Conduct\n\nPlease note that the gap project is released with a [Contributor Code of\n    Conduct](https://contributor-covenant.org/version/2/1/CODE_OF_CONDUCT.html).\nBy contributing to this project, you agree to abide by its terms.\n  [Copied to clipboard]\n\n\nPaste of the code of conduct in the README.md is rebuild with devtools::build_readme()\ndevtools::build_readme()\nℹ Installing gap in temporary library\nℹ Building /projects/gap/README.Rmd\n\n\n\n\n\n\n\n\n\n\n\ngolem code of conduct file\n\n\n\nLifecycle badge\n\nusethis::use_lifecycle_badge(\"Experimental\")\n\n\n✔ Adding Lifecycle: experimental badge to 'README.Rmd'\n• Re-knit 'README.Rmd' with `devtools::build_readme()`\n\n\nRebuild the README.md with devtools::build_readme()\nusethis::use_lifecycle_badge(\"Experimental\")\nℹ Installing gap in temporary library\nℹ Building /projects/gap/README.Rmd\n\n\n\n\n\n\n\n\n\n\n\ngolem lifecycle badge\n\n\n\nNEWS.md\n\nusethis::use_news_md(open = FALSE)\n\n\n✔ Writing 'NEWS.md'\n\n\n\n\n\n\n\n\n\n\n\ngolem NEWS.md file\n\n\n\nGit: usethis::use_git() will ask if you’d like to commit the files in your golem app to a repo of the same name:\n\nusethis::use_git()\n\n\n✔ Setting active project to '/projects/gap'\n✔ Initialising Git repo\n✔ Adding '.Rproj.user', '.Rhistory', '.Rdata', '.httr-oauth',\n  '.DS_Store', '.quarto' to '.gitignore'\nThere are 16 uncommitted files:\n* '.gitignore'\n* '.here'\n* '.Rbuildignore'\n* 'CODE_OF_CONDUCT.md'\n* 'DESCRIPTION'\n* 'dev/'\n* 'gap.Rproj'\n* 'inst/'\n* 'LICENSE'\n* 'LICENSE.md'\n* ...\nIs it ok to commit them?\n\n1: Definitely\n2: Negative\n3: Not now\n\nSelection: 1\n\n\nTo initialize the Git pane, you’ll need to restart RStudio (in the next dialogue)\n✔ Adding files\n✔ Making a commit with message 'Initial commit'\n• A restart of RStudio is required to activate the Git pane\nRestart now?\n\n1: Absolutely\n2: Negative\n3: No\nSelection: 1\n\n\n\n\n\n\n\n\nCautionCommon files: Recommend\n\n\n\n\n\n\nEach of these files are important for an R package, so having them consolidated in 01_start.R makes it easier to get up and running quickly. However, if you’d like to edit their contents before moving onto the next step (or you’d like information on a particular function/file), I recommend consulting R packages for this section\n\n\n\n\n\n\nInit Testing Infrastructure\ngolem::use_recommended_tests() with set up the testthat architecture for unit tests.\n\ngolem::use_recommended_tests()\n\n\n\n\n\n\ngolem test files\n\n\n\n✔ Setting active project to '/projects/gap'\n✔ Adding 'testthat' to Suggests field in DESCRIPTION\n✔ Adding '3' to Config/testthat/edition\n✔ Creating 'tests/testthat/'\n✔ Writing 'tests/testthat.R'\n• Call `use_test()` to initialize a basic test file and open it for editing\n\nIt also adds a few words to the WORDLIST file in the inst folder:\n\n✔ Adding 'spelling' to Suggests field in DESCRIPTION\n✔ Adding 'en-US' to Language\nThe following words will be added to the wordlist:\n - Lifecycle\n - goelm\n - golem\nAre you sure you want to update the wordlist?\n1: Yes\n2: No\n\nSelection: 1\nAdded 3 and removed 0 words in /projects/gap/inst/WORDLIST\nUpdated /projects/gap/tests/spelling.R\n• Run `devtools::check()` to trigger spell check\n✔ Tests added\n\ngolem::use_recommended_tests() also provides some examples for testing the UI, server, and other golem functions:\n\n\nshow/hide unit tests in test-golem-recommended.R\ntest_that(\"app ui\", {\n  ui &lt;- app_ui()\n  golem::expect_shinytaglist(ui)\n  # Check that formals have not been removed\n  fmls &lt;- formals(app_ui)\n  for (i in c(\"request\")) {\n    expect_true(i %in% names(fmls))\n  }\n})\n\ntest_that(\"app server\", {\n  server &lt;- app_server\n  expect_type(server, \"closure\")\n  # Check that formals have not been removed\n  fmls &lt;- formals(app_server)\n  for (i in c(\"input\", \"output\", \"session\")) {\n    expect_true(i %in% names(fmls))\n  }\n})\n\ntest_that(\n  \"app_sys works\",\n  {\n    expect_true(\n      app_sys(\"golem-config.yml\") != \"\"\n    )\n  }\n)\n\ntest_that(\n  \"golem-config works\",\n  {\n    config_file &lt;- app_sys(\"golem-config.yml\")\n    skip_if(config_file == \"\")\n\n    expect_true(\n      get_golem_config(\n        \"app_prod\",\n        config = \"production\",\n        file = config_file\n      )\n    )\n    expect_false(\n      get_golem_config(\n        \"app_prod\",\n        config = \"dev\",\n        file = config_file\n      )\n    )\n  }\n)\n\n# Configure this test to fit your need.\n# testServer() function makes it possible to test code in server functions and modules, without needing to run the full Shiny application\ntestServer(app_server, {\n\n  # Set and test an input\n  session$setInputs(x = 2)\n  expect_equal(input$x, 2)\n\n  # Example of tests you can do on the server:\n  # - Checking reactiveValues\n  # expect_equal(r$lg, 'EN')\n  # - Checking output\n  # expect_equal(output$txt, \"Text\")\n})\n\n# Configure this test to fit your need\ntest_that(\n  \"app launches\",\n  {\n    golem::expect_running(sleep = 5)\n  }\n)\n\n\nThese tests pass right out of the box, and they give a little ‘sneak preview’ of how the golem framework works.\n\n\nshow/hide results from unit tests in test-golem-recommended.R\n==&gt; Testing R file using 'testthat'\n\nℹ Loading gap\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 9 ]\nLoading required package: shiny\n[ FAIL 0 | WARN 0 | SKIP 1 | PASS 10 ]\n\n── Skipped tests (1) ─────────\n• interactive() is not TRUE\n  (1):\n  test-golem-recommended.R:72:5\n\n\nTest complete\n\n\n\n\n\n\n\n\nImportantgolem recommended tests: Highly recommend\n\n\n\n\n\n\nI love this feature of golem apps! in a single function I have the folders required for unit testing, words added to the WORDLIST (which I almost never remember to do), and an example test with shiny’s testServer() function.\n\n\n\n\n\n\nFavicon\nA favicon is a the little image that shows up on your browser tab or address bar. golem has a default favicon in the inst/app/ folder:\n\n\n\n\n\ngolem favicon file\n\n\n\ninst/\n  └── app\n       └── www\n            └── favicon.ico\n\n\n3 directories, 1 file\n\nThe inst/ folder serves a specific purpose in golem apps (and R packages), which I’ll cover more below. For our purpose, the golem::use_favicon() function can use the existing image:\n\ngolem::use_favicon(path = \"inst/app/www/favicon.ico\")\n\nThe output introduces another common golem function: golem_add_external_resources()\n\n✔ favicon.ico created at \n/projects/gap/inst/app/www/favicon.ico\nFavicon is automatically linked in app_ui via `golem_add_external_resources()`\n\nThis function is used to add external resources to your application (and will come up often during development).\n\n\nAdd helper functions\nMost applications will have two types of code–shiny functions for running your application (app functions), and functions that do everything else (or utility functions). The golem framework further distinguishes utility functions into two types: 1) “small functions that are reused throughout the app” (with a utils_ prefix), and 2) “larger functions, which are more central to the application” (with a fct_ prefix).\n\n\n\n\n\n\nNoteDocumenting & exporting functions: NOTE\n\n\n\n\n\n\nThe functions in golem_utils_ui.R and golem_utils_server.R are created with the @noRd tag, which prevents the .Rd file generation. If you’d like the functions available outside of the package, you can use @export. If you’d like ‘a manual page created but not present in the function index’, use @keywords internal. See the examples I’ve created here and here\n\n\n\n\nThe descriptions below are from the text and provide examples for the two types of utility functions:\n\nutils_ functions: “…the hexmake app has two of these files, R/utils_ui.R and R/utils_server.R, in which you will find small functions that are reused throughout the app.”\n\n\nfct_ functions: “…in hexmake, you will find R/fct_mongo.R, which is used to handle all the things related to connecting and interacting with the Mongodb database.”\n\n\nuse_utils_ui()\nThe golem::use_utils_ui() function will add a collection of utility functions for the UI. Including with_test = TRUE will add a test for these functions.\n\n\n\n\n\ngolem UI utility functions & tests\n\n\n\ngolem::use_utils_ui(with_test = TRUE)\n\n\n✔ File created at /projects/gap/R/golem_utils_ui.R\n✔ Utils UI added\n✔ File created at /projects/gap/tests/testthat/test-golem_utils_ui.R\n✔ Tests on utils_server added\n\n\n\nuse_utils_server()\ngolem also includes a set of functions for the application server (or server modules), golem::use_utils_server(). The with_test = TRUE will also add a test to the tests/testthat/ folder:\n\ngolem::use_utils_server(with_test = TRUE)\n\n\n✔ File created at /projects/gap/R/golem_utils_server.R\n✔ Utils server added\n✔ File created at /projects/gap/tests/testthat/test-golem_utils_server.R\n✔ Tests on utils_server added\n\n\n\n\n\n\ngolem server utility functions & tests\n\n\n\n\n\n\n\n\nCautiongolem utility functions: Recommend\n\n\n\n\n\n\nI consider these functions optional, but the examples in each file have a broad enough application that you’ll probably discover something helpful for your golem application. The with_test argument also provides more examples of unit tests for your application functions, so you’re likely to find something useful!\n\n\n\n\n\n\n\n\nEnd 01_start.R\nThis is the final function in the dev/01_start.R file. In the next golem dev script (dev/02_dev.R), I’ll cover development of your golem application."
  },
  {
    "objectID": "series/shiny-frameworks/golem/index.html#build",
    "href": "series/shiny-frameworks/golem/index.html#build",
    "title": "golem shiny app-packages",
    "section": "Build",
    "text": "Build\nThe dev/02_dev.R file is appropriately titled, ‘Engineering’, and unlike the functions in the first script, these functions will be used repeatedly for creating files in the R/ and inst/ folders.\n\nBegin 02_dev.R\n\nApp files\nLet’s start by examining the contents of the R/ folder in our new golem application:\n\n\n\n\n\ngolem application files\n\n\n\nR/\n├── app_config.R\n├── app_server.R\n├── app_ui.R\n└── run_app.R\n\n1 directory, 4 files\n\ngolem applications structure shiny apps into three files: R/app_ui.R, R/app_server.R, and R/run_app.R.\n\nThe R/app_ui.R and R/app_server.R scripts are golem’s version of ui.R and server.R\nR/run_app.R is a standalone app function, and\nR/app_config.R is used to set/get golem configuration settings (which we will cover more below).\n\n\napp_ui.R\napp_ui.R wraps the UI functions in shiny::tagList() (you’ll see this function in shiny UI module functions, too).\n\n\nshow/hide app_ui()\napp_ui &lt;- function(request) {\n  tagList(\n    # Leave this function for adding external resources\n    golem_add_external_resources(),\n    # Your application UI logic\n    fluidPage(\n      h1(\"gap\")\n    )\n  )\n}\n\n\napp_ui() also contains a call to golem_add_external_resources(), which we used above to add the favicon image.\n\n\nshow/hide golem_add_external_resources()\ngolem_add_external_resources &lt;- function() {\n  add_resource_path(\n    \"www\",\n    app_sys(\"app/www\")\n  )\n\n  tags$head(\n    favicon(),\n    bundle_resources(\n      path = app_sys(\"app/www\"),\n      app_title = \"gap\"\n    )\n    # Add here other external resources\n    # for example, you can add shinyalert::useShinyalert()\n  )\n}\n\n\n\n\napp_server.R\nThe contents of app_server.R file looks similar to a standard shiny server function:\n\n\nshow/hide app_server()\napp_server &lt;- function(input, output, session) {\n  # Your application server logic\n}\n\n\n\n\napp_config.R\nThe app_config.R file contains the “internal mechanics for golem, notably for referring to values in the inst/ folder, and to get values from the config file in the inst/ folder”. Two functions drive the internal mechanics of your golem app: app_sys() and get_golem_config()\n\napp_sys() is a wrapper around the system.file() function, and it’s used to “quickly refer to the files inside the inst/ folder”\n\n\n\nshow/hide app_sys()\napp_sys &lt;- function(...) {\n  system.file(..., package = \"gap\")\n}\n\n\n\nget_golem_config() is where you’ll set golem configuration options (covered here in the text).\n\n\n\nshow/hide get_golem_config()\nget_golem_config &lt;- function(\n  value,\n  config = Sys.getenv(\n    \"GOLEM_CONFIG_ACTIVE\",\n    Sys.getenv(\n      \"R_CONFIG_ACTIVE\",\n      \"default\"\n    )\n  ),\n  use_parent = TRUE,\n  # Modify this if your config file is somewhere else\n  file = app_sys(\"golem-config.yml\")\n) {\n  config::get(\n    value = value,\n    config = config,\n    file = file,\n    use_parent = use_parent\n  )\n}\n\n\nget_golem_config() reads the inst/golem-config.yml configuration file:\n\ndefault:\n  golem_name: gap\n  golem_version: 0.0.0.9000\n  app_prod: no\nproduction:\n  app_prod: yes\ndev:\n  golem_wd: !expr here::here()\n\ngolem-config.yml gives me access to the app version, name, and (development) working directory. This file is designed to add “production-only elements” and be “shareable across golem projects”\n\n\nrun_app.R\nrun_app.R is the exported function I’ll use to run my golem app after loading/documenting/installing the package:\n\ndevtools::load_all(\".\")\n\n\nℹ Loading gap\n\n\ndevtools::document()\n\n\nℹ Updating gap documentation\nℹ Loading gap\n\nRestarting R session...\n\n\nlibrary(gap)\ngap::run_app()\n\n\n\n\n\n\n\nTipR/app_config.R: Tip\n\n\n\n\n\n\nThe great thing about golem applications is that despite having a somewhat overwhelming amount of code and options, most of these can be ignored until you need to use them. R/app_config.R is a great example of this. The get_golem_config() function is a powerful tool for deploying apps in production, but you can get started developing your application without diving into the details.\n\n\n\n\n\n\n\n\nDependencies\nDependency management is a necessary evil of package development. shiny has a large ecosystem of user-written add-on packages. To use the code from add-on packages in our application, we need a way to keep track of which function belongs to which package.\n\n\n\n\n\ngolem app dependencies\n\n\nThe DESCRIPTION file manages package-level dependencies. The Imports field in the DESCRIPTION file specifies packages that my package uses, so the functions from these packages will be available for my package, but not for users (unless they use the :: operator or load the package themselves).\nThe NAMESPACE file manages function-level access. The NAMESPACE file manages the functions that are exported from my package (i.e., functions available to users who install my package), and the functions my package imports from other packages.\nThe golem text describes the difference between these files in the following way,\n\n“The DESCRIPTION file dictates which packages have to be installed when your application is installed”\n“The NAMESPACE file describes how your app interacts with the R session at run time, i.e. when your application is launched”\n\nThe attachment package makes it easier to manage the dependencies in your golem application. It does this by looking through the files in your package to make sure everything is properly documented in the NAMESPACE and DESCRIPTION file (note that these two files are not equivalent or connected).\nThe att_amend_desc() function removes a lot of the tedium involved in dependency management:\n\nattachment::att_amend_desc()\n\nThis function adds the appropriate parameters to golem-config.yml and sets up function documentation in the DESCRIPTION file\n\nSaving attachment parameters to yaml config file\nUpdating [app-name] documentation\nSetting `RoxygenNote` to \"7.2.3\"\n\nIt loads the contents of our package (i.e. devtools::load_all()) and writes the NAMESPACE file\n\nℹ Loading [app-name]\nWriting NAMESPACE\n\nIt also writes the help files in the man/ folder.\n\nWriting run_app.Rd\n\n\n\n\n\n\n\nImportantgolem dependencies: Highly recommend\n\n\n\n\n\n\nManaging the dependencies in your app is an essential part of getting your application to deploy in a production environment, and this is a very helpful addition to your package development workflow (whether you’re building an app package or standard R package).\n\n\n\n\n\n\nAdd modules\ngolem has functions for quickly creating modules and utility/helper functions in the R/ folder.\n\nadd_module()\n\ngolem::add_module(name = \"name_of_module1\", with_test = TRUE) \ngolem::add_module(name = \"name_of_module2\", with_test = TRUE) \n\n\n\n\nAdd helper functions\ngolem apps differentiates two types of helper functions: uils_ and fct_.\n\nadd_utils()\n\nuils_ functions: “small functions that might be used several times in the application” … “more ‘topic centered’, in the sense that they gather functions that relate to a specific feature of the application(+”\n\n\ngolem::add_utils(\"helpers\", with_test = TRUE)\n\n\n\nadd_fct()\n\nfct_ functions: “larger functions that are more central to the application” … “more used as a place to put miscellaneous functions”\n\n\ngolem::add_fct(\"helpers\", with_test = TRUE)\n\nwith_test = TRUE ensures these functions will also create test files in tests/\n\n\n\n\n\ngolem::add_ functions\n\n\n\n\n\n\n\n\nImportantgolem modules and helper functions: Highly recommend\n\n\n\n\n\n\nThese functions are incredibly helpful for a variety of reasons: 1) they simplify the naming convention by automatically creating prefixes for modules (mod_[name]_ui/mod_[name]_server) and helper functions (utils_/fct_), 2) the with_test argument makes it easy to create an accompanying test file, which ensures you have tests for each function/module (and promotes test-driven development!).\n\n\n\n\n\n\n\nExternal resources\ndev/02_dev.R includes golem wrappers for including CSS, JavaScript, and SASS files to the inst/app/www/ folder:\n\nJavaScript files\nYou can add JavaScript to your application using the golem::add_js_file(\"script\") and golem::add_js_handler(\"handlers\") functions.\nThe golem text has an entire chapter dedicated to JavaScript (which is worth reading).\n\n\nApp styling\nYou can add CSS or SASS styling to your application using the golem::add_css_file(\"custom\") and golem::add_sass_file(\"custom\") functions, too.\n\n\n\n\n\ngolem external resources\n\n\n\n\n\n\n\n\nCautiongolem external resources: Recommend\n\n\n\n\n\n\nIt’s unlikely a production-grade shiny application only includes R code, and figuring out how to add other code files to your application can get complicated quickly. These functions are incredibly helpful (and they work outside of a golem applications!).\n\n\n\n\n\n\n\nAdd internal datasets\nIf you application uses data, you can add it to your application with the usethis functions (use_data_raw() or use_data()). I recommend reading the data section of R packages (and this section on adding data to inst/extdata).\n\n\n\n\n\ngolem app data\n\n\nLocations of data in golem app-packages\n\ninst/extdata\nExternal data you’d like to make available in your package should be stored in inst/extdata/\nThis is where I’ve placed the movies file:\ninst/extdata/\n└── movies.RData\n\n1 directory, 1 file\n\n\nuse_data_raw()\nThe data-raw/ folder is for the ‘data-creating script’ that was used to create the version of the data in your app-package:\n\nI’ll create a raw data file for movies.\n\n\nusethis::use_data_raw(\"movies\")\n\n\nNewly created .R scripts in use_data_raw() will have a call to use_data(). See below:\n\n✔ Writing 'data-raw/movies.R'\n• Modify 'data-raw/movies.R'\n• Finish the data preparation script in 'data-raw/movies.R'\n• Use `usethis::use_data()` to add prepared data to package\n\n\n\n\nuse_data()\nThe objects created from the .R files in data-raw/ are stored in the data/ folder (and any other data you need in your app-package).\n\n“store R objects and make them available to the user…in data/”\n\nFor example, in data-raw/movies.R, I load the movies data from inst/extdata/, and save movies to the data/ folder:\n\n## code to prepare `movies` dataset goes here\nload(\"inst/extdata/movies.RData\")\nusethis::use_data(movies, overwrite = TRUE)\n\n\nThe output is below:\n\n✔ Saving 'movies' to 'data/movies.rda'\n• Document your data (see 'https://r-pkgs.org/data.html')\n\n\nFollow this guide to document your datasets.\n\n\nshow/hide movies data documentation\n#' Movies dataset\n#'\n#' A dataset containing movie rankings from IMDB and Rotten Tomatoes. Original\n#' source found [here](https://rstudio-education.github.io/shiny-course/)\n#'\n#' @format A data frame with 651 rows and 34 variables:\n#'\n#' \\describe{\n#'   \\item{title}{movie title}\n#'   \\item{title_type}{title type (Documentary, Feature Film, TV, Movie)}\n#'   \\item{genre}{movie genre (Action & Adventure, Animation,\n#'                Art House & International, Comedy, Documentary, Drama, Horror,\n#'                Musical & Performing Arts, Mystery & Suspense, Other,\n#'                Science Fiction & Fantasy)}\n#'   \\item{runtime}{length of film (in minutes)}\n#'   \\item{mpaa_rating}{G, NC-17, PG, PG-13, R, Unrated}\n#'   \\item{studio}{studio movie was filmed in}\n#'   \\item{thtr_rel_date}{Theatre release date}\n#'   \\item{thtr_rel_year}{Theatre release year}\n#'   \\item{thtr_rel_day}{Theatre release day}\n#'   \\item{dvd_rel_date}{DVD release date}\n#'   \\item{dvd_rel_year}{DVD release year}\n#'   \\item{dvd_rel_month}{DVD release month}\n#'   \\item{dvd_rel_day}{DVD release day}\n#'   \\item{imdb_rating}{IMDB rating}\n#'   \\item{imdb_num_votes}{IMDB number of votes}\n#'   \\item{critics_rating}{Critics rating}\n#'   \\item{critics_score}{Critics score}\n#'   \\item{audience_rating}{Audience rating}\n#'   \\item{audience_score}{Audience score}\n#'   \\item{best_pic_nom}{Best picture nomination?}\n#'   \\item{best_pic_win}{Best picture win?}\n#'   \\item{best_actor_win}{Best actor win?}\n#'   \\item{best_actress_win}{Best actrss win?}\n#'   \\item{best_dir_win}{Best director win?}\n#'   \\item{top200_box}{Top 200 box-office?}\n#'   \\item{director}{Film director name}\n#'   \\item{actor1}{Actor 1 name}\n#'   \\item{actor2}{Actor 2 name}\n#'   \\item{actor3}{Actor 3 name}\n#'   \\item{actor4}{Actor 4 name}\n#'   \\item{actor5}{Actor 5 name}\n#'   \\item{imdb_url}{IMDB website url}\n#'   \\item{rt_url}{Rotten Tomatoes website url}\n#' }\n\"movies\"\n\n\nThe fivethirtyeight package also has great examples of documented datasets.\nAfter loading and documenting your package, you can view structure and variable names of the movies data by entering ??movies in the Console:\n\n\n\n\n\n\n\n\n\n\n(a) movies data documentation\n\n\n\n\n\nFigure 2: Documentation for gap::movies stored in R/data.R\n\n\n\n\n\n\n\nTests\nThe tests/ folder was created in dev/01_start.R with golem::use_recommended_tests(). This function is a wrapper around usethis::use_testthat(), and it sets up the tests/ folder:\ntests\n├── spelling.R\n├── testthat/\n└── testthat.R\nIn dev/02_dev.R, the golem::add_module() and golem::add_utils()/golem::add_fct() functions also include a with_test = TRUE argument, which creates a test file in the tests/ folder.\nThese functions add two test files in tests/testthat/:\ntests/testthat\n├── test-golem-recommended.R\n├── test-golem_utils_server.R\n└── test-golem_utils_ui.R\n\n1 directory, 3 files\nThese files test the functions in the files golem_utils_ui.R and golem_utils_server.R, and we can run them independently with testthat::test_file()\n\ntest_file(\"tests/testthat/test-golem_utils_server.R\")\n\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 13 ]\n\n\ntest_file(\"tests/testthat/test-golem_utils_ui.R\")\n\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 51 ]\n\n\n\nDocumentation\nR package vignettes contain high-level, long-form documentation for your package. These R Markdown documents combine narrative text and code that describe how the ‘parts’ (functions, data, etc.) of the package behave. In app-packages, vignettes might included the following information:\nFor shiny app-packages, the following types of documentation might be included in the vignettes:\n\n\n\n\n\n\n\nIntroduction to the package\nInstallation guide\nUsage examples\nDescription of the application and modules\nApplication workflow\nData preparation\n\n\n\n\n\n\n\n\n\nTroubleshooting\nFAQs\nAdvanced usage\nDetails on functions and datasets\nReferences and Contact information\n\n\n\n\nTo create a new vignette, run usethis::use_vignette(\"NAME OF VIGNETTE\"):\n\nusethis::use_vignette(\"gap\")\n\n\n✔ Setting active project to '/Users/mjfrigaard/projects/gap'\n✔ Adding 'knitr' to Suggests field in DESCRIPTION\n✔ Adding 'rmarkdown' to Suggests field in DESCRIPTION\n✔ Adding 'knitr' to VignetteBuilder\n✔ Adding 'inst/doc' to '.gitignore'\n✔ Creating 'vignettes/'\n✔ Adding '*.html', '*.R' to 'vignettes/.gitignore'\n✔ Writing 'vignettes/gap.Rmd'\n• Modify 'vignettes/gap.Rmd'\n\nThe vignette file opens with the title matching the argument passed to use_vignette(). To build the vignettes in your package, run:\n\ndevtools::build_vignettes()\n\n\n\n\n\n\n\nTipgolem package vignettes\n\n\n\n\n\n\nAs described in ‘Rmd, Vignettes, and documentation first’, R markdown vignettes are a perfect sandbox for building and testing shiny apps.\n\n‘the good news is that when checking a package, i.e. when running check() from devtools (Wickham, Hester, and Chang 2020) or R CMD check, the Vignettes are going to be built, and the process will fail if at least one of the Vignettes fails to render. That way, you can use the documentation of the back-end as an extra tool for doing unit testing!’\n‘One radical approach to the ’Rmd first’ philosophy is to write everything in an Rmd from the very beginning of your project: write the function code, their roxygen tags, their tests, etc., then move everything to the correct spot in the package infrastructure once you are happy with everything. And of course, when you need to add another feature to your app, open a new markdown and start the process of development and documentation again’\n\n\n\n\n\n\nCode Coverage\nTest code coverage measures the extent to which the test cases cover the possible execution paths in the package codebase–its a way to ensure that the tests are robust enough to verify that the code behaves as expected.\nThere are two functions/methods used to calculate code coverage in your application: usethis::use_coverage() and covrpage::covrpage().\n\nusethis::use_coverage()\nuse_coverage() is part of the usethis package and can be run interactively during development:\n\nusethis::use_coverage()\n\n✔ Setting active project to '/Users/mjfrigaard/projects/gap'\n\n\ncovrpage::covrpage()\nInstall covrpage using the following:\n\n# install.packages(\"remotes\")\n# remotes::install_github('yonicd/covrpage', \n#   force = TRUE, quiet = TRUE)\nlibrary(covrpage)\n\nTo use covrpage, run the following:\n\ncovrpage::covrpage()\n\n\ncovrpage::covrpage()\n\nThis sets up the README in the tests/ folder.\ntests/\n├── README.md &lt;- covrpage README!\n├── spelling.R\n├── testthat\n│   ├── test-golem-recommended.R\n│   ├── test-golem_utils_server.R\n│   └── test-golem_utils_ui.R\n└── testthat.R\nThe test coverage vignette is created with use_covrpage_vignette()\n\ncovrpage::use_covrpage_vignette()\n\ncopying tests_and_coverage.Rmd into ./vignettes\nadding inst/doc to .gitignore\nadding knitr,rmarkdown to Suggests field in ./DESCRIPTION\nadding VignetteBuilder: knitr to ./DESCRIPTION\nYou can view the covrpage for this app here\n\n\n\nCI\nContinuous integration can be handled with one of the GitHub Actions functions (make sure you’re using Git). See the usethis website for more information on using GitHub Actions.\nIf you’re using another CI management system, the following options are available.\n\n\n\nGithub Actions CI\n\nSet up GitHub actions\n\n# GitHub Actions\nusethis::use_github_action()\n\n\n# Chose one of the three\nusethis::use_github_action_check_release()\nusethis::use_github_action_check_standard()\nusethis::use_github_action_check_full()\n\n\n# Add action for PR\nusethis::use_github_action_pr_commands()\n\n\n\n\nOther CI Options\n\nTravis CI\n\nusethis::use_travis()\nusethis::use_travis_badge()\n\nAppVeyor\n\nusethis::use_appveyor()\nusethis::use_appveyor_badge()\n\nCircle CI\n\nusethis::use_circleci()\nusethis::use_circleci_badge()\n\nJenkins\n\nusethis::use_jenkins()\n\nGitLab CI\n\nusethis::use_gitlab_ci()\n\n\n\n\n\n\n\n\nEnd 02_dev.R\nThis concludes the 02_dev.R file. It’s likely you’ll return to this file repeatedly for various functions during development, so I’d leave it in the dev/ folder for future reference."
  },
  {
    "objectID": "series/shiny-frameworks/golem/index.html#use",
    "href": "series/shiny-frameworks/golem/index.html#use",
    "title": "golem shiny app-packages",
    "section": "Use",
    "text": "Use\nIn this section, I’ll go over the functions used during application development, how to launch the application (locally, in the IDE), and the third and final dev/ script (dev/03_deploy.R), which is full of options for deploying your shiny app.\n\nWriting code\nWhile developing, I find the add_* functions are incredibly helpful (add_module(), add_utils(), and add_fct()). New modules functions can be created with golem::add_module(\"name\") along with their tests and utility functions.\n\nadd_module(name = \"plot\", utils = \"server\", with_test = TRUE)\n\n\n✔ File created at R/mod_plot.R\n✔ File created at R/mod_plot_utils_server.R\n✔ File created at tests/testthat/test-mod_plot.R\n\n\nThe functions added to the R/ folder include @noRd by default (which must be removed create the .Rd files in the man/ folder)\n\n# UI module template -------------------\n#' test UI Function\n#'\n#' @description A shiny Module.\n#'\n#' @param id,input,output,session Internal parameters for {shiny}.\n#'\n#' @noRd &lt;- this one!\n#'\n#' @importFrom shiny NS tagList\n# server module template ---------------\n#' test Server Functions\n#'\n#' @noRd &lt;- and this one!\n\nUI module functions end with a _ui suffix:\n\n\nshow/hide mod_plot_ui()\n#' plot UI Function\n#'\n#' @param id\n#'\n#' @return shiny UI module\n#' @export mod_plot_ui\n#'\n#' @importFrom shiny NS tagList tags\n#' @importFrom shiny plotOutput verbatimTextOutput\nmod_plot_ui &lt;- function(id) {\n  ns &lt;- shiny::NS(id)\n  shiny::tagList(\n    shiny::tags$br(),\n    shiny::tags$blockquote(\n      shiny::tags$em(\n        shiny::tags$h6(\n          \"The code for this application comes from the \",\n          shiny::tags$a(\"Building web applications with Shiny\",\n            href = \"https://rstudio-education.github.io/shiny-course/\"\n          ),\n          \"tutorial\"\n        )\n      )\n    ),\n    shiny::plotOutput(outputId = ns(\"scatterplot\"))\n  )\n}\n\n\nServer module functions end with a _server suffix:\n\n\nshow/hide mod_plot_server()\n#' plot Server Functions\n#'\n#' @param id module id\n#' @param var_inputs inputs from mod_var_input\n#'\n#' @return shiny server module\n#' @export mod_plot_server\n#'\n#' @importFrom shiny NS moduleServer reactive\n#' @importFrom tools toTitleCase\n#' @importFrom shiny renderPlot\n#' @importFrom stringr str_replace_all\n#' @importFrom ggplot2 labs theme_minimal theme\nmod_plot_server &lt;- function(id, var_inputs) {\n  shiny::moduleServer(id, function(input, output, session) {\n    movies &lt;- gap::movies\n\n    inputs &lt;- shiny::reactive({\n      plot_title &lt;- tools::toTitleCase(var_inputs$plot_title())\n      list(\n        x = var_inputs$x(),\n        y = var_inputs$y(),\n        z = var_inputs$z(),\n        alpha = var_inputs$alpha(),\n        size = var_inputs$size(),\n        plot_title = plot_title\n      )\n    })\n\n    output$scatterplot &lt;- shiny::renderPlot({\n      plot &lt;- point_plot(\n        df = movies,\n        x_var = inputs()$x,\n        y_var = inputs()$y,\n        col_var = inputs()$z,\n        alpha_var = inputs()$alpha,\n        size_var = inputs()$size\n      )\n      plot +\n        ggplot2::labs(\n          title = inputs()$plot_title,\n          x = stringr::str_replace_all(tools::toTitleCase(inputs()$x), \"_\", \" \"),\n          y = stringr::str_replace_all(tools::toTitleCase(inputs()$y), \"_\", \" \")\n        ) +\n        ggplot2::theme_minimal() +\n        ggplot2::theme(legend.position = \"bottom\")\n    })\n  })\n}\n\n## To be copied in the UI\n# mod_plot_ui(\"plot_1\")\n\n## To be copied in the server\n# mod_plot_server(\"plot_1\")\n\n\n\nSee the utility function and other module in the gap app-package on GitHub below:\n\nR/mod_var.R\n\nR/mod_plot_utils_server.R\n\n\nInclude tests for new modules and functions using the with_test = TRUE argument\n\ntests/testthat/\n            ├── _snaps\n            ├── test-golem-recommended.R\n            ├── test-golem_utils_server.R\n            ├── test-golem_utils_ui.R\n            ├── test-mod_plot.R\n            ├── test-mod_plot_utils_server.R\n            └── test-mod_var_input.R\n\n2 directories, 6 files\n\n\n\n\n\n\n\n\nTipModule names: tip\n\n\n\n\n\n\nIncluding mod in the name of module scripts and functions makes it easier to separate them from other functions in my package namespace, if I’m using tab-completion, or if I’m searching for a particular file using Ctrl + .:\n\n\n\n\n\n\nFigure 3: Go to File/Function in RStudio\n\n\n\n\n\n\n\nThe updated covrpage report is available here\n\n\nAdding resources\nIf I want to include other files (like images), I can add these files to inst/app/www/,\n\ninst/app/www\n# add icon\ninst/app\n      └── www/\n           └── shiny.png\nThen I can include the path in the UI (see example below):\n\n# add icon\nshiny::tags$img(src = \"www/shiny.png\")\n\n\n\naddResourcePath()\nIf I wanted to include images in their own folder (like images/), I can use golem::addResourcePath() to add the name of the sub-folder to inst/app/\n\n# add icon\ngolem::add_resource_path(\n          prefix = 'images', \n          directoryPath = system.file('app/images',\n                          package = 'gap'))\n\nNow I can add the image file to the inst/app/www/images/ folder and include the following code in the UI:\n\n# add icon\nshiny::tags$img(src = \"www/images/golem-hex.png\")\n\n\nIn R/app_ui.R, the app_ui() function contains the UI layout functions (fluidPage(), sidebarLayout(), etc.), and a call to golem_add_external_resources():\n\n\nshow/hide app_ui()\n#' The application User-Interface\n#'\n#' @param request Internal parameter for `{shiny}`.\n#'     DO NOT REMOVE.\n#' @import shiny\n#' @keywords internal\napp_ui &lt;- function(request) {\n  shiny::tagList(\n    # Leave this function for adding external resources\n    golem_add_external_resources(),\n    # Your application UI logic\n    shiny::fluidPage(\n      shiny::tags$h1(\"gap\"),\n      shiny::sidebarLayout(\n        shiny::sidebarPanel(\n          mod_var_input_ui(\"vars\")\n        ),\n        shiny::mainPanel(\n          # add shiny hex in www/\n          shiny::tags$img(src = \"www/shiny.png\"),\n          mod_plot_ui(\"plot\"),\n          # add golem hex (in www/images/)\n          shiny::fluidRow(\n            shiny::tags$em(shiny::tags$h4(\n              \"Brought to you by: \",\n              shiny::tags$img(src = \"www/images/golem-hex.png\")\n            ))\n          )\n        )\n      )\n    )\n  )\n}\n\n\nThe golem_add_external_resources() function is below:\n\n\ngolem_add_external_resources()\n# this is also included in the app_ui.R script\ngolem_add_external_resources &lt;- function() {\n  add_resource_path(\n    \"www\",\n    app_sys(\"app/www\")\n  )\n  tags$head(\n    favicon(),\n    bundle_resources(\n      path = app_sys(\"app/www\"),\n      app_title = \"gap\"\n    )\n    # Add here other external resources\n    # for example, you can add shinyalert::useShinyalert()\n  )\n}\n\n\n\nNow when I run devtools::load_all(), devtools::document(), install/restart, and load the package, I see the images properly rendered with the application:\n\n\n\n\n\n\nImportantgolem_add_external_resources(): Highly recommend\n\n\n\n\n\n\ngolem app-packages take advantage of the inst/ folder to load external resources. Using golem_add_external_resources() helps ensure the external resources are added to the application and loaded when the application is deployed.\n\n\n\n\n\n\n\nBegin 03_deploy.R\nThe final step in the guided tour contains functions for deploying a new application to Posit Connect or Docker (it opens automatically after completing the dev/02_dev.R)\n\nRun checks\nThese functions are part of the package development process. devtools::check() should be run frequently (I run it after creating a new .R file or creating a new test).\nIf you plan on submitting a package to CRAN, the rhub::check_for_cran() function will create a ‘to-do’ list of CRAN comments.\n\n## Run checks ----\n## Check the package before sending to prod\ndevtools::check()\nrhub::check_for_cran()\n\n\ndevtools::check(): “It’s counter-intuitive but the key to minimizing this pain is to run R CMD check more often: the sooner you find a problem, the easier it is to fix” - R packages\nThe outputs from the initial devtools::check() are below (I’ve split it up into sections)\n\nDocumenting\n\n\n\nshow/hide check() Documenting output\n══ Documenting ═══════════════════════════════════════════════════════════\nℹ Updating gap documentation\nℹ Loading gap\n\n══ Building ═════════════════════════════════════════════════════════════\nSetting env vars:\n• CFLAGS    : -Wall -pedantic -fdiagnostics-color=always\n• CXXFLAGS  : -Wall -pedantic -fdiagnostics-color=always\n• CXX11FLAGS: -Wall -pedantic -fdiagnostics-color=always\n• CXX14FLAGS: -Wall -pedantic -fdiagnostics-color=always\n• CXX17FLAGS: -Wall -pedantic -fdiagnostics-color=always\n• CXX20FLAGS: -Wall -pedantic -fdiagnostics-color=always\n── R CMD build ──────────────────────────────────────────────────────────\n✔  checking for file '/projects/apps/gap/DESCRIPTION' ...\n─  preparing ‘gap’: (561ms)\n✔  checking DESCRIPTION meta-information ...\n─  installing the package to build vignettes\n✔  creating vignettes (5.6s)\n─  excluding invalid files\n   Subdirectory 'R' contains invalid file names:\n     ‘_disable_autoload.R’\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n─  building ‘gap_0.0.0.9000.tar.gz’\n\n\n\nChecking\n\n\n\nshow/hide check() Checking output\n══ Checking ══════════════════════════════════════════════════════════════\nSetting env vars:\n• _R_CHECK_CRAN_INCOMING_REMOTE_               : FALSE\n• _R_CHECK_CRAN_INCOMING_                      : FALSE\n• _R_CHECK_FORCE_SUGGESTS_                     : FALSE\n• _R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_: FALSE\n• NOT_CRAN                                     : true\n── R CMD check ───────────────────────────────────────────────────────────\n─  using log directory ‘/private/var/folders/0x/x5wkbhmx0k74tncn9swz7xpr0000gn/T/RtmpYiEbLJ/file75936b43aefb/gap.Rcheck’\n─  using R version 4.2.3 (2023-03-15)\n─  using platform: x86_64-apple-darwin17.0 (64-bit)\n─  using session charset: UTF-8\n─  using options ‘--no-manual --as-cran’\n✔  checking for file ‘gap/DESCRIPTION’\n─  this is package ‘gap’ version ‘0.0.0.9000’\n─  package encoding: UTF-8\n✔  checking package namespace information\n✔  checking package dependencies (2s)\n✔  checking if this is a source package ...\n✔  checking if there is a namespace\n✔  checking for executable files (592ms)\n✔  checking for hidden files and directories\n✔  checking for portable file names\n✔  checking for sufficient/correct file permissions\n✔  checking whether package ‘gap’ can be installed (5s)\n✔  checking installed package size\n✔  checking package directory ...\n✔  checking for future file timestamps ...\n✔  checking ‘build’ directory\n✔  checking DESCRIPTION meta-information ...\n✔  checking top-level files ...\n✔  checking for left-over files\n✔  checking index information ...\n✔  checking package subdirectories ...\n✔  checking R files for non-ASCII characters ...\n✔  checking R files for syntax errors ...\n✔  checking whether the package can be loaded (1.2s)\n✔  checking whether the package can be loaded with stated dependencies (1s)\n✔  checking whether the package can be unloaded cleanly (998ms)\n✔  checking whether the namespace can be loaded with stated dependencies (991ms)\n✔  checking whether the namespace can be unloaded cleanly (1.2s)\n✔  checking dependencies in R code (1.1s)\n✔  checking S3 generic/method consistency (2.1s)\n✔  checking replacement functions (1.1s)\n✔  checking foreign function calls (1.1s)\n✔  checking R code for possible problems (6.8s)\n✔  checking Rd files (406ms)\n✔  checking Rd metadata ...\n✔  checking Rd line widths ...\n✔  checking Rd cross-references ...\n✔  checking for missing documentation entries (1.2s)\nW  checking for code/documentation mismatches (2.4s)\n   Data codoc mismatches from documentation object 'movies':\n   Variables in data frame 'movies'\n     Code: actor1 actor2 actor3 actor4 actor5 audience_rating\n           audience_score best_actor_win best_actress_win best_dir_win\n           best_pic_nom best_pic_win critics_rating critics_score director\n           dvd_rel_date dvd_rel_day dvd_rel_month dvd_rel_year genre\n           imdb_num_votes imdb_rating imdb_url mpaa_rating rt_url runtime\n           studio thtr_rel_date thtr_rel_day thtr_rel_month thtr_rel_year\n           title title_type top200_box\n     Docs: actor1 actor2 actor3 actor4 actor5 audience_rating\n           audience_score best_actor_win best_actress_win best_dir_win\n           best_pic_nom best_pic_win critics_rating critics_score director\n           dvd_rel_date dvd_rel_day dvd_rel_month dvd_rel_year genre\n           imdb_num_votes imdb_rating imdb_url mpaa_rating rt_url runtime\n           studio thtr_rel_date thtr_rel_day thtr_rel_year title\n           title_type top200_box\n\n✔  checking Rd \\usage sections (3.4s)\n✔  checking Rd contents ...\n✔  checking for unstated dependencies in examples ...\n✔  checking contents of ‘data’ directory ...\n✔  checking data for non-ASCII characters ...\n✔  checking LazyData\n✔  checking data for ASCII and uncompressed saves ...\n✔  checking installed files from ‘inst/doc’\n✔  checking files in ‘vignettes’ ...\n✔  checking examples (2.4s)\n✔  checking examples with --run-donttest (2.8s)\n✔  checking for unstated dependencies in ‘tests’ ...\n─  checking tests ...\n\n\n\nspelling.R\n\n\n\nshow/hide check() spelling.R\n✔  Running ‘spelling.R’\nX  Comparing ‘spelling.Rout’ to ‘spelling.Rout.save’ ...\n   6,47d5\n   &lt; Potential spelling errors:\n   &lt;   WORD                   FOUND IN\n   &lt; CONFIG                 get_golem_config.Rd:17\n   &lt; Codecov                README.md:11\n   &lt; Config                 get_golem_config.Rd:5,25\n   &lt; HTLM                   with_red_star.Rd:10\n   &lt; IMDB                   movies.Rd:27,28,45,53\n   &lt; Theatre                movies.Rd:20,21,22\n   &lt; UI                     mod_plot_ui.Rd:5,13,16\n   &lt;                        mod_var_ui.Rd:5,13\n   &lt; Ventura                tests_and_coverage.Rmd:109\n   &lt; ackage                 README.md:6\n   &lt; actrss                 movies.Rd:36\n   &lt; br                     rep_br.Rd:5,10,13,16\n   &lt;                        tests_and_coverage.Rmd:82\n   &lt; config                 app_sys.Rd:15\n   &lt;                        get_golem_config.Rd:15,20,22\n   &lt;                        tests_and_coverage.Rmd:39,89\n   &lt; covr                   tests_and_coverage.Rmd:29,116\n   &lt; covrpage               tests_and_coverage.Rmd:24,117\n   &lt; darwin                 tests_and_coverage.Rmd:108\n   &lt; enurl                  tests_and_coverage.Rmd:83\n   &lt; goelm                  title:1\n   &lt; jq                     tests_and_coverage.Rmd:81\n   &lt; jquery                 jq_hide.Rd:5,13\n   &lt; li                     tests_and_coverage.Rmd:75,77\n   &lt; macOS                  tests_and_coverage.Rmd:109\n   &lt; na                     not_in.Rd:5,15\n   &lt;                        not_na.Rd:5,13\n   &lt;                        tests_and_coverage.Rmd:69\n   &lt; reactiveValues         rv.Rd:5,13\n   &lt; reactiveValuesToList   rvtl.Rd:5,13\n   &lt; rv                     tests_and_coverage.Rmd:73\n   &lt; rvtl                   tests_and_coverage.Rmd:73\n   &lt; sys                    tests_and_coverage.Rmd:88\n   &lt; tagRemoveAttributes    tests_and_coverage.Rmd:78\n   &lt; testthat               tests_and_coverage.Rmd:49,115\n   &lt; tibble                 point_plot.Rd:10\n   &lt; ui                  \n   tests_and_coverage.Rmd:37,41,54,74,74,75,75,76,76,77,77,78,78,79,\n   79,80,80,81,\n                          81,82,82,83,83,84,84,85,85,86,92,93\n   &lt; undisplay              tests_and_coverage.Rmd:79\n   &lt; ️                    tests_and_coverage.Rmd:97   \n\n\n\ntestthat.R\n\n\n\nshow/hide check() tests and coverage\n✔  Running ‘testthat.R’ (2.9s)\n✔  checking for unstated dependencies in vignettes ...\n✔  checking package vignettes in ‘inst/doc’\n✔  checking re-building of vignette outputs (1.6s)\n✔  checking for non-standard things in the check directory\n✔  checking for detritus in the temp directory\n\n   See\n     ‘/private/var/folders/0x/x5wkbhmx0k74tncn9swz7xpr0000gn/T/RtmpYiEbLJ/file75936b43aefb/gap.Rcheck/00check.log’\n   for details.\n\n\n\nR CMD check results\n\n\n\nshow/hide check() R CMD check\n── R CMD check results ──────────────────────────────────── gap 0.0.0.9000 ────\nDuration: 48.2s\n\n❯ checking for code/documentation mismatches ... WARNING\n  Data codoc mismatches from documentation object 'movies':\n  Variables in data frame 'movies'\n    Code: actor1 actor2 actor3 actor4 actor5 audience_rating\n          audience_score best_actor_win best_actress_win best_dir_win\n          best_pic_nom best_pic_win critics_rating critics_score director\n          dvd_rel_date dvd_rel_day dvd_rel_month dvd_rel_year genre\n          imdb_num_votes imdb_rating imdb_url mpaa_rating rt_url runtime\n          studio thtr_rel_date thtr_rel_day thtr_rel_month thtr_rel_year\n          title title_type top200_box\n    Docs: actor1 actor2 actor3 actor4 actor5 audience_rating\n          audience_score best_actor_win best_actress_win best_dir_win\n          best_pic_nom best_pic_win critics_rating critics_score director\n          dvd_rel_date dvd_rel_day dvd_rel_month dvd_rel_year genre\n          imdb_num_votes imdb_rating imdb_url mpaa_rating rt_url runtime\n          studio thtr_rel_date thtr_rel_day thtr_rel_year title\n          title_type top200_box\n\n0 errors ✔ | 1 warning ✖ | 0 notes ✔\n\n\nrhub::check_for_cran(): “run check_for_cran() and assign the result to an object” … “use the cran_summary() method to get a message that you can copy-paste in your cran-comments.md file” - rhub\n\n\n\n\n\n\n\nImportantdevtools::check(): Highly recommend\n\n\n\n\n\n\nIt’s easy to forget some of the development workflow steps while you’re creating an app-package–devtools::check() makes it easier to ensure you’re building a robust package (and app!).\n\n\n\n\n\n\nLocal, CRAN or Package Manager\ndevtools::build() is also a regular part of the package development process. This function will source and bundle your package (learn the differences here).\n\n# Deploy\n\n## Local, CRAN or Package Manager ----\n## This will build a tar.gz that can be installed locally,\n## sent to CRAN, or to a package manager\ndevtools::build()\n\nThis will create a gap_0.0.0.9000.tar.gz file to share or submit to a package management system.\n\n── R CMD build ───────────────────────────────────────────────────────────────\n✔  checking for file ‘/projects/apps/gap/DESCRIPTION’ ...\n─  preparing ‘gap’: (613ms)\n✔  checking DESCRIPTION meta-information ...\n─  installing the package to build vignettes\n✔  creating vignettes (6.6s)\n─  excluding invalid files\n   Subdirectory 'R' contains invalid file names:\n     ‘_disable_autoload.R’\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n─  building ‘gap_0.0.0.9000.tar.gz’\n   \n[1] \"/projects/apps/gap_0.0.0.9000.tar.gz\"\n\n\ndevtools::install() is another common development workflow function.\n\n\n\nRStudio\nTo deploy an application with RStudio (Posit) products, use of the functions below:\n\n## RStudio ----\n## If you want to deploy on RStudio related platforms\ngolem::add_rstudioconnect_file()\ngolem::add_shinyappsio_file()\ngolem::add_shinyserver_file()\n\n\ngolem::add_rstudioconnect_file()\n\ngolem::add_shinyappsio_file()\n\ngolem::add_shinyserver_file()\n\n\n\nDocker\nIf you use Docker to deploy applications, you can use the following functions:\n\n\nshow/hide docker functions\n## Docker ----\n## If you want to deploy via a generic Dockerfile\ngolem::add_dockerfile_with_renv()\n\n## If you want to deploy to ShinyProxy\ngolem::add_dockerfile_with_renv_shinyproxy()\n\n\nRead more:\n\ngolem::add_dockerfile_with_renv()\n\ngolem::add_dockerfile_with_renv_shinyproxy()\n\n\n\napp.R\nI’ll deploy my app using shinyapps.io, so after running golem::add_shinyappsio_file() I will see the following output and a new app.R file.\n\ngolem::add_shinyappsio_file()\n\n\n── Creating _disable_autoload.R ──────────────────────────────────\n✔ Created\n✔ Setting active project to '/Users/mjfrigaard/projects/gap'\n✔ Adding '^app\\\\.R$' to '.Rbuildignore'\n✔ Adding '^rsconnect$' to '.Rbuildignore'\n✔ Adding 'pkgload' to Imports field in DESCRIPTION\n• Refer to functions with `pkgload::fun()`\n✔ File created at /Users/mjfrigaard/projects/gap/app.R\nTo deploy, run:\n• rsconnect::deployApp()\n\n• Note that you'll need to upload the whole package to ShinyApps.io\n\n\nView the app.R file contents below:\n\n\n# Launch the ShinyApp (Do not remove this comment)\n# To deploy, run: rsconnect::deployApp()\n# Or use the blue button on top of this file\npkgload::load_all(export_all = FALSE, helpers = FALSE, attach_testthat = FALSE)\noptions( \"golem.app.prod\" = TRUE)\ngap::run_app() # add parameters here (if any)\n\n\n\n\n\n\n\nImportantapp.R: Highly recommend\n\n\n\n\n\n\nBeing able to run your application from app.R is helpful because it performs a few preliminary operations before launching:\n\npkgload::load_all(): ‘It roughly simulates what happens when a package is installed and loaded with library(), without having to first install the package’\noptions('golem.app.prod' = TRUE): ‘use functions in your back-end for development purposes, that will be ignored in production’\n\n\n\n\n\n\n\ndeployApp()\nThe rsconnect::deployApp() function will deploy the application to the shinyapps.io site (provided you have an account).\n\nrsconnect::deployApp(appName = \"gap-movies\")\n\n\nPreparing to deploy application...DONE\nUploading bundle for application: 9468261...DONE\nDeploying bundle: 7466839 for application: 9468261 ...\nWaiting for task: 1319021708\n  building: Parsing manifest\n  building: Building image: 8845318\n  building: Installing system dependencies\n  building: Fetching packages\n  building: Building package: pkgload\n  building: Building package: testthat\n  building: Installing files\n  building: Pushing image: 8845318\n  deploying: Starting instances\n  rollforward: Activating new instances\n  success: Stopping old instances\nApplication successfully deployed to https://mjfrigaard.shinyapps.io/gap-movies/\n\n\n\n\n\n\n\nCautionrsconnect::deployApp(): Recommend\n\n\n\n\n\n\nThe rsconnect::deployApp() function is helpful for quickly deploying a shiny app-package. I provide the appName because gap is not long enough, but there are other useful arguments for deploying an app into production.\n\n\n\n\n\n\n\nEnd 03_deploy.R\nView the deployed application here."
  },
  {
    "objectID": "series/shiny-frameworks/golem/index.html#recap",
    "href": "series/shiny-frameworks/golem/index.html#recap",
    "title": "golem shiny app-packages",
    "section": "Recap",
    "text": "Recap\nBuilding an application with golem is very similar to developing an R package. The overall process remains the same: New code is placed in R/, external resources are placed in inst/, tests are stored and run from tests/testthat/, etc. The figure below displays how the golem framework works within the R package structure to create ‘production-grade shiny applications’:\n\n\n\n\n\n\n\n\n\n\n(a) golem app-package\n\n\n\n\n\nFigure 4: golem framework overview\n\n\n\n\nI didn’t cover using renv with this app-package, but you can read more about this in the Using {renv} section."
  },
  {
    "objectID": "series/shiny-frameworks/rhino/index.html",
    "href": "series/shiny-frameworks/rhino/index.html",
    "title": "rhino shiny apps",
    "section": "",
    "text": "ImportantALERT!\n\n\n\n\n\n\nThis post is currently under development. Thank you for your patience.\n\n\n\n\nThis post is another walk-through of a Shiny application using the rhino framework. rhino is designed to, ’Build high quality, enterprise-grade Shiny apps at speed.’–I’ll go through developing a rhino shiny app (and how it’s different from other app-packages).\n\ninstall.packages(\"remotes\")\nremotes::install_github(\"Appsilon/rhino\")\n\nFor consistency, I’ll be using the application from RStudio’s Building Web Applications with Shiny course. These materials are a great resource if you’re new to shiny–even if you’re aren’t, it’s still worth checking out–plus it’s free!"
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html",
    "href": "series/testing/p3-shiny-module-tests/index.html",
    "title": "Testing Shiny modules",
    "section": "",
    "text": "ImportantUpdates to series\n\n\n\n\n\n\nThis series on testing has been updated with recent changes in testthat, shinytest2, and other packages to improve testing.\nThis is the third post in a series on testing shiny applications. I’ll cover testing shiny module server functions using the testhat package and shiny’s testServer() function."
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#testing-shiny-modules",
    "href": "series/testing/p3-shiny-module-tests/index.html#testing-shiny-modules",
    "title": "Testing Shiny modules",
    "section": "Testing shiny modules",
    "text": "Testing shiny modules\n\n\n\nShiny functions pose a couple of unique challenges for testing. First, we can’t execute shiny server functions in the console. Second, as Shiny apps become more complex, it’s highly recommended to break up the code base into modules. Modules have additional challenges due to their reactivity being split between interconnected UI and server functions.\nThe shiny package doesn’t provide a direct, built-in way to test modules, but the testServer() function addresses these challenges by testing “reactive interactions” in module server functions. testServer() also works with testthat, which means we can structure these ‘reactive interaction’ tests just like other unit tests (for non-application functions)."
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#a-shiny-app-package",
    "href": "series/testing/p3-shiny-module-tests/index.html#a-shiny-app-package",
    "title": "Testing Shiny modules",
    "section": "A Shiny App-Package",
    "text": "A Shiny App-Package\ntestthat is designed to work within an R package, and the mstsap branch of sapkgs has a Mastering Shiny testServer app-package to demonstrate writing tests with testServer().\nThe functions, modules, and applications in mstsap come from the Shiny Modules chapter of Mastering Shiny.1 If you haven’t read this chapter–start there.\n\n# to get the mstsap package used in this post:\ndevtools::load_all()\nlibrary(mstsap)\n\n\n\n\n\n\n\nTipWhy create an app-package?\n\n\n\n\n\n\nA shiny app-package is a shiny application that’s been developed as (or converted to) an R package. The benefits of storing shiny apps in R packages have been well documented, but I’ll summarize just a few that are specific to testing:\n\nStandardized folder structure:\n\nIf unit tests are performed with testthat, minimal setup is required to perform tests.\nusethis::use_testthat() sets up test files in the tests/testthat/ folder (to test the code in the R/ folder)\n\nRead more about using testthat with R packages here.\n\nTest extras:\n\nTest data can be placed in tests/testthat/&lt;test dir&gt;/&lt;test_data.rds&gt;\n\nThe code used to create the test data should be placed in make_&lt;test_data.rds&gt;\n\nAdditional testing functions can be stored in tests/testthat/helpers.R\n\nRead more about test helpers here.\n\nDevelopment tools:\n\nIf you’re using RStudio, tests can be run individually (testthat::test_file()) or collectively (devtools::test()), and code helpers and data are loaded using devtools::load_all()\n\nTests created with testthat remain isolated during development\n\nRead more about developing packages with RStudio in the R Packages text."
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#modules",
    "href": "series/testing/p3-shiny-module-tests/index.html#modules",
    "title": "Testing Shiny modules",
    "section": "Modules",
    "text": "Modules\nIn a previous post, I used the following definition for unit tests,\n\n“A unit test is a piece of code that invokes a unit of work and checks one specific end result of that unit of work.” - The Art of Unit Testing, 2nd edition\n\nShiny modules can also be broken into discrete ‘units of work’ with expected ‘end results.’ Modules are ‘a pair of UI and server functions’ designed to compartmentalize input and output IDs into distinct namespaces.2\n\n\n\n\n\n\nNoteShiny module refresher\n\n\n\n\n\nModule UI functions typically wrap the layout, input, and output functions in tagList(). Module server functions contain the ‘backend’ code that typically goes in a shiny server function. Both the UI and server module functions are linked by an id argument, which is created using NS() (namespace) in the UI function, and called in the server function with moduleServer().\n\nModule UI functions\nBelow is an example module UI function:\n\nmod_fun_ui &lt;- function(id) {\n  tagList(\n    numericInput(inputId = NS(namespace = id, id = \"num_input\")),\n    uiOutput(outputId = NS(namespace = id, id = \"num_out\"))\n  )\n}\n\n\nmod_fun_ui creates a dedicated namespace for one inputId and one outputId with shiny::NS():\n\n█─mod_fun_ui \n├─id \n└─█─tagList \n  ├─█─numericInput \n  │ └─inputId = █─NS \n  │             ├─namespace = id \n  │             └─id = \"num_input\" \n  └─█─uiOutput \n    └─outputId = █─NS \n                 ├─namespace = id \n                 └─id = \"num_out\" \n\n\n\n\nModule server functions\nThe corresponding module server function is below:\n\nmod_fun_server &lt;- function(id) {\n        moduleServer(id, function(input, output, session) {\n            ns &lt;- session\n          output$num_out &lt;- uiOutput(outputId = input$num_input)\n      })\n}\n\n\nThe code to render the reactive input$num_input with output$num_out is contained in the nested call to moduleServer()\n\n█─mod_fun_server \n├─id \n└─█─moduleServer \n  ├─id = id \n  ├─server = █─`function(input, output, session)` \n  │          ├─`ns &lt;- session` \n  │          ├─`output$num_out &lt;-` \n  │          └─█─renderUI \n  │            └─`input$num_input` \n  └─session = session \n\n\n\n\nUsing modules\nBoth module functions are combined in the ui and server arguments of shinyApp():\n\nshinyApp(\n    ui = fluidPage(\n          mod_fun_ui(id = \"mod\")\n        ),\n   server = function(input, output, session) \n          mod_fun_server(\"mod\")\n  )\n\n\nThe id arguments connect the UI and server functions to communicate between the UI and backend of the app:\n\n█─shinyApp \n├─ui = █─fluidPage \n│      └─█─mod_fun_ui \n│        └─id = \"mod namespace\" \n└─server = █─`function(input, output, session)` \n           └─█─mod_fun_server \n             └─id = \"mod namespace\" \n\n\nI recommend creating test files when you create module files (i.e., with usethis::use_r() & usethis::use_test()).\n\n\n\n\nHowever, the ‘unit of work’ for a Shiny module might be accomplished with a combination of a module UI and server functions, and a helper/utility function.\nmstsap contains three modules: dataset, selectVar, and selectDataVar. If you’re like more information on these modules, click on the links below.\n\n1) Dataset input module\n\n\n\n\n\n\n\n\n\n\ndatasetInput/datasetServer: loads and returns data object from the datasets package (filtered by data frames or matrices)\n\n\n\nThe objects from datasets are filtered in the UI module function with a filter argument that can be used to “limit the options to built-in datasets that are either data frames (filter = is.data.frame) or matrices (filter = is.matrix)”. The names are passed to the choices in the selectInput():\n\n\nshow/hide choices in datasetInput()\nnames &lt;- ls(\"package:datasets\")\n  if (!is.null(filter)) {\n    data &lt;- lapply(names, get, \"package:datasets\")\n    names &lt;- names[vapply(data, filter, logical(1))]\n  }\n\n\nThe datasets object is returned with get() (wrapped in reactive()). See below:\n\n\nshow/hide returned data from datasetServer()\nshiny::reactive(\n      get(input$dataset, \"package:datasets\")\n    )\n\n\n\n\n2) selectVar module\n\n\n\n\n\n\n\n\n\n\nselectVarInput/selectVarServer: displays a selectInput() that “allows the user to select variables of specified type from a given reactive dataset.”\n\n\n\nThe data argument in selectVarServer() is the returned value from datasetServer(). The data() is used with the filter argument in the find_vars() function:\n\n\nshow/hide find_vars()\nfind_vars &lt;- function(data, filter) {\n # I've included the updated version with the 'stopifnot()' checks!\n  stopifnot(is.data.frame(data))\n  stopifnot(is.function(filter))\n  names(data)[vapply(data, filter, logical(1))]\n}\n\n\nThe filter argument can be used to return variables by class/type (using is.* functions like is.numeric() or is.character()).\nWhen data() changes, the output from find_vars() updates the choices in the variable selectInput() (i.e., input$var). See below:\n\n\n\n\n\nselectVarServer() also returns the selected variable (input$var) as a reactive value (var())\n\n\n3) selectDataVar module\n\n\n\n\n\n\n\n\n\n\nselectDataVarUI/selectDataVarServer: The selectDataVar module is from the section titled, “Modules inside of modules”, so here we see the dataset and selectVar modules placed inside the selectDataVar module (each with a new namespace (NS())).\n\n\n\n\n\n\n\n\n\nNoteNaming modules\n\n\n\n\n\n\nWhen creating an app-packages, modules are stored in the R/ folder as a single file, typically following a naming convention that differentiates modules from the other package functions. The modules in this post use camelCase, with suffix variations (i.e., Input/Server and UI/Server) for each functions. Other options come from the golem and leprechaun packages.\ngolem modules are created with golem::add_module()\n\n\n\nexpand to see golem::add_module(“inputs”)\nmod_inputs_ui &lt;- function(id){\n  ns &lt;- NS(id)\n  tagList(\n  )\n}\nmod_inputs_server &lt;- function(id){\n  moduleServer( id, function(input, output, session){\n    ns &lt;- session$ns\n \n  })\n}\n## To be copied in the UI\n# mod_inputs_ui(\"inputs_1\")\n    \n## To be copied in the server\n# mod_inputs_server(\"inputs_1\")\n\n\n\ngolem modules the following naming convention:\n\nAll new module functions have a mod_ prefix\ngolem module functions are differentiated with either a _ui or _server suffix\nNew golem module files are named R/mod_&lt;name&gt;.R\n\nleprechaun modules are also created with a leprechaun::add_module() function.\n\n\n\nexpand to see leprechaun::add_module(“inputs”)\ninputsUI &lt;- function(id){\n    ns &lt;- NS(id)\n    tagList(\n        h2(\"inputs\")\n    )\n}\ninputs_server &lt;- function(id){\n  moduleServer(id, function(input, output, session) {\n                ns &lt;- session$ns\n                send_message &lt;- make_send_message(session)\n                # your code here\n        }\n    )\n}\n# UI\n# inputsUI('id')\n\n# server\n# inputs_server('id')\n\n\n\nleprechaun modules have a slightly different naming convention:\n\nAll new UI module functions have a UI suffix\nAll new module server functions have a _server suffix\nleprechaun module functions do not have a prefix\nNew leprechaun modules named module_&lt;name&gt;.R\n\nShiny app-packages often require multiple modules and utility functions, so uniform names will make it easier to manage (and test!) your code."
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#standalone-app-functions",
    "href": "series/testing/p3-shiny-module-tests/index.html#standalone-app-functions",
    "title": "Testing Shiny modules",
    "section": "Standalone App Functions",
    "text": "Standalone App Functions\nmstsap contains three standalone functions for running each set of module functions.\nI’ve made a small change to each standalone app function–each app has a call to reactiveValuesToList() that displays in the UI.\n\n\nprint reactive values\n  shiny::verbatimTextOutput(\"vals\")\n\n  output$vals &lt;- shiny::renderPrint({\n    x &lt;- shiny::reactiveValuesToList(input,\n                            all.names = TRUE)\n    print(x)\n  })\n\n\n\ndatasetApp\n\n\n\n\n\n\n\n\n\n\ndatasetApp() contains a call to the dataset module, and includes a tableOutput() to render the selected data object:\n\n\n\nWhen datasetApp() is run, the app displays the dataset object in the tableOutput(), and the verbatimTextOutput() renders the reactive values as a text:\n\n\n\n\n\n\nFigure 1\n\n\n\nThe output above shows what NS() does in the dataset module–it appends the module id argument to the inputId (which is why we see dataset-dataset).\n\ndataset-: the module id\ndataset-dataset the inputId from the selectInput()\n\n\n\nselectVarApp\n\n\n\n\n\n\n\n\n\n\nselectVarApp() includes both dataset and selectVar modules, but instead of rendering the output in a table, the UI renders the variable output in a verbatimTextOutput().\n\n\n\nNote that selectVarApp() contains namespaces for two modules:\n\n\"data\": the namespace for the datasetnput() and datasetServer() modules, inheriting the filter argument and creating the data object\n\"var\": the selectVar modules are linked with the \"var\" id. selectVarServer() uses the data object created by datasetServer() (and also inherits the filter argument).\n\nThese namespaced IDs are rendered below with reactiveValuesToList():\n\n\n\n\n\nThere’s a lot happening in selectVarApp(), so I’ve created the figure below to display the code for the modules with their displayed outputs:\n\n\n\n\n\n\n\nAs we can see, the data output from the dataset module is used to generate the vars() reactive for the verbatimTextOutput() in selectVarApp(). Note that both dataset and selectVar modules don’t contain any output functions–these have been provided in the UI for both datasetApp() and selectVarApp().\n\n\nselectDataVarApp\n\n\n\n\n\n\n\n\n\n\nThe final app in mstsap is selectDataVarApp(). Here the inputs from dataset and selectVar have been moved into the sidebarPanel(), and the output is rendered in the mainPanel().\n\n\n\nThe reactive values here show how the ‘Modules inside of modules’ work–by adding the additional call to NS() in the datasetInput() and selectVarInput() functions within selectDataVarUI() and selectDataVarServer(), an additional namespace is appended to the reactive values (input$dataset and input$var):\n\n\n\n\n\n\n\n\n\n(a) selectDataVarApp with reactive values\n\n\n\n\n\nFigure 2: selectDataVarApp with reactiveValuesToList()\n\n\n\nBelow is a figure that displays the contents of the selectDataVar modules (I’ve removed the tagList() and moduleServer() for simplicity), the selectDataVarApp(), and the rendered outputs:\n\n\n\n\n\n\n\n\n\n\n(a) selectDataVarApp schema\n\n\n\n\n\nFigure 3: dataset and selectVar modules inside selectDataVar module with rendered outputs"
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#testserver",
    "href": "series/testing/p3-shiny-module-tests/index.html#testserver",
    "title": "Testing Shiny modules",
    "section": "testServer()",
    "text": "testServer()\nModule server functions can be tested the same way as a traditional shiny server function, as long as you provide the inputs and verify the correct outputs. Below I’ll cover some general advice on module server tests (and the arguments in testServer()).\n\nWhat should I test?\nThe best bit of advice I’ve found helpful when writing tests comes from R Packages,\n\n“focus your time on code that you’re not sure about, is fragile, or has complicated interdependencies”\n\nThe quote isn’t in reference to testing modules or Shiny application functions, but I’ve found it’s easy to fall into the trap of trying to test everything when a targeted approach is more efficient (and equally valid).\nThe items below have been compiled from Mastering Shiny, R Packages, and Engineering Production-Grade Shiny Apps:\n\nDo the inputs/outputs behave as expected?\n\nThese tests verify the module server function inputIds and outputIds are properly namespaced and accessible\n\nDoes the module contain the expected reactive values/objects?\n\nTests should verify it’s reactivity–module server functions will automatically recompute the outputs when it’s inputs change, so tests should verify changes to inputs produce the expected behaviors and outputs. This includes any returned values from the module (and any additional function arguments).\n\nAre the calculations correct?\n\nIf the module server function performs calculations or data manipulations, the tests should verify the module produces the correct result (ideally for a variety of inputs and edge cases).\n\nHow are errors handled in the module?\n\nWhat errors are displayed from the module? Tests should simulate scenarios that can test if the module: 1) returns errors that are informative, 2) fails silently (when appropriate), or 3) falls back to the correct default behavior.\n\n\nThe first test I’ll perform is for datasetServer(), the module used to return a data object from the datasets package.\n\n\nArguments\ntestServer() has the following arguments:\n\napp can be a module server function (i.e., datasetServer), or any shiny.appobj\nexpr is where I’ll add the testthat expectations and other test code\nargs is a list() I can use to include any module server function arguments\n\n\n\nTesting inputs\nI’ll start by testing if the initial input value (input$dataset) in datasetServer() is set to NULL. The module server function is the first argument in testServer():\n\ntestServer(app = datasetServer, expr = {\n  expect_equal(input$dataset, NULL)\n  cat(\"\\ndatasetServer: dataset$input is NULL\", \"\\n\")\n})\n\n\nAdd custom messages with cat() and the inputId we’re testing. Then load, document, and install the package\ndevtools::load_all()\nℹ Loading mstsap\ndevtools::document()\nℹ Updating mstsap documentation\nℹ Loading mstsap\n\nRestarting R session...\n\nlibrary(mstsap)\n\nAnd run the test with testthat::test_file():\n\n\ntest_file(\"tests/testthat/test-datasetServer.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\ndatasetServer: dataset$input is NULL \n\ntitle-meta: “Creating test messages with testServer()”\n\ncallout-icon: false\nfreeze: true\nexecute: echo: true message: false warning: false eval: false —\n\n\n\n\n\n\nNoteTest comments with testServer()\n\n\n\n\n\n\nThe testServer() documentation has examples of using cat() to create custom messages. I put a function for creating testServer() messages (test_cmt()) in the helper.R file (read more about test helpers here).\nIt has two arguments (test and msg), and makes it easy to print messages to the console while I’m developing tests.\n\ntest_cmt(test = \"mod_server_function\", msg = \"test contents\")\n\n       mod_server_function: test contents \n\n\n\n\n\n\nSetting test inputs\ntestServer() allows us to mimic changing application (or module) inputIds with session$setInputs() like so:\n\nsession$setInputs(inputId = \"value\")\n\nBelow is a test for input$dataset in datasetServer():\n\n  session$setInputs(dataset = \"faithful\")\n  expect_equal(\n    object = input$dataset,\n    expected = \"faithful\")\n  test_cmt(\"datasetServer\", \"dataset$input\")\n\n\n\n\nReturned values\nAny returned values from module server functions can be accessed in testServer() with session$returned(). I’ll verify input$dataset returns an object from datasetServer() by testing the class of session$returned():\n\n\nshow/hide test with session$returned()\n  session$setInputs(dataset = \"airquality\")\n  expect_equal(\n    object = class(session$returned()),\n    expected = \"data.frame\")\n  test_cmt(\"datasetServer\", \"class(session$returned())\")\n\n  session$setInputs(dataset = \"WorldPhones\")\n  expect_true(\n    object = is.matrix(session$returned()))\n  test_cmt(\"datasetServer\", \"is.matrix(session$returned())\")\n\n\nNote that both methods above can be used to check the class of the returned object.\n\nI can also use the typeof(datasets::mtcars) for a direct comparison:\n\n\nshow/hide test with session$returned()\n  session$setInputs(dataset = \"mtcars\")\n  expect_equal(\n    # app value...\n    object = typeof(session$returned()), \n    # ...compared to actual output\n    expected = typeof(datasets::mtcars)) \n  test_cmt(\"datasetServer\", \"typeof(session$returned())\")\n\n\n\n\n\nServer function arguments\nIf the module server function has additional arguments beyond id, then it has additional functionality to verify with unit tests. To test additional module server arguments, pass these to testServer(args = list()). The args list should include named arguments from the module server function, i.e., list(param1 = \"value1\", param2 = \"value2\").\nFor example, selectVarServer() has data and filter arguments:\n\ndata is the returned reactive object from datasetServer()\nfilter is the function passed to the find_vars() utility function\n\n\n\n\n\n\n\n\n\n\n\n(a) dataset() -&gt; selectVar()\n\n\n\n\n\nFigure 4: Object returned from datasetServer() and passed to selectVarServer()\n\n\n\n\nBelow is a test for selectVarServer() using args to verify the reactive data() is datasets::mtcars:\n\ntestServer(selectVarServer,\n  args = list(data = mtcars,\n              filter = is.numeric), expr = {\n  expect_true(\n    object = is.reactive(data))\n  test_cmt(\"selectVarServer\", \"is.reactive(data())\")\n})\n\n\nBut this fails with the following error:\n\n\ntest_file(\"tests/testthat/test-selectVarServer.R\")\n\n[ FAIL 1 | WARN 0 | SKIP 0 | PASS 0 ]\n── Error (test-selectVarServer.R:1:1): (code run outside of `test_that()`) ───\nError in `(function (id, data, filter = is.numeric) \n\nWhat happened?\n\nI’ve included this example because it’s not in the testServer() documentation, and it’s common to pass values between modules (see here in Engineering Production-Grade Shiny Apps and here in Mastering Shiny)\n\nTesting module communication\nThe error message above tells me the issue is originating from the stopifnot() calls in selectVarServer().\n\n\n\n\n\n\nImportantUpdating selectVarServer() and find_vars()\n\n\n\n\n\n\nBoth selectVarServer() and find_vars() are updated from their original versions to include stopifnot() checks for is.reactive(), is.data.frame() and is.function():\n\nOriginal versions:\n\nfind_vars &lt;- function(data, filter) {\n  names(data)[vapply(data, filter, logical(1))]\n}\n\n\nselectVarServer &lt;- function(id, data, filter = is.numeric) {\n  moduleServer(id, function(input, output, session) {\n    observeEvent(data(), {\n      updateSelectInput(session, \"var\", choices = find_vars(data(), filter))\n    })\n\n    reactive(data()[[input$var]])\n  })\n}\n\nUpdated versions:\n\nselectVarServer &lt;- function(id, data, filter = is.numeric) {\n\n  stopifnot(is.reactive(data))\n  stopifnot(!is.reactive(filter))\n\n  moduleServer(id, function(input, output, session) {\n    observeEvent(data(), {\n      updateSelectInput(session = session, \n        inputId = \"var\", \n        choices = find_vars(data(), filter)\n        )\n    })\n\n    reactive(data()[[input$var]])\n  })\n}\n\n\nfind_vars &lt;- function(data, filter) {\n  stopifnot(is.data.frame(data))\n  stopifnot(is.function(filter))\n  names(data)[vapply(data, filter, logical(1))]\n}\n\n\n\n\n\n\nI’ll stop a moment here to address what’s happening in each module:\n\nThe datasetServer() returns the results of input$dataset as a reactive (data())\ndata() enters selectVarServer() in the data argument\nInside selectVarServer(), two stopifnot() functions evaluate the reactivity of data and filter with shiny::is.reactive()\n\nIn datasetServer(), the return object is wrapped in the reactive() function, so the items args = list() also need to be wrapped in reactive().\nI’ll re-write the test above to a more basic test using is.reactive():\n\ntestServer(selectVarServer,\n  args = list(data = reactive(mtcars), \n              filter = is.numeric), expr = {\n  expect_true(\n    object = is.reactive(data()))\n  test_cmt(\"selectVarServer\", \"is.reactive(data())\")\n})\n\n\ntest_file(\"tests/testthat/test-selectVarServer.R\")\n\n[ FAIL 1 | WARN 0 | SKIP 0 | PASS 0 ]\n       selectVarServer: is.reactive(data()) \n── Failure (test-selectVarServer.R:1:1): (code run outside of `test_that()`) ───\nis.reactive(data()) is not TRUE\n\n`actual`:   FALSE\n`expected`: TRUE \n\nAnother failure???\n\nThe results of this test might seem confusing given my advice to wrap the args list in reactive(), but some reading of the x argument in is.reactive() will clear up the error:\n\nFor is.reactive(), an object to test. For reactive(), an expression.\n\nRemoving the parentheses from data() will result in the proper test results:\n\ntestServer(selectVarServer,\n  args = list(data = reactive(mtcars), \n              filter = is.numeric), expr = {\n  expect_true(\n    object = is.reactive(data))\n  test_cmt(\"selectVarServer\", \"is.reactive(data())\")\n})\n\n\ntest_file(\"tests/testthat/test-selectVarServer.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\n       selectVarServer: is.reactive(data()) \nNow that I have a reactive data() input, I can explore how this value is used inside selectVarServer(). To update input$var, the data() input is passed to find_vars() (a function that uses a filter argument “used to select which variables to list”). See the example below:\n\nfind_vars(\n  data = chickwts, \n  filter = is.factor)\n\n#&gt; [1] \"feed\"\nI’ll write an expectation that captures the behavior of find_vars() in selectVarServer():\n\ntestServer(selectVarServer,\n  args = list(data = reactive(chickwts),\n              filter = is.numeric), expr = {\n  expect_equal(\n    object = find_vars(data(), is.factor),\n    expected = \"feed\")\n  test_cmt(\"selectVarServer\", \"find_vars()\")\n})\n\nTo verify that the returned object from selectVarServer() is the selected column, I’ll need to simulate the application behavior in the tests:\n\nCreate a reactive data() input in selectVarServer():\n\n\nsetting args = list()\n  testServer(selectVarServer,\n    args = list(data = reactive(chickwts),\n                filter = is.numeric), expr = {\n\n    # include expectations below...\n\n  })\n\n\nSet the input$var and verify the input$var:\n\n\nverify input$var\n  session$setInputs(var = \"weight\")\n  expect_equal(object = input$var,\n      expected = \"weight\")\n  test_cmt(\"selectVarServer\", \"input$var\")\n\n\nSet the input$var and verify the session$returned()\n\n\nverify session$returned()\n  session$setInputs(var = \"feed\")\n  expect_equal(object = session$returned(),\n    expected = chickwts[[\"feed\"]])\n  test_cmt(\"selectVarServer\", \"session$returned()\")\n\n\n\n\n\n\nModule outputs\nRendered outputs can be accessed in testServer() just like inputs (i.e., with output$outputId). But the modules in mstsap don’t have outputs–these are included in the standalone app functions (datasetApp(), selectVarApp(), and selectDaraVarApp()).\nFortunately, app functions can also be passed to the app argument of testServer(). I’ll use datasetApp() to demonstrate.\n\n\n\n\n\n\n\n\n\n\nds_app &lt;- datasetApp()\n  testServer(ds_app, \n    expr = {\n\n  })\n\n\n\nTesting a standalone app function is similar to testing a module server function, but with a few minor differences. First, the output from the standalone app function is assigned to an object (ds_app), then placed in the app argument.\nTo use session$setInputs() need to include the namespace for the inputId. The output from reactiveValuesToList() in datasetApp() shows me how to access the inputId in the datasetServer() module (i.e., input$`dataset-dataset`):\n\n\n\n\n\n\n\n\n\n\nds_app &lt;- datasetApp()\ntestServer(ds_app, \nexpr = {\n  session$setInputs(\n  `dataset-dataset` = \"chickwts\")\n})\n\n\n\nTesting outputs with testServer() is different than testing outputs in regular unit tests, because Shiny outputs are executed in the server, but then rendered as HTML in the UI. testServer() outlines a testing strategy for complex outputs:\n\n*The goal for your tests should be to ask “is the code that I wrote producing the plot I want?” There are two components to that question:\n\nDoes the plot generate without producing an error?\nIs the plot visually correct?\n\ntestServer is great for assessing the first component here. By merely referencing output$plot in your test, you’ll confirm that the plot was generated without an error.\n\nIf we replace plot with table in the advice above, the tests for datasetApp() should confirm output$data is generated without producing an error.\nInstead of writing an expectation, we’ll use cat() to display the contents of output$data after setting the `dataset-dataset` input:\n\nds_app &lt;- datasetApp()\ntestServer(ds_app, expr = {\n  session$setInputs(`dataset-dataset` = \"chickwts\")\n  cat(\"\\n\\toutput$data:\\n\", output$data, \"\\n\")\n})\n\nThe results from the test is below:\n\ntest_file(\"tests/testthat/test-datasetApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 0 ]\n    output$data:\n &lt;table  class = 'table shiny-table table- spacing-s' style = 'width:auto;'&gt;\n  &lt;thead&gt; \n      &lt;tr&gt; \n        &lt;th style='text-align: right;'&gt; weight &lt;/th&gt; \n        &lt;th style='text-align: left;'&gt; feed &lt;/th&gt;  \n     &lt;/tr&gt; \n    &lt;/thead&gt; \n      &lt;tbody&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 179.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 160.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 136.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 227.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 217.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td align=\"right\"&gt; 168.00 &lt;/td&gt; &lt;td&gt; horsebean &lt;/td&gt; &lt;/tr&gt;\n   &lt;/tbody&gt; \n &lt;/table&gt; \nThe output is the HTML used to render the table in the UI. This doesn’t add a passing test, but it confirms that the table is being generated from the data() reactive.\nThe tests for datasetApp() will confirm the inputId, and verify the class and names of the data() reactive (which will be passed to the renderTable() function):\n\n  expect_equal(\n    object = input$`dataset-dataset`,\n    expected = \"chickwts\")\n  test_cmt(\"datasetApp\", \"input$`dataset-dataset`\")\n\n  expect_true(\n    object = is.data.frame(data()))\n  test_cmt(\"datasetApp\", \"is.data.frame(data())\")\n\n  expect_equal(\n    object = names(data()),\n    expected = names(datasets::chickwts))\n  test_cmt(\"datasetApp\", \"names(data())\")\n\nI can include a test for the class of output$data, but note that this is a character output:\n\nexpect_equal(\n  object = class(output$data),\n  expected = \"character\")\ntest_cmt(\"datasetApp\", \"class(output$data)\")\n\nThe same method can be used to test the selectVarApp(), but note this app requires passing both inputIds to session$setInputs():\n\n\nshow/hide selectVarApp() tests\nsv_app &lt;- selectVarApp()\ntestServer(app = sv_app, expr = {\n  session$setInputs(`var-var` = \"Ozone\",\n                    `data-dataset` = \"airquality\")\n  # confirm contents of output$out\n  cat(\"\\n\\toutput$out:\\n\", output$out, \"\\n\")\n  \n  # confirm var is reactive \n  expect_true(object = is.reactive(var))\n  # confirm var input\n  expect_equal(\n    object = input$`var-var`,\n    expected = \"Ozone\")\n  # confirm data is reactive\n  expect_true(object = is.reactive(data))\n  # confirm data() is a data.frame\n  expect_true(\n    object = is.data.frame(data()))\n  # confirm 'data' can be subsetted with 'var'\n  expect_equal(\n    object = data()[[input$`var-var`]],\n    expected = airquality[[\"Ozone\"]])\n})\n\n\n\nTesting nested modules\nI highly recommend viewing the output of reactiveValuesToList() if your application has nested modules. It’s easy to lose track of ids if they span multiple layers.\nWe know selectDataVarApp() contains ‘modules inside other modules’, and these layers are reflected in the namespaces:\n\n\n\n\n\nTo access the inputIds in the nested modules, we need to pass the full ‘appended’ namespace:\n\ndv_app &lt;- selectDataVarApp()\ntestServer(app = dv_app, expr = {\n  session$setInputs(`var-var-var` = \"Ozone\",\n                    `var-data-dataset` = \"airquality\")\n})\n\nAfter setting the inputs, I can confirm the contents of output$out\n\ndv_app &lt;- selectDataVarApp()\ntestServer(app = dv_app, expr = {\n  session$setInputs(`var-var-var` = \"Ozone\",\n                    `var-data-dataset` = \"airquality\")\n  cat(\"\\n\\toutput$out:\\n\", output$out, \"\\n\")\n})\n\n\ntest_file(\"tests/testthat/test-selectDataVarApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 0 ]\n    output$out:\n   [1]  41  36  12  18  NA  28  23  19   8  NA   7  16  11  14  18\n [16]  14  34   6  30  11   1  11   4  32  NA  NA  NA  23  45 115\n [31]  37  NA  NA  NA  NA  NA  NA  29  NA  71  39  NA  NA  23  NA\n [46]  NA  21  37  20  12  13  NA  NA  NA  NA  NA  NA  NA  NA  NA\n [61]  NA 135  49  32  NA  64  40  77  97  97  85  NA  10  27  NA\n [76]   7  48  35  61  79  63  16  NA  NA  80 108  20  52  82  50\n [91]  64  59  39   9  16  78  35  66 122  89 110  NA  NA  44  28\n[106]  65  NA  22  59  23  31  44  21   9  NA  45 168  73  NA  76\n[121] 118  84  85  96  78  73  91  47  32  20  23  21  24  44  21\n[136]  28   9  13  46  18  13  24  16  13  23  36   7  14  30  NA\n[151]  14  18  20 \nAfter confirming output$out, I’ll test the inputs:\n\n  expect_equal(\n    object = input$`var-var-var`,\n    expected = \"Ozone\")\n  test_cmt(\"selectDataVarApp\", \"input$`var-var-var`\")\n\n  expect_equal(\n    object = input$`var-data-dataset`,\n    expected = \"airquality\")\n  test_cmt(\"selectDataVarApp\", \"input$`var-data-dataset`\")\n\nI can also verify the contents of the reactive var() inside the test:\n\n  expect_true(object = is.reactive(var))\n  test_cmt(\"selectDataVarApp\", \"is.reactive(var)\")\n  cat(\"\\n\\tvar:\\n\", var(), \"\\n\")\n\n\ntest_file(\"tests/testthat/test-selectDataVarApp.R\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 3 ]\n       selectDataVarApp: is.reactive(var) \n\n    var:\n 41 36 12 18 NA 28 23 19 8 NA 7 16 11 14 18 14 34 6 30 11 1 11 4 32 NA NA NA 23 \n    45 115 37 NA NA NA NA NA NA 29 NA 71 39 NA NA 23 NA NA 21 37 20 12 13 NA NA NA\n    NA NA NA NA NA NA NA 135 49 32 NA 64 40 77 97 97 85 NA 10 27 NA 7 48 35 61 79 \n    63 16 NA NA 80 108 20 52 82 50 64 59 39 9 16 78 35 66 122 89 110 NA NA 44 28 \n    65 NA 22 59 23 31 44 21 9 NA 45 168 73 NA 76 118 84 85 96 78 73 91 47 32 20 23\n    21 24 44 21 28 9 13 46 18 13 24 16 13 23 36 7 14 30 NA 14 18 20"
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#recap",
    "href": "series/testing/p3-shiny-module-tests/index.html#recap",
    "title": "Testing Shiny modules",
    "section": "Recap",
    "text": "Recap\nThis post has shown how shiny’s testServer() function allows you to isolate and test module server functions, which makes it easier to ensure that your server function behaves as expected (and locate and fix bugs).\nI hope you have a better understanding of how you can use testServer() to test a modules inputs/outputs, reactivity, calculations, and errors.\nIn the next post I’ll cover performing integration tests with shinytest2!"
  },
  {
    "objectID": "series/testing/p3-shiny-module-tests/index.html#footnotes",
    "href": "series/testing/p3-shiny-module-tests/index.html#footnotes",
    "title": "Testing Shiny modules",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSpecifically, the applications come from sections 19.3 through 19.3.4.↩︎\nThe help files for NS() include the following description for a module namespace: “a namespace is to an ID as a directory is to a file.”↩︎"
  },
  {
    "objectID": "series/testing/p5-rhino-tests/index.html",
    "href": "series/testing/p5-rhino-tests/index.html",
    "title": "Testing rhino apps",
    "section": "",
    "text": "packages\nlibrary(shiny)\nlibrary(shinytest2)\nlibrary(testthat)\nlibrary(rhino)\n\n\nThe rhino framework from Appsilon introduces a novel method for developing your Shiny application. Unlike the golem and leprechaun frameworks, rhino applications are not built inside R packages.\nThe example rhino application we’ll be using comes from my moviesApp repo covered in the Shiny App-Packages book (you can access this app using the shinyap package or directly from the repo)."
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html",
    "href": "series/testing/p1-bdd-testing/index.html",
    "title": "Behavior Driven Unit Tests",
    "section": "",
    "text": "packages\nlibrary(testthat)\nlibrary(lobstr)\nlibrary(dplyr)\nlibrary(shiny)\nlibrary(covr)\nThis post is the first in a series on testing Shiny applications. We’ll cover developing and testing a set of utility functions for a Shiny app-package using testhat. If you’d like to follow along, all the code we’ll be using is contained in the utap branch of the sapkgs repo on GitHub.\n# renv::install(\"mjfrigaard/utap\")\nlibrary(utap)\nTesting the code in Shiny app-packages can be more complicated than testing the code in a typical R package, because app-packages contain two types of code:\nThese two types of code require different types of tests. Utility functions are usually accompanied by unit tests similar to the tests you’d find in a standard R package1, while the application’s reactive code can be tested using Shiny’s testServer() function, and the system tests can be built using the shinytest2 package.\nThis post will cover writing unit tests for a set of utility functions using testthat and covr. Any tips or time-savers I’ve found will be in green callout boxes:"
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html#what-are-unit-tests",
    "href": "series/testing/p1-bdd-testing/index.html#what-are-unit-tests",
    "title": "Behavior Driven Unit Tests",
    "section": "What are unit tests?",
    "text": "What are unit tests?\n\n\n\n\n“A unit test is a piece of code that invokes a unit of work and checks one specific end result of that unit of work. If the assumptions on the end result turn out to be wrong, the unit test has failed. A unit test’s scope can span as little as a method or as much as multiple classes.” - The Art of Unit Testing, 2nd edition\n\nThinking of functions as ‘units of work’ and their desired behavior as an ‘end results’ provides a useful mental model (especially during behavior-driven development. These terms also align nicely with the testing advice offered by testthat:\n\nStrive to test each behaviour in one and only one test. Then if that behaviour later changes you only need to update a single test.\n\nIn app-packages, the testthat package provides a comprehensive and flexible framework for performing unit tests.\n\ntestthat\nGet started with testthat by running usethis::use_testthat(). This function will create following files and folders:\ntests/\n  ├── testthat/\n  └── testthat.R\nTo create new tests, we’ll run usethis::use_test(\"&lt;name&gt;\") (with \"select_class\" being the name of the function we’d like to test).\n\nusethis::use_test(\"select_class\")\n\n✔ Setting active project to '/projects/apps/utap'\n✔ Writing 'tests/testthat/test-select_class.R'\n• Modify 'tests/testthat/test-select_class.R'\n\nTest files\nNew test files are be created and opened from the tests/testthat/ folder (with a test- prefix). Each function we’re testing should have it’s own .R file the R/ folder and a corresponding test- file in the tests/testthat/ folder (we’ll see how this helps with interactive testing in the IDE below). The initial contents of a new test file contains the boilerplate code below:\n\n\n\ntest_that(\"multiplication works\", {\n  expect_equal(2 * 2, 4)\n})\n\n\n\n\n\ntestthat test file\n\n\n\n\n\n\n\nTest structure\ntest_that() sets the test “scope” or “execution environment”, and encapsulates the test code and expectations. Note the use of curly brackets after the code argument:\n\n\n\n\n\n\nFigure 1: testthat test\n\n\n\n\n\nExpectations\nTest expectations are the code that comes into direct contact with the unit of work and end result for each function. It’s likely we’ll have multiple expectations for any given function, so we store these in tests and use the desc to describe the test context (all testthat expectations have an expect_* prefix):\n\n\n\n\n\n\nexpect_* functions\n\n\n\n\n\n\n\nexpectations\n\n\n\n\n\n\n\n\nKeyboard shortcuts\nI highly recommend using a shortcut while developing tests because it will improve your ability to iterate quickly.2\n\n\n\ndevtools function\ntest()\n\n\n \n\n\nKeyboard shortcut\nCtrl/Cmd + Shift + T\n\n\n\n\n\n\ntest_active_file()\n\n\n \n\n\nCtrl/Cmd + T\n\n\n\n\n\n\ntest_coverage_active_file()\n\n\n \n\n\nCtrl/Cmd + Shift + R"
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html#behavior-driven-development",
    "href": "series/testing/p1-bdd-testing/index.html#behavior-driven-development",
    "title": "Behavior Driven Unit Tests",
    "section": "Behavior-Driven Development",
    "text": "Behavior-Driven Development\nBehavior-driven development (or behavior-driven testing) is helpful if you find yourself communicating with users and/or stakeholders while developing Shiny apps. BDD centers around “conversation and examples to specify how you expect a system to behave”3 and it’s supported with testthats describe() and it() functions.4\n\n\n\n\n\n\nNoteBDD features & scenarios\n\n\n\n\n\n\nIn BDD, requirements are written plain language ‘feature files’ using a series of keywords:\nFeature:  \n  As a \n  I want \n  So that\n  \n  Background:\n    Given \n    And  \n    \n  Scenario:  \n    When \n    And  \n    Then \n    \nThe Feature is a high-level description (usually with a title and description). As a describes the end user the feature is intended for, their needs (I want), and the desired result (So that).\nThe Background can include any steps or conditions that exist before each scenario.\nA Scenario is a series of steps outlining a concrete examples that illustrates a feature. When is used to describe an event, or an action. Then describes what will verify the expected outcome is observable by the user. And combines Given with When or Then.\nRead more about Gherkin on the Cucumber website..\n\n\n\n\n\nSpecifications\nIn R packages, micro-iteration is defined as, “the interactive phase where you initiate and refine a function and its tests in tandem.” In app development, this stage might after you’ve received needs or specifications by an end-user or stakeholder.\nIf we’re using BDD, we’ll translate these specifications into functional requirements, then start writing test(s). After outlining the tests, we’ll write the function(s) to pass the test.\ntestthat’s describe() and it() functions and Gherkin syntax can clarify this process because we can describe what it is we want to test before getting stuck writing any test code.\nLet’s assume we’ve been asked to design an application that automatically to populates the user drop-downs with variables based on their format: binary, numeric, categorical, and–a subset of categorical–facet.5\n\nFeatures & Background: use the description (entered as a character string in the first argument of describe()) to capture the “unit of work” for each function. Feature and Background information can be included in nested describe() blocks.\n\n\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n})\n\n\nScenario: Every new Scenario keyword should have a corresponding it() or test_that() call.6 Try to be as specific as possible (while staying short and sweet) when describing the scenarios.\n\n\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n    it(\"Scenario: Given a data frame with a mix of columns\n      When I call pull_cols() with type 'binary'\n      Then I should receive a list of 'binary' column names\", code = {\n      \n    })\n  \n})\n\n\nExpectations: The Then keywords capture our expectations (and expect_*() function). In this case, it’s the ‘list of column names that match the \"&lt;type&gt;\" criteria’\n\n\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n    it(\"Scenario: Given a data frame with a mix of columns\n      When I call pull_cols() with type 'binary'\n      Then I should receive a list of 'binary' column names\", code = {\n      \n      expect_equal(is.logical(object))\n      \n    })\n  \n})\n\nIt’s worth noting that, at least conceptually, scenarios and expectations arise first. We’re usually working backwards from a desired “end result” a function is supposed to produce (i.e., compute a value, download a file, create a column, etc.).\n\nRequirements\nFor example, calling pull_cols(df, \"bin\") would ‘pull’ all the binary columns from an input data.frame or tibble (the example below uses palmerpenguins::penguins):\n\npull_cols(palmerpenguins::penguins, type = \"bin\")\n\n\n##  sex \n## \"sex\" \n\nThe return values can be passed to updateSelectInput() in the server to provide column names by type (i.e., numeric, binary, etc). pull_colls() can be used to quickly group variables into groups for data visualizations or table displays.\nFor example, categorical variables with 3-5 levels can be mapped to a facet layer (if using ggplot2). See the hypothetical UI output example below:\n\n# UI code\nselectInput(\n  inputId = ns(\"facet\"),\n  label = \"Select Facet Column\",\n  choices = c(\"\", NULL)\n)\n\n\n# pull facet columns from data\nfacet_cols &lt;- reactive({\n  pull_cols(df = ds(), type = \"facet\")\n})\n# update facet inputs\nobserve({\n  updateSelectInput(\n    session = session,\n    inputId = \"facet\",\n    choices = facet_cols()\n  )\n}) |&gt;\n  bindEvent(facet_cols())\n\nIn the example above, pull_cols() is passed a reactive dataset (data()), and the output is used to update the selectInput():\n\n\n\nSelect Facet Column\n\nspecies\nisland\n\n\n\n\n\n\nThe first step of pull_cols() will be to identify and extract columns based on their class, so we’ll create a test for select_class(), a function with a class parameter that supports multiple column types. The roxygen2 documentation for select_class() is below:\n\n\nshow/hide roxygen2 documentation\n#' Select Column Class\n#'\n#' `select_class()` selects columns from a data.frame based on the specified\n#' `class`. Options include logical, integer, double, character, factor, ordered,\n#' and list column types.\n#'\n#' @param df A `data.frame` from which columns will be selected.\n#' @param class Character vector specifying the class(es) of columns to select.\n#'   Supported values are:\n#'   * \"logical\" (\"lo\")  \n#'   * \"integer\" (\"in\")  \n#'   * \"double\" (\"do\")  \n#'   * \"character\" (\"ch\")  \n#'   * \"factor\" (\"fa\")   \n#'   * \"ordered\" (\"or\")   \n#'   * \"list\" (\"li\")\n#'   \n#' @param return_tbl Logical indicating whether to return the result as a\n#'   `data.frame`. If `FALSE`, a vector of selected column names is returned.\n#'\n#' @return A `data.frame` or vector of column names, depending on `return_tbl`.\n\n\nWe’ve also included a return_tbl argument that allows select_class() to return the column names.\n\n\nAbstract folder trees\nWhile developing R functions, I’ve found the ast() function from the lobstr package can be great for keeping track of nested function calls.\nselect_class() will have a nested is_class() function, which contains a series of test for objects (i.e., is.logical(), is.integer(), etc.). To keep track of nested functions in R/ files, sometimes I’ll outline the function in an abstract function tree and store this in a vignette.7\nBelow is an example tree for select_class():\n\n\n\nSyntax:\n\n\nlobstr::ast(\n    select_class(\n      is_class()\n      )\n)\n\n\n\n\nOutput:\n\n\n\n█─select_class \n└─█─is_class \n\n\n\n\nThe tree above is simple–it only has two functions so far–but as packages grow these abstract displays become more important for tracking function calls (and tests!).\n\n\n\n\n\n\nTipTIP! Function Names\n\n\n\n\n\n\nComing up with names for functions can be challenging. I like to follow the tidyverse style guide and use short verbs as a prefix (make_, get_, check_ etc.) that will give ‘future’ me hints as to their behavior.\nI like to stick to naming conventions I’m familiar with. For example, select_class() has similar behavior to dplyr::select(), and pull_cols() is more like dplyr::pull().\n\n\n\n\nOutlining functions with lobstr::ast() can helpful if we plan on iterating multiple, smaller functions. For example, before making a binary vector of column names, we need to verify the column has only two values. Binary variables can come in multiple flavors (logical, integer, character, factor, ordered, etc.), so check_binary_vec() will have a series of ‘checks’ for each column type.\nBelow is an abstract folder tree outlining pull_binary_cols(), the function called to extract a named character vector of binary column names:\n\n\n█─pull_binary_cols \n├─█─select_class \n│ └─█─is_class \n└─█─make_binary_vec \n  └─█─check_binary_vec \n    ├─█─check_log_binary \n    ├─█─check_int_binary \n    ├─█─check_chr_binary \n    ├─█─check_fct_binary \n    └─█─check_ord_binary \n\n\npull_binary_cols() calls select_class() then passes the selected columns to make_binary_vec(), where check_binary_vec() determines if it’s one of the five types of possible binary variables.\n\npull_binary_cols(palmerpenguins::penguins)\n##   sex \n## \"sex\"\n\n\npull_binary_cols(dplyr::starwars)\n##   gender \n## \"gender\"\n\nThe pull_facet_cols() outline is similar, except that it calls the pull_binary_cols() first, then selects the columns and determines if any remaining have 3-5 categorical levels:\n\n\n█─pull_facet_cols \n├─█─pull_binary_cols \n├─█─select_class \n│ └─█─is_class \n└─█─make_facet_vec \n  └─█─check_facet_vec \n    ├─█─check_chr_facet \n    └─█─check_fct_facet"
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html#test-tools",
    "href": "series/testing/p1-bdd-testing/index.html#test-tools",
    "title": "Behavior Driven Unit Tests",
    "section": "Test tools",
    "text": "Test tools\nBefore we can start developing the tests for pull_cols(), we’ll need data. We can define test data inside the it() call for select_class():\n\ndescribe(\"select_class() returned objects\", code = {\n  it(\"df returned\", {\n    # define test data\n    test_data &lt;- data.frame(\n      log_var = c(TRUE, FALSE, TRUE),\n      int_var = c(1L, 2L, 3L),\n      dbl_var = c(1.1, 2.2, 3.3),\n      chr_var = paste0(rep(\"item:\", times = 3), 1:3))\n  })\n})\n\nThis is helpful because it’s clear what test_data contains, and many times a small dataset will suffice. However, larger, more complex test data should be stored as a test fixture.\n\nTest fixtures\nCreating test fixtures is covered in R packages, but I’ll summarize the key points:\n\nTest data (and other objects) can either be created within a test, or as a persistent test fixture\nTest data fixtures should be stored in tests/testthat/fixtures/&lt;test_data.rds&gt;\nThe code used to create any test data fixtures should be stored in the same folder with a make_ prefix (i.e., tests/testthat/fixtures/&lt;make_test_data.R&gt;)\n\nThis is easier to picture with a demonstration: In the tests/testthat/ folder, I’ll create a new fixtures folder, and add a make_test_data.R file.8\ntests/testthat/\n        └── fixtures/\n                └── make_test_data.R\nIn make_test_data.R, I’ll create test_data using the code above and save test_data in tests/testthat/fixtures/ as test_data.rds:\ntests/testthat/\n        └── fixtures/\n                ├── make_test_data.R\n                └── test_data.rds\nTo load the data into my test, I’ll add the following to the top of the test context:\n\ndescribe(\"select_class() returned objects\", code = {\n  \n  test_data &lt;- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n  \n})\n\ntestthat::test_path() will load the data from the testing directory when I’m ready to run my test.\nThe select_class() function should also be able to return a data.frame/tibble of the specified class, or a named vector of the column names. testthat’s expect_* functions have a lot of options for writing very specific tests.\n\ndescribe(\"select_class() returned objects\", code = {\n  \n  it(\"df returned\", {\n    # define/load test data\n    expect_s3_class(object, \"data.frame\")\n  })\n  \n  it(\"tibble returned\", {\n    # define/load test data\n    expect_s3_class(object,\n      class = c(\"tbl_df\", \"tbl\", \"data.frame\")\n    )\n  })\n  \n  it(\"string returned\", {\n    # define/load test data\n    expect_type(object = object, type = \"character\")\n  })\n  \n  it(\"named vector returned\", {\n    # define/load test data\n    expect_named(object = object, expected = \"log_var\")\n  })\n})\n\nselect_class() should also return the columns according to the class argument. For the logical, integer, double, character, and list columns, we can assess each returned object with expect_type(). However, with the factor and ordered columns, we’ll use the expect_s3_class().\n\n\nshow/hide select_class() tests\n# check classes ----\ndescribe(\"select_class() return classes\", code = {\n  ## check logical ----\n    it(\"logical works\", {\n      test_data &lt;- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n      # define obj\n      obj &lt;- select_class(df = test_data, class = \"logical\")\n      # test type\n      expect_type(obj[[1]], type = \"logical\")\n    })\n    ## check integer ----\n    it(\"integer works\", {\n      # integer test code\n      })\n  ## check double ----\n    it(\"double works\", {\n      # double test code\n    })\n  ## check character ----\n    it(\"character works\", {\n      # character test code\n    })\n    ## check list ----\n    it(\"list works\", {\n      # list test code\n    })\n  ## check factor ----\n    it(\"factor works\", {\n      test_data &lt;- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n      obj &lt;- select_class(df = test_data, class = \"factor\")\n      expect_s3_class(obj[[1]], class = \"factor\")\n    })\n  ## check factor (ordered) ----\n    it(\"ordered works\", {\n      # ordered factor test code\n    })\n\n})\n\n\nUsing describe() and it() allows us to outline tests for select_class(), and including test fixtures makes it easier to test all possible classes returned.\nWhen we’ve covered my intended ‘end results’ for select_class() (i.e., what we expect to happen when it works and we expect to happen when it doesn’t), we cam write the function:\n\n\nselect_column_class()\nselect_class &lt;- function(df, class, return_tbl = TRUE) {\n  if (!is.data.frame(df)) stop(\"df must be a dataframe\")\n\n  # define classes\n  valid_classes &lt;- c(\"logical\", \"integer\", \"double\", \"numeric\", \"character\",\n                     \"factor\", \"ordered\", \"list\")\n  class &lt;- match.arg(class, choices = valid_classes, several.ok = TRUE)\n\n  # helper function to check classes\n  is_class &lt;- function(x, cls) {\n    cls &lt;- match(cls, valid_classes)\n    cls_name &lt;- valid_classes[cls]\n    switch(cls_name,\n           logical = is.logical(x),\n           integer = is.integer(x),\n           double = is.double(x),\n           numeric = is.numeric(x),\n           character = is.character(x),\n           factor = is.factor(x),\n           ordered = is.ordered(x),\n           list = is.list(x),\n           FALSE)\n  }\n\n  selected_cols &lt;- sapply(df, function(x) any(sapply(class, is_class, x = x)))\n\n  col_names &lt;- names(df)[selected_cols]\n\n  if (return_tbl) {\n    return(df[, col_names, drop = FALSE])\n  } else {\n    return(setNames(object = col_names, nm = col_names))\n  }\n}\n\n\nBelow is a summary of tips for adding data your tests.\n\n\n\n\n\n\n\n\n\n(a) Unit test fixtures\n\n\n\n\n\nFigure 2: Unit test fixtures\n\n\n\n\n\nTest helpers\nTest helpers can be stored in tests/testthat/helper.R. Test helpers are functions or code that 1) is too long to repeat with each test, and 2) doesn’t take too much time or memory to run. Read more about test helpers here..\nFor this application, I’ve created a set of test helpers to make different forms of test data (because we’ll be repeatedly defining columns with slightly different attributes).\nFor example, col_maker() can be used to create a tibble with columns based on the col_type, size, and missing:\n\ncol_maker(col_type = c(\"log\", \"int\", \"dbl\", \n                       \"chr\", \"fct\", \"ord\"),\n          size = 3,\n          missing = TRUE)\n## # A tibble: 3 × 6\n##   log_var int_var dbl_var chr_var fct_var ord_var\n##   &lt;lgl&gt;     &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;fct&gt;   &lt;ord&gt;  \n## 1 TRUE          1     0.1 item:1  group 1 level 1\n## 2 FALSE        20    NA   &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n## 3 NA           NA     0.1 item:1  group 1 level 1\n\nI can also create tibbles with custom columns using individual helper _maker() functions:\n\ntibble::tibble(\n    log_var = log_maker(size = 3),\n    chr_var = chr_maker(size = 3, lvls = 3),\n    ord_var = ord_maker(size = 3, lvls = 2)\n)\n## # A tibble: 3 × 3\n##   log_var chr_var ord_var\n##   &lt;lgl&gt;   &lt;chr&gt;   &lt;ord&gt;  \n## 1 TRUE    item:1  level 1\n## 2 FALSE   item:2  level 2\n## 3 TRUE    item:3  level 1\n\nThese helpers make it easier to iterate through the test expectations and function development, because tibbles like the one above can be developed inside each test.\nBelow is an example for testing if pull_binary_cols() will correctly identify the logical columns (for both return objects):\n\n\nusing test helpers\ndescribe(\"pull_binary_cols() works\", {\n    it(\"logical tibble (with missing)\", code = {\n      test_data &lt;- tibble::tibble(log = log_maker(size = 2, missing = TRUE))\n      expect_equal(pull_binary_cols(test_data),\n      expected = c(log = \"log\"))\n    })\n    it(\"logical tibble\", code = {\n      test_data &lt;- tibble::tibble(log = log_maker(size = 2, missing = FALSE))\n      expect_equal(pull_binary_cols(test_data),\n      expected = c(log = \"log\"))\n    })\n})\n\n\nSometimes it will still make sense to create the test data inside the test scope (i.e. inside the it() or test_that() call). For example, I was pull_binary_cols() to identify integer columns with binary values (0, 1). I should make these test data explicit:\n\n\nusing test helpers\nit(\"test integer with binary values (0, 1, NA)\", code = {\n  test_data &lt;- data.frame(int = c(0L, 1L))\n  expect_equal(pull_binary_cols(test_data),\n  expected = c(int = \"int\"))\n})\nit(\"test integer with binary values and missing (0, 1, NA)\", code = {\n  test_data &lt;- data.frame(int = c(0L, 1L, NA_integer_))\n  expect_equal(pull_binary_cols(test_data),\n  expected = c(int = \"int\"))\n})\n\n\nWhen I’m confident with the pull_binary_cols() function and it’s tests, I’ll run devtools:::test_active_file().\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 9 ]\n\n\nTest coverage\nHow many tests should I write?\nIn testthat code coverage measures the extent to which the tests in the tests/testthat/ folder cover the possible execution paths of the functions in the R/ folder.\nCode test coverage is a way to confirm that the unit tests are robust enough to verify that your code behaves as expected. In R packages, code coverage is discussed in the testing chapter using the covr package.\nDuring development, check the code coverage of a test file with devtools::test_coverage_active_file(). Sometimes this function can be temperamental, so I use the combination of covr functions below:\n\ncovr::file_coverage(\n  source_files = \"R/&lt;function_file.R&gt;\", \n  test_files = \"tests/testthat/test-&lt;function_file.R&gt;\") |&gt;\n  covr::report()\n\nBelow is the test coverage for make_binary_vec()–a smaller helper function for pull_binary_cols()–in the Viewer when devtools::test_coverage_active_file() is entered in the Console:\n\n\n\n\n\n\n\n\n\n(a) Test coverage\n\n\n\n\n\nFigure 3: Unit test coverage interactively\n\n\n\nWe can see from the output we don’t have 100% test coverage for make_binary_vec(). When we click on the file path in the table we can se what execution paths aren’t being tested:\n\n\n\n\n\n\n\n\n\n(a) Behavior not tested in make_binary_vec()\n\n\n\n\n\nFigure 4: The area in red is the untested portion of make_binary_vec()\n\n\n\nIt’s probably not worth chasing down the remaining 17% on this function because I’ve outlined it’s primary requirements in the BDD functions:\n\ndescribe(\"make_binary_vec() works\", {\n    it(\"logical\", {\n      # test code\n    })\n  it(\"integer\", {\n      # test code\n    })\n  it(\"character\", {\n      # test code\n    })\n  it(\"factor\", {\n      # test code\n    })\n})\n\nStriving for a high percentage of coverage is a good practice, it doesn’t guarantee that the function always behaves as expected. Unit tests might execute a line of code, but still not catch a bug due to the design of the test (it’s easy to have high coverage if the unit tests are shallow and don’t check for any potential edge cases).\nAfter developing the functions in utap, the files in the R/ folder are organized into names based on the ‘main function and its supporting helpers’:\nR/\n├── check_binary_vec.R\n├── check_facet_vec.R\n├── make_binary_vec.R\n├── make_facet_vec.R\n├── nin.R\n├── pull_binary_cols.R\n├── pull_cat_cols.R\n├── pull_cols.R\n├── pull_facet_cols.R\n├── pull_numeric_cols.R\n├── select_class.R\n└── utap-package.R\nThe tests/testthat/ folder file names have identical names as the files in the R/ folder.\ntests\n├── testthat\n│   ├── _snaps\n│   ├── fixtures\n│   │   ├── make_test_data.R\n│   │   └── test_data.rds\n│   ├── helper.R\n│   ├── test-check_binary_vec.R\n│   ├── test-check_facet_vec.R\n│   ├── test-make_binary_vec.R\n│   ├── test-nin.R\n│   ├── test-pull_binary_cols.R\n│   ├── test-pull_cat_cols.R\n│   ├── test-pull_cols.R\n│   ├── test-pull_facet_cols.R\n│   ├── test-pull_numeric_cols.R\n│   └── test-select_class.R\n└── testthat.R\n\n4 directories, 14 files\nIt’s common for R packages to have a general R/utils.R file that defines the ‘utility’ functions, but these files can become a catch-all for any functions that don’t have a clear home (read more here).\nFor example, I could stored the %nin% operator in R/utils.R (but it removes the ability to run test_coverage_active_file():\nWhen I’ve completed a set of test files, I can use devtools::test() to check if they’re passing.\n\ndevtools::test()\n\n==&gt; devtools::test()\n\nℹ Testing utap\n✔ | F W  S  OK | Context\n✔ |         23 | check_binary_vec\n✔ |          3 | check_facet_vec\n✔ |          4 | make_binary_vec\n✔ |          3 | nin          \n✔ |          9 | pull_binary_cols\n✔ |          4 | pull_cat_cols\n✔ |          4 | pull_cols    \n✔ |         15 | pull_facet_cols\n✔ |          2 | pull_numeric_cols\n✔ |         14 | select_class \n\n══ Results ═══════════════════\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 81 ]\n\n🎯 Your tests hit the mark 🎯\nThe output above shows all tests are passing (and some helpful words of encouragement!). To check the code coverage for the utap package, I can run devtools::test_coverage() to view the output in the Viewer.\n\ndevtools::test_coverage()\n\nℹ Computing test coverage for utap\n\n\n\n\n\n\n\n\n\n(a) test_coverage() for entire package\n\n\n\n\n\nFigure 5: devtools::test_coverage()\n\n\n\nClicking on any of the Files will open the Source tab and give a summary like the one above from test_coverage_active_file(). I can also use covr::package_coverage() in the Console for simpler output:\n\n\n\n\n\n\n\n\n\n(a) package_coverage() for entire package\n\n\n\n\n\nFigure 6: covr::package_coverage()\n\n\n\n\n\n\n\n\n\nTipTIPS: Unit tests\n\n\n\n\n\n\nThe advice on unit tests below (in bold) comes from Effective Software Testing, 2022. I’ve included descriptions of how testthat satisfies each recommendation:\n\nUnit tests should be fast: the text recommends unit tests take a ‘couple of milliseconds’ to execute. testthat tests typically fall within this threshold (and provide time measurements to identify bottlenecks).\nUnit tests are easy to control: i.e., ‘input values and the expected result value are easy to adapt or modify in the test.’ testthat expectations give us ample access to 1) the expected result and 2) the observed result.\nUnit tests are easy to write: i.e., ‘do not require a complicated setup or additional work’. When used combination with usethis, testthat unit tests can be set up, created, written, and run with a few lines of code."
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html#other-code-metrics",
    "href": "series/testing/p1-bdd-testing/index.html#other-code-metrics",
    "title": "Behavior Driven Unit Tests",
    "section": "Other code metrics",
    "text": "Other code metrics\nSometimes it’s interesting to view the relationship between function size and number of tests using the cloc package..\n\nlibrary(cloc)\n\ncloc stands for Count Lines of Code, and it’s a rough metric used to gauge code complexity. It’s simple, but apparently provides “just as much predictive power as more elaborate constructs like cyclomatic complexity.”source\nBelow is a count of the lines of code in each file in the R folder:\n\ncloc::cloc_by_file(\"R\")\n\n# A tibble: 13 × 6\n   source filename                language   loc blank_lines comment_lines\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;chr&gt;    &lt;int&gt;       &lt;int&gt;         &lt;int&gt;\n 1 R      \"R/select_class.R\"      R           27           5            31\n 2 R      \"R/check_binary_vec.R\"  R           24           0            14\n 3 R      \"R/make_facet_vec.R\"    R           19           0            19\n 4 R      \"R/pull_numeric_cols.R\" R           19           1            23\n 5 R      \"R/pull_binary_cols.R\"  R           14           0            19\n 6 R      \"R/pull_facet_cols.R\"   R           14           0            37\n 7 R      \"R/check_facet_vec.R\"   R           13           0            14\n 8 R      \"R/pull_cat_cols.R\"     R           13           0            18\n 9 R      \"R/make_binary_vec.R\"   R           10           0            19\n10 R      \"R/pull_cols.R\"         R            8           0            15\n11 R      \"R/nin.R\"               R            3           0             9\n12 R      \"R/utap-package.R\"      R            2           0             6\n13 R      \"\"                      SUM        166           6           224\nThis output also confirms the relationship between lines of code and tests."
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html#recap",
    "href": "series/testing/p1-bdd-testing/index.html#recap",
    "title": "Behavior Driven Unit Tests",
    "section": "Recap",
    "text": "Recap\nThis post has been an introduction to unit testing utility functions in a Shiny app-package. When I’m confident the utility functions are working, I’ll start adding them into modules (and testing with testServer() or shinytest2). Files names can change a lot throughout the course of developing a Shiny app-package, so it’s helpful to adopt (or create) a naming convention.9\nWhich particular file naming convention you choose isn’t as important as adopting a convention and implementing it."
  },
  {
    "objectID": "series/testing/p1-bdd-testing/index.html#footnotes",
    "href": "series/testing/p1-bdd-testing/index.html#footnotes",
    "title": "Behavior Driven Unit Tests",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLearn more about R packages in R Packages, 2ed↩︎\nR Packages, 2ed also suggests binding test_active_file() and test_coverage_active_file() to keyboard shortcuts.↩︎\nRead more about behavior-driven development in BDD in Action, 2ed↩︎\ndescribe() and it() are discussed in the testthat documentation.↩︎\nThe variable names would automatically populate the choices argument for a selectInput()↩︎\ntestthat’s it() function is essentially identical to test_that().↩︎\nBoth functions are placed in R/select_class.R, and both unit tests are also in the tests/testthat/test-select_class.R file.↩︎\nThe fixtures name is not required, but it always make sense to keep folder names explicit.↩︎\nIf you’re using the golem framework to develop your shiny app-package, the utils_ and fct_ prefixes are used to define two different types of utility/helper functions. utils_ files contain ‘small helper functions and’top-level functions defining your user interface and your server function’. fct_ files contain ‘the business logic, which are potentially large functions…the backbone of the application and may not be specific to a given module’.↩︎"
  },
  {
    "objectID": "series/testing/p4-system-shiny/index.html",
    "href": "series/testing/p4-system-shiny/index.html",
    "title": "Shiny System Tests With shinytest2",
    "section": "",
    "text": "ImportantUpdates to series\n\n\n\n\n\n\nThis series on testing has been updated with recent changes in testthat, shinytest2, and other packages to improve testing.\nThis is the fourth post in a series on testing Shiny applications. The previous posts have covered using BDD in unit tests, testing apps outside of an R package structure, and testing module server functions. In this post, we’ll be covering testing Shiny applications using testthat and shinytest2."
  },
  {
    "objectID": "series/testing/p4-system-shiny/index.html#app-packages",
    "href": "series/testing/p4-system-shiny/index.html#app-packages",
    "title": "Shiny System Tests With shinytest2",
    "section": "App-Packages",
    "text": "App-Packages\nIn the previous post, we stored the modules and applications from the Shiny modules chapter of Mastering Shiny in the mstsap package. The msst2ap package contains shinytest2 tests for the Shiny apps in Mastering Shiny (hence the name: Mastering Shiny shinytest2 app-package).\nYou can install msst2ap using the following:\n\ninstall.packages(\"remotes\")\nremotes::install_github(\n  \"https://github.com/mjfrigaard/msst2ap\"\n)\n\nI’ve stored development versions of the applications in the inst/dev/ folder of msst2ap:\ninst\n└── dev\n    ├── datasetApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    ├── gghistApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    ├── histogramApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    ├── selectDataVarApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    └── selectVarApp\n        ├── DESCRIPTION\n        ├── R\n        │   └── modules.R\n        ├── README.md\n        └── app.R\n\n12 directories, 20 files\n\nUsing system.file()\nThe apps stored in the inst/dev/ directory of msst2ap can be passed to the app_dir argument of AppDriver$new() with system.file():\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$view()\n})\n\n\n\n\nSetting inputs\nThe first things we’ll check is changing the dataset-dataset input from ability.cov to attitude using app$set_inputs() (Note that this uses the module notation above (i.e., \"id-inputId\"):\n\ntest_that(\"mstsap::datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n})\n\nIf you can see both windows, you’ll see the application values change in the Chromium browser:\n\n\n\n\n\n\n\n\n\n\n\n\n(a) app$set_inputs()\n\n\n\n\n\n\n\nFigure 1: Set application inputs with app$set_inputs()\n\n\n\n\n\n\nChecking inputs\nWe can capture values in a list inside the test by including a call to app$get_values() and assigning the output to app_values.\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n  app_values &lt;- app$get_values()\n})\n\napp_values has a similar structure to the .json snapshot covered above (i.e., with input, output, and export):\n\nstr(app_values)\n\nList of 3\n $ input :List of 1\n  ..$ dataset-dataset: chr \"attitude\"\n $ output:List of 2\n  ..$ data: chr \"&lt;table  class = 'table shiny-table table- spacing-s' style = 'width:auto;'&gt;\\n&lt;thead&gt; &lt;tr\"..\n  ..$ vals: chr \"$`dataset-dataset`\\n[1] \\\"attitude\\\"\\n\"\n $ export: Named list()\nWe can use waldo::compare() to verify the input in app_values to verify the value that we changed with app$set_inputs()\n\nwaldo::compare(\n  x = app_values$input$`dataset-dataset`,\n  y = \"attitude\"\n)\n\n✔ No differences\nwaldo::compare() can easily be adapted to a new test expectation:\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n  app_values &lt;- app$get_values()\n  waldo::compare(x = app_values$input$`dataset-dataset`,\n                 y = \"attitude\")\n  testthat::expect_equal(\n    object = app_values$input$`dataset-dataset`,\n    expected = \"attitude\")\n})\n\nAt the end of the test, I’ll add a call app$stop() to close the Chromium app.\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n  app_values &lt;- app$get_values()\n  waldo::compare(x = app_values$input$`dataset-dataset`,\n                 y = \"attitude\")\n  testthat::expect_equal(\n    object = app_values$input$`dataset-dataset`,\n    expected = \"attitude\")\n  app$stop()\n})"
  },
  {
    "objectID": "series/testing/p4-system-shiny/index.html#exporting-test-values",
    "href": "series/testing/p4-system-shiny/index.html#exporting-test-values",
    "title": "Shiny System Tests With shinytest2",
    "section": "Exporting test values",
    "text": "Exporting test values\nThe shinytest2 documentation repeatedly1 recommends2 exporting test values from Shiny applications. We’ll use the application stored in inst/dev/selectVarApp/ to explore exporting test values.\nThe application in the inst/dev/selectVarApp/ folder of msst2ap includes a call to exportTestValues() and the test.mode option set to TRUE in the call to shinyApp().3\n\nserver &lt;- function(input, output, session) {\n  data &lt;- datasetServer(\"data\")\n  var &lt;- selectVarServer(\"var\", data, filter = filter)\n\n  output$out &lt;- renderTable(head(var()))\n\n  output$vals &lt;- renderPrint({\n    x &lt;- reactiveValuesToList(input,\n      all.names = TRUE\n    )\n    print(x)\n  })\n\n  exportTestValues(\n    var = var(),\n    data = data()\n  )\n}\n\nThe test for this application contains the same system.file() call to create the AppDriver object:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n})\n\nAfter entering app$view() in the Console, the application opens in the Chromium headless browser again:\n\napp$view()\n\nWe can see selectVarApp has been launched in showcase mode, so the README and code files are displayed in the UI.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) app$view()\n\n\n\n\n\n\n\nFigure 2: View selectVarApp() application with app$view()\n\n\n\n\nIn our test file, we’ll use app$set_values() to change the $`data-dataset` and $`var-var` inputs:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n  \n1  app$set_inputs(`data-dataset` = \"mtcars\")\n})\n\n\n1\n\nChange $`data-dataset` to mtcars\n\n\n\n\nWe’ll also change the variable input from mpg to wt and verify the output in the UI:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n  \n1  app$set_inputs(`data-dataset` = \"mtcars\")\n2  app$set_inputs(`var-var` = \"wt\")\n})\n\n\n1\n\nChange $`data-dataset` to mtcars\n\n2\n\nChange $`var-var` to wt\n\n\n\n\nThe printed reactiveValuesToList() is updated UI when the selectInput() changes:\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Set data-dataset\n\n\n\n\n\n\n\nFigure 3: View selectVarApp() after setting data-dataset and var-var with app$set_inputs()\n\n\n\n\n\nGetting values\nWe’ll use app$get_values() to store the exported input, output, and export test values in app_values:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n\n1  app$set_inputs(`data-dataset` = \"mtcars\")\n2  app$set_inputs(`var-var` = \"wt\")\n\n3  app_values &lt;- app$get_values()\n})\n\n\n1\n\nChange $`data-dataset` to mtcars\n\n2\n\nChange $`var-var` to wt\n\n3\n\nAssign to app_values list\n\n\n\n\napp_values is a list (similar to the .json snapshot file), but now we’ve explicitly exported values from the server in selectVarApp():\n\nnames(app_values$export)\n\n\n[1] \"data\" \"var\" \n\n\n\nExpectations\nWe can use app_values to verify the structure of each exported object:\n\ndata should be a data.frame()\n\n\ntestthat::expect_true(\n  object = is.data.frame(app_values$export$data)\n)\n\n\nvar should be have one column:\n\n\ntestthat::expect_true(\n  object = ncol(app_values$export$var) == 1)\n\nOnce again, we end the test with a call to app$stop(). The completed test for selectVarApp() is below:\n\n\nshow/hide mstsap::selectVarApp test\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n\n  app$set_inputs(`data-dataset` = \"mtcars\")\n  app$set_inputs(`var-var` = \"wt\")\n\n  app_values &lt;- app$get_values()\n\n  testthat::expect_true(\n    object = is.data.frame(app_values$export$data))\n\n  testthat::expect_true(\n    object = ncol(app_values$export$var) == 1)\n\n  app$stop()\n})"
  },
  {
    "objectID": "series/testing/p4-system-shiny/index.html#testing-complex-outputs",
    "href": "series/testing/p4-system-shiny/index.html#testing-complex-outputs",
    "title": "Shiny System Tests With shinytest2",
    "section": "Testing complex outputs",
    "text": "Testing complex outputs\nmsst2ap has the histogramApp() from Mastering Shiny in inst/dev/histogramApp/, and a ggplot2 version of the histogramApp() in the inst/dev/ggHistApp/ folder:\n\ninst\n└── dev\n    ├── ggHistApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    └── histogramApp\n        ├── DESCRIPTION\n        ├── R\n        │   └── modules.R\n        ├── README.md\n        └── app.R\n\n6 directories, 8 files\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) histogramApp()\n\n\n\n\n\n\n\n\n\n\n\n(b) ggHistApp()\n\n\n\n\n\n\n\nFigure 4: histogramApp() vs. ggHistApp()\n\n\n\n\n\nTesting reactive values\nThe module server functions in histogramApp() return two values: data and x:\n\nserver &lt;- function(input, output, session) {\n  \n  data &lt;- datasetServer(\"data\")\n  x &lt;- selectVarServer(\"var\", data)\n  \n  histogramServer(\"hist\", x)\n\n  output$vals &lt;- shiny::renderPrint({\n    x &lt;- shiny::reactiveValuesToList(input,\n                            all.names = TRUE)\n    print(x)\n  })\n\n}\n\ndata is returned reactive from datasetServer() and becomes an input parameter for selectVarServer(), and x is the returned reactive.\nBoth of these are reactive values, but they aren’t treated like returned values from the reactive() function (i.e., they don’t have parentheses). These are passed in the server as reactive expressions, which we can confirm using exportTestValues():\n\n\nshow/hide msst2ap::histogramApp() server\nserver &lt;- function(input, output, session) {\n  data &lt;- datasetServer(\"data\")\n  x &lt;- selectVarServer(\"var\", data)\n  histogramServer(\"hist\", x)\n\n  # remaining code omitted\n  \n1  exportTestValues(\n      data = data,\n      x = x\n    )\n}\n\n\n\n1\n\nWe’ve also added options(shiny.testmode = TRUE) to the top of the app.R file.\n\n\n\n\nIn the test for histogramApp(), we’ll create the app with AppDriver$new() and change the three inputs using app$set_inputs():\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n  app_values &lt;- app$get_values()\n  names(app_values)\n})\n\n[1] \"data\" \"x\"  \nWe’ll test is these are reactive functions by combining rlang::is_function() and shiny::is.reactive():\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n  app_values &lt;- app$get_values()\n  names(app_values)\n  expect_equal(\n    rlang::is_function(app_values$export$data),\n    shiny::is.reactive(app_values$export$data))\n  expect_equal(\n    rlang::is_function(app_values$export$x),\n    shiny::is.reactive(app_values$export$x))\n})\n\n\n\nUsing app logs\nshinytest2 also has the handy get_logs() that allows us to check the logs for specific functionality. Below is the output from get_logs() from histogramApp():\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n1  app_logs &lt;- app$get_logs()\n2  str(app_logs)\n})\n\n\n1\n\nCreate app logs\n\n2\n\nView log structure\n\n\n\n\nClasses ‘shinytest2_log’ and 'data.frame':  56 obs. of  5 variables:\n $ workerid : chr  NA NA NA NA ...\n $ timestamp: POSIXct, format: \"2024-03-31 04:47:41\" \"2024-03-31 04:47:41\" ...\n $ location : chr  \"shinytest2\" \"shinytest2\" \"shinytest2\" \"shinytest2\" ...\n $ level    : chr  \"info\" \"info\" \"info\" \"info\" ...\n $ message  : chr  \"Start AppDriver initialization\" \"Starting Shiny app\" \"Creating \"..\nAfter changing the three inputs with set_inputs(), we can check the output to see these actions were included in the logs:\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n  app_values &lt;- app$get_values()\n  names(app_values)\n  expect_equal(\n    rlang::is_function(app_values$export$data),\n    shiny::is.reactive(app_values$export$data))\n  expect_equal(\n    rlang::is_function(app_values$export$x),\n    shiny::is.reactive(app_values$export$x))\n  app$set_inputs(`hist-bins` = 15)\n1  app_logs &lt;- app$get_logs()\n2  ds_msg &lt;- subset(app_logs,\n                   message == \"Setting inputs: 'data-dataset'\")\n  expect_equal(nrow(ds_msg), 1L)\n3  var_msg &lt;- subset(app_logs,\n                    message == \"Setting inputs: 'var-var'\")\n  expect_equal(nrow(var_msg), 1L)\n4  hist_msg &lt;- subset(app_logs,\n                     message == \"Setting inputs: 'hist-bins'\")\n  expect_equal(nrow(hist_msg), 1L)\n})\n\n\n1\n\nCreate app logs\n\n\n2\n\nCreate and test dataset\n\n\n3\n\nCreate and test variable\n\n\n4\n\nCreate and test bins\n\n\n\n\nLogs can also be passed from the test to the application using log_message().\n\n\nVerify initial inputs\nThe ggHistApp() app is similar to histogramApp(), but instead of passing a reactive vector to hist(), ggHistServer() passes a reactive one-column data.frame (x()) to the ggplot2 functions. We’ll add exportTestValues() to a development version of ggHistServer() in inst/dev/: 4\n\n\nshow/hide ggHistServer()\nggHistServer &lt;- function(id, x, title = reactive(\"Histogram\")) {\n  stopifnot(is.reactive(x))\n  stopifnot(is.reactive(title))\n\n  moduleServer(id, function(input, output, session) {\n    \n1    gg2_plot &lt;- reactive({\n      ggplot2::ggplot(\n          mapping =\n            ggplot2::aes(purrr::as_vector(x()))\n        ) +\n          ggplot2::geom_histogram(bins = input$bins) +\n          ggplot2::labs(\n            title = paste0(title(), \" [bins = \", input$bins, \"]\"),\n            y = \"Count\",\n            x = names(x())\n          ) +\n          ggplot2::theme_minimal()\n    })\n\n2    observe({\n      output$hist &lt;- renderPlot({gg2_plot()}, res = 124)\n    }) |&gt; \n      bindEvent(c(x(), title(), input$bins))\n\n3    exportTestValues(\n      bins = input$bins,\n      x = x(),\n      title = title()\n    )\n\n    # remaining code omitted\n    \n  })\n}\n\n\n\n1\n\nBuild ggplot2 graph\n\n2\n\nRender plot\n\n\n3\n\nExport bins, x() and title()\n\n\n\n\nThe version of ggHistServer() above replaces the ggHistServer() used in the standalone app function).5 The remaining modules from mstsap are explicitly namespaced. The code below identifies the location of each module in ggHistApp(): 6\n\n\nshow/hide ggHistApp()\nggHistApp &lt;- function() {\n  ui &lt;- fluidPage(\n    sidebarLayout(\n      sidebarPanel(\n        mstsap::datasetInput(\"data\", is.data.frame),\n        mstsap::selectVarInput(\"var\"),\n      ),\n      mainPanel(\n1        histogramOutput(\"hist\"),\n        code(\"app vals\"),\n        verbatimTextOutput(\"vals\")\n      )\n    )\n  )\n\n  server &lt;- function(input, output, session) {\n    data &lt;- mstsap::datasetServer(\"data\")\n2    x &lt;- ggSelectVarServer(\"var\", data)\n3    ggHistServer(\"hist\", x)\n\n    output$vals &lt;- renderPrint({\n        x &lt;- reactiveValuesToList(input,\n          all.names = TRUE)\n        print(x, width = 30, max.levels = NULL)},\n      width = 30)\n  }\n  \n4    exportTestValues(\n      x = x(),\n      data = data(),\n      react_x = x,\n      react_data = data\n    )\n\n  shinyApp(ui, server)\n}\nggHistApp()\n\n\n\n1\n\nFrom R/histogramOutput.R\n\n\n2\n\nFrom R/ggSelectVarServer.R\n\n\n3\n\nFrom inst/dev/ggHistApp/R/modules.R\n\n4\n\nExported test values\n\n\n\n\nIn the test-shinytest2-ggHistApp.R test file, I’ll verify the vdiffr package is installed, then create the AppDriver object with a call to system.file() and set the height and width:\n\ntest_that(\"{shinytest2}: ggHistApp\", {\n  skip_if_not_installed(\"vdiffr\")\n  app_pth &lt;- system.file(\"dev\", \"ggHistApp\",\n                                  package = \"msst2ap\")\n  app &lt;- AppDriver$new(app_pth,\n                       height = 750, width = 1200)\n})\n\nView the application in the Chromium browser by running app$view() in the Console:\n\napp$view()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) app$view()\n\n\n\n\n\n\n\nFigure 5: View ggHistApp() application with app$view()\n\n\n\n\nThe first expectations in the example test the default input values:\n\ntestthat::test_that(\"{shinytest2}: gghistApp\", {\n  testthat::skip_if_not_installed(\"vdiffr\")\n\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"gghistApp\",\n                                             package = \"msst2ap\"),\n                       height = 750, width = 1200)\n\n1  app_init_data &lt;- app$get_value(input = \"data-dataset\")\n  waldo::compare(app_init_data, \"BOD\")\n  expect_equal(\n    object = app_init_data,\n    expected = \"BOD\")\n\n2  app_init_var &lt;- app$get_value(input = \"var-var\")\n  waldo::compare(app_init_var, \"Time\")\n  expect_equal(\n    object = app_init_var,\n    expected = \"Time\")\n})\n\n\n1\n\nVerify initial data\n\n2\n\nVerify initial variable\n\n\n\n\n\n\nSet and verify export\nNext, we check changing the input values with app$set_values(id-inputId):\n\ntestthat::test_that(\"{shinytest2}: gghistApp\", {\n  testthat::skip_if_not_installed(\"vdiffr\")\n\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"gghistApp\",\n                                             package = \"msst2ap\"),\n                       height = 750, width = 1200)\n\n1  app_init_data &lt;- app$get_value(input = \"data-dataset\")\n  waldo::compare(app_init_data, \"BOD\")\n  expect_equal(\n    object = app_init_data,\n    expected = \"BOD\")\n\n2  app_init_var &lt;- app$get_value(input = \"var-var\")\n  waldo::compare(app_init_var, \"Time\")\n  expect_equal(\n    object = app_init_var,\n    expected = \"Time\")\n  \n3  app$set_inputs(`data-dataset` = \"mtcars\")\n  app_exp_x_01 &lt;- app$get_value(export = \"hist-x\")\n  waldo::compare(\n    x = app_exp_x_01,\n    y = mtcars[1])\n  expect_equal(\n    object = app_exp_x_01,\n    expected = mtcars[1])\n\n4  app$set_inputs(`var-var` = \"disp\")\n  app_exp_plot_obj_01 &lt;- app$get_value(export = \"hist-plot_obj\")\n  waldo::compare(\n    x = app_exp_plot_obj_01,\n    y = purrr::as_vector(mtcars['disp']))\n  expect_equal(\n    object = app_exp_plot_obj_01,\n    expected = purrr::as_vector(mtcars['disp']))\n\n5  app$set_inputs(`hist-bins` = 15)\n  app_set_bins_01 &lt;- app$get_value(input = \"hist-bins\")\n  waldo::compare(app_set_bins_01, 15L)\n  expect_equal(\n    object = app_set_bins_01,\n    expected = 15)\n})\n\n\n1\n\nVerify initial data\n\n2\n\nVerify initial variable\n\n3\n\nVerify exported data\n\n4\n\nVerify exported var\n\n5\n\nVerify histogram changes\n\n\n\n\n\n\nVerify exports\nFinally, we’ll test the exported values by creating app$get_values()$export and checking it’s contents:\n\ntestthat::test_that(\"{shinytest2}: gghistApp\", {\n  testthat::skip_if_not_installed(\"vdiffr\")\n\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"gghistApp\",\n                                             package = \"msst2ap\"),\n                       height = 750, width = 1200)\n\n1  app_init_data &lt;- app$get_value(input = \"data-dataset\")\n  waldo::compare(app_init_data, \"BOD\")\n  expect_equal(\n    object = app_init_data,\n    expected = \"BOD\")\n\n2  app_init_var &lt;- app$get_value(input = \"var-var\")\n  waldo::compare(app_init_var, \"Time\")\n  expect_equal(\n    object = app_init_var,\n    expected = \"Time\")\n  \n3  app$set_inputs(`data-dataset` = \"mtcars\")\n  app_exp_x_01 &lt;- app$get_value(export = \"hist-x\")\n  waldo::compare(\n    x = app_exp_x_01,\n    y = mtcars[1])\n  expect_equal(\n    object = app_exp_x_01,\n    expected = mtcars[1])\n\n4  app$set_inputs(`var-var` = \"disp\")\n  app_exp_plot_obj_01 &lt;- app$get_value(export = \"hist-plot_obj\")\n  waldo::compare(\n    x = app_exp_plot_obj_01,\n    y = purrr::as_vector(mtcars['disp']))\n  expect_equal(\n    object = app_exp_plot_obj_01,\n    expected = purrr::as_vector(mtcars['disp']))\n\n5  app$set_inputs(`hist-bins` = 15)\n  app_set_bins_01 &lt;- app$get_value(input = \"hist-bins\")\n  waldo::compare(app_set_bins_01, 15L)\n  expect_equal(\n    object = app_set_bins_01,\n    expected = 15)\n\n  \n6  exp_values &lt;- app$get_values()$export\n\n7  expect_true(is.data.frame(exp_values$`hist-x`))\n8  expect_equal(exp_values$`hist-x`, mtcars['disp'])\n\n9  expect_true(is.numeric(exp_values$`hist-plot_obj`))\n10  expect_equal(\n    object = exp_values$`hist-plot_obj`,\n    expected = purrr::as_vector(mtcars['disp']))\n})\n\n\n1\n\nVerify initial data\n\n2\n\nVerify initial variable\n\n3\n\nVerify exported data\n\n4\n\nVerify exported var\n\n5\n\nVerify histogram changes\n\n6\n\nExport expected values\n\n7\n\nVerify hist-x is data.frame\n\n8\n\nVerify hist-x is correct column\n\n9\n\nVerify hist-plot_obj is numeric\n\n10\n\nVerify hist-plot_obj is vector\n\n\n\n\n\n\nVerify plot with vdiffr\nNow we verify the plot with the exported plot_obj (in the hist module) with expect_doppelganger() from the vdiffr package.\n\ngg2_plot &lt;- app$get_value(output = \"hist-hist\")\n1  expect_equal(gg2_plot$alt, \"Plot object\")\n2  vdiffr::expect_doppelganger(\n      title = \"mtcars_disp_plot\",\n      fig = ggplot2::ggplot(data = exp_values$`hist-x`,\n              mapping =\n              ggplot2::aes(x = disp)\n          ) +\n            ggplot2::geom_histogram(bins = exp_values$`hist-bins`) +\n            ggplot2::labs(\n              title = paste0(exp_values$`hist-title`,\n                             \" [bins = \",\n                             exp_values$`hist-bins`, \"]\"),\n              y = \"Count\",\n              x = names(exp_values$`hist-x`)\n            ) +\n            ggplot2::theme_minimal()\n      )\n\n\n1\n\nCheck the rendered plot object\n\n\n2\n\nggHistApp() renders a ggplot2 graph, which makes it easier to demonstrate this example of checking a plot from the shinytest2 package website.\n\n\n\n\nI saved the test file and ran the test to confirm the snapshot file was created in tests/testthat/_snaps/:\n\n── Warning (test-shinytest2-gghistApp.R:72:3): {shinytest2}: gghistApp ─────────\nAdding new file snapshot: 'tests/testthat/_snaps/mtcars-disp-plot.svg'\n\n\n\nSet, get, expect\nThe process above is repeated with new values passed to app$set_inputs() and verified with app$get_values():\n\nThe data-dataset, var-var, and hist-bins are updated again with new values.\n\n\n# verify usaarrests_plot ---- \napp$set_inputs(`data-dataset` = \"USArrests\")\napp$set_inputs(`var-var` = 'UrbanPop')\napp$set_inputs(`hist-bins` = 15)\n\n\nThe updated values are exported automatically with exportTestValues() and stored in exp_values:\n\n\n# export values \nexp_values &lt;- app$get_values()$export\n\n\nThe new plot is verified again with expect_doppelganger():\n\n\nvdiffr::expect_doppelganger(\n  title = \"usaarrests_plot\",\n  fig = ggplot2::ggplot(data = exp_values$`hist-x`,\n          mapping =\n          ggplot2::aes(x = UrbanPop)\n      ) + \n        ggplot2::geom_histogram(bins = exp_values$`hist-bins`) +\n        ggplot2::labs(\n          title = paste0(exp_values$`hist-title`, \n                         \" [bins = \",\n                         exp_values$`hist-bins`, \"]\"),\n          y = \"Count\",\n          x = names(exp_values$`hist-x`)\n        ) +\n        ggplot2::theme_minimal()\n  )\n\nNow that we have a template, we can set, get, and expect multiple plot snapshots:\n\n  ## SET -----\n  app$set_inputs(`data-dataset` = \"sleep\")\n  app$set_inputs(`var-var` = 'extra')\n  app$set_inputs(`hist-bins` = 8)\n  # GET ----\n  exp_values &lt;- app$get_values()$export\n  # EXPECT ----\n  vdiffr::expect_doppelganger(\n    title = \"sleep_extra_plot\",\n    fig = ggplot2::ggplot(data = exp_values$data,\n            mapping =\n            ggplot2::aes(x = extra)\n        ) + \n          ggplot2::geom_histogram(bins = exp_values$`hist-bins`) +\n          ggplot2::labs(\n            title = paste0(exp_values$`hist-title`, \n                           \" [bins = \",\n                           exp_values$`hist-bins`, \"]\"),\n            y = \"Count\",\n            x = names(exp_values$x)\n          ) +\n          ggplot2::theme_minimal()\n    )\n\nThe initial run of this test will save the snapshot file to tests/testthat/_snaps/:\ntests/testthat/_snaps/shinytest2-gghistApp\n├── mtcars-disp-plot.svg\n├── sleep-extra-plot.svg\n└── usaarrests-plot.svg\n\n1 directory, 3 files\n\n\nResults\nThe final results of devtools::test() in msst2ap are below:\n\ndevtools::test()\n\n==&gt; devtools::test()\n\nℹ Testing msst2ap\n✔ | F W  S  OK | Context\n✔ |          1 | shinytest2-datasetApp [4.8s]                                                   \n⠼ |          5 | shinytest2-gghistApp       \n⠋ |         11 | shinytest2-gghistApp                                   \n⠙ |         12 | shinytest2-gghistApp                       \n✔ |         13 | shinytest2-gghistApp [5.1s]                                \n✔ |          5 | shinytest2-histogramApp [3.6s]                                                 \n✔ |          2 | shinytest2-selectVarApp [2.2s]                                                 \n✔ |          1 | shinytest2 [4.2s]                                                              \n\n══ Results ══════════════════════════════════════════════════════════════════\nDuration: 19.9 s\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 22 ]"
  },
  {
    "objectID": "series/testing/p4-system-shiny/index.html#recap",
    "href": "series/testing/p4-system-shiny/index.html#recap",
    "title": "Shiny System Tests With shinytest2",
    "section": "Recap",
    "text": "Recap\nThis post has covered creating tests with testthat and shinytest2 for an app-package containing a Shiny application. In general, shinytest2 is designed for end-to-end testing of Shiny applications. System tests (or regression testing) can capture the state of a Shiny app (input, output, and exported values) during user interactions and compare them with a previous state (i.e., snapshots). As we can see, shinytest2 makes it easier to test specific app behaviors and set expectations iteratively with the AppDriver.\nshinytest2 tests can also simulate user interaction in a way that testServer() tests can’t, such as waiting for reactive outputs to update after the input changes, clicking on action buttons, etc. shinytest2 can also be resource-intensive, so it’s recommended to write these tests after you’ve completed the standard testthat unit tests and testServer() tests.\nOther things to consider when writing shinytest2 tests include:\n\nDefine What to Test: Since Shiny apps are interactive, so shinytest2 tests should simulate user interaction as much as possible. The tests should focus on key user interactions and the output they should generate. shinytest2 provides functions for simulating user clicks, inputs, and other interactions. Not every interaction needs to be tested, but crucial ones and those that handle complex logic should be.\nOrganize Your Tests & Use Descriptive Test Names: Organize your tests into separate files based on the app or feature they test. Each test should have a descriptive name that clarifies what the test is for. Organizing your test files with unambiguous names will make it easier to manage multiple tests, and it will make it easier to understand what’s going wrong when a test fails.\nCreate snapshots for expected outputs: Use snapshot files to verify that an app’s output matches the expected results. AppDriver$expect_values() generates .json and .png snapshot files for the application. The .json file contains input, output, and export values, and the .png file is a debug screenshot, which records how the app looked when the values where captured. These files can then be compared to a baseline snapshot.\nExport app values: While snapshot files are great for detecting changes, it’s important to remember that “differences in the captured screenshot will never cause test failures.” Manually inspecting the snapshot .png files during test development can also be time-consuming and tedious. Wherever possible, export app values and compare them against expected reference values."
  },
  {
    "objectID": "series/testing/p4-system-shiny/index.html#footnotes",
    "href": "series/testing/p4-system-shiny/index.html#footnotes",
    "title": "Shiny System Tests With shinytest2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“In some cases, it’s useful to snapshot some bits of internal state of an application – state that’s not reflected directly in the inputs or outputs. This can be done by exporting values.” - shinytest2 documentation↩︎\n“It cannot be recommended enough to use exportTestValues() to test your Shiny app’s reactive values.” - shinytest2 documentation↩︎\nRead more about exporting test values here.↩︎\nThis section replicates these test examples from shinytest2 using the ggHistApp().↩︎\nThis version is loaded from a inst/dev/histogramApp/R/modules.R file.↩︎\nThis version is loaded from a inst/dev/histogramApp/R/app.R file.↩︎"
  },
  {
    "objectID": "series/testing/p2-nonpkg-unit-tests/index.html",
    "href": "series/testing/p2-nonpkg-unit-tests/index.html",
    "title": "Testing Non-Package Shiny Apps",
    "section": "",
    "text": "packages\nlibrary(testthat)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(shiny)\nlibrary(vdiffr)\nlibrary(shinytest2)\nThis is the second post in a series on testing Shiny applications. I’ll cover testing Shiny module server functions using the testhat package outside of an R package structure. The noap branch of the sapkgs."
  },
  {
    "objectID": "series/testing/p2-nonpkg-unit-tests/index.html#testing-module-server-functions",
    "href": "series/testing/p2-nonpkg-unit-tests/index.html#testing-module-server-functions",
    "title": "Testing Non-Package Shiny Apps",
    "section": "Testing module server functions",
    "text": "Testing module server functions\nThis post covers how shiny::testServer() works using a simple Shiny application. The code for abcApp() is an RStudio project (i.e., there is a noap.Rproj file in the parent folder), but it’s not part of an R package. Developing shiny applications as R packages is highly recommended, but it’s possible to begin writing unit tests before your application is a fully developed shiny app-package.\nFor more information regarding performing tests outside of the package environment, see this issue on GitHub.\n\nABC App\ntestthat is designed to perform unit tests in R packages, but not all Shiny apps begin as R packages. The Shiny application we’ll be using for this demonstration has been written using Shiny modules and a single utility function.\nThe standalone application function (launchApp()) is stored in app.R, the modules are contained in modules.R, and the single utility function is stored in utils.R:\n├── README.md\n├── app.R\n├── modules.R\n├── sapkgs.Rproj\n├── tests/\n│   ├── testthat/\n│   │   ├── test-mod_abc_server.R\n│   │   └── test-num_super_script.R\n│   └── testthat.R\n└── utils.R\n\nThe tests/ folder contains the following:\ntests\n├── testthat\n│   ├── test-mod_abc_server.R\n│   └── test-num_super_script.R\n└── testthat.R\n\ntests/ has a testthat.R ‘test runner’ file\n\nNew test files should be placed in tests/testthat/ (see example test-mod_abc_server.R below):\n\n\n\nUI module function\nIn this small example app, both ui and server modules are stored in the modules.R file.\n\nUI module:\n\n\nmod_abc_ui() (example ui module function)\n# ui module\nmod_abc_ui &lt;- function(id) {\n  ns &lt;- NS(id)\n  tagList(\n    column(\n      width = 3,\n      offset = 2,\n      numericInput(\n        inputId = ns(\"num\"),\n        label = \"Alphabet Number\",\n        value = 5,\n        min = 1,\n        max = 26\n      )\n    ),\n    column(\n      width = 6,\n      br(),\n      uiOutput(\n        outputId = ns(\"txt\")\n      ),\n      verbatimTextOutput(ns(\"out\"))\n    )\n  )\n}\n\n\n\n\n\nServer module function\nThe counterpart to mod_abc_ui() is mod_abc_server():\n\nServer module:\n\n\nmod_abc_server() (example server module function)\n# server module\nmod_abc_server &lt;- function(id) {\n  moduleServer(id, function(input, output, session) {\n    # reactive\n    letter &lt;- reactive({\n      LETTERS[input$num]\n    })\n    # super script\n    sup_scrpt &lt;- reactive({\n      num_super_script(x = input$num)\n    })\n    # output\n    output$txt &lt;- renderUI({\n      HTML(\n        paste0(\n          em(\n            \"The \", code(input$num), code(sup_scrpt()),\n            \" letter in the alphabet is: \", code(letter())\n          )\n        )\n      )\n    })\n    output$out &lt;- renderPrint({\n      HTML(\n        paste0(\n          em(\n            \"The \", code(input$num), code(sup_scrpt()),\n            \" letter in the alphabet is: \", code(letter())\n          )\n        )\n      )\n    })\n  })\n}\n\n\n\n\n\nModule utility function\nThe mod_abc_server() function uses the num_super_script() function stored in utils.R:\n\nUtility function:\n\n\nnum_super_script() (example utility function)\n# utility function\nnum_super_script &lt;- function(x) {\n      num &lt;- as.numeric(x)\n      if (num &lt; 0) {\n        stop(\"not a valid number\")\n      } else if (num &gt; 26) {\n        stop(\"not a valid number\")\n      } else if (num == 0) {\n        super_script &lt;- \"\"\n      } else if (num == 1 | num == 21) {\n        super_script &lt;- \"st\"\n      } else if (num == 2 | num == 22) {\n        super_script &lt;- \"nd\"\n      } else if (num == 3 | num == 23) {\n        super_script &lt;- \"rd\"\n      } else {\n        super_script &lt;- \"th\"\n      }\n    return(super_script)\n}\n\n\n\n\n\nStandalone app function\n\nStandalone app functions include a call to shiny::shinyApp():\n\n\nlaunch() (example app with modules)\nlaunchApp &lt;- function() {\n  shinyApp(\n    ui = fluidPage(\n      h2(\"ABC App\"),\n      fluidRow(\n        mod_abc_ui(\"x\")\n      )\n    ),\n    server = function(input, output, session) {\n      mod_abc_server(\"x\")\n    }\n  )\n}\nlaunchApp()\n\n\n\nThe call to shiny::shinyApp() is placed inside the launchApp() function\nThe ui argument is wrapped in shiny::fluidPage() with the ui module function (mod_abc_ui()) placed inside fluidRow()\nThe server argument includes the standard function(input, output, session) and the module server companion function–mod_abc_server()–with a matching id arguments\n\n\nBecause launchApp() is not part of a package, shiny and testthat are loaded and the modules and utility function are sourced in the top of the app.R file.\n\n\nsource utils.R and modules.R in app.R\n# packages --------------------------------------------------------\nlibrary(shiny)\nlibrary(testthat)\n\n# utils ------------------------------------------------------------------\nsource(\"utils.R\")\n\n# modules ------------------------------------------------------------------\nsource(\"modules.R\")\n\n\n\n\n\nUsing testServer()\nIn the test-mod_abc_server.R file, I’ll add testServer() and include the module server function as the first argument:\n\napp is the module server function (mod_abc_server) or any shiny.appobj\n\n\napp = mod_abc_server\ntestServer(app = mod_abc_server, {\n\n})\n\n\n\n\nTesting input$s\n\nThe first test I’ll add will check the initial value of input$num\n\nI’ll also include a custom message with cat()\n\n\n\ntest initial value with custom message\ntestServer(mod_abc_server, {\n  # Test initial value\n  testthat::expect_equal(input$num, NULL)\n  cat(\"\\n Test 1 initial input$num = NULL: \", is.null(input$num), \"\\n\")\n})\n\n\n\ntestServer() allows me to set new input values with session$setInputs()\n\nUse session$setInputs() to set input$num to 3\n\nTest 2 confirms input$num has changed (we’ll also add another custom message with cat())\n\n\n\nsetInputs() and test inputs\ntestServer(mod_abc_server, {\n  # set inputs\n  session$setInputs(num = 3)\n  # Test set inputs\n  testthat::expect_equal(input$num, 3)\n  cat(\"\\n Test 2 setInputs(num = 3):\", input$num, \"\\n\")\n})\n\n\n\n\n\nTesting reactive values\nThe module’s reactive values are also available to in testServer().\n\nTest 3 adds a test for sup_scrpt() (given the changed value of input$num)\n\nThe expected value is what I’m expecting num_super_script() to return:\n\n\n\nCheck sup_scrpt() reactive value with expect_equal()\ntestServer(mod_abc_server, {\n  # Test super script\n  testthat::expect_equal(object = sup_scrpt(), expected = \"rd\")\n  cat(\"\\n Test 3 sup_scrpt(): = 'rd':\", sup_scrpt(), \"\\n\")\n})\n\n\n\nFor completeness we’ll add a test for letter()\n\n\n\nCheck letter() reactive value with expect_equal()\ntestServer(mod_abc_server, {\n  # Test letter\n  expect_equal(object = letter(), expected = \"C\")\n  cat(\"\\n Test 4 letter() = C:\", letter(), \"\\n\")\n})\n\n\n\n\n\nTesting output$s\nThe module output values are also available as output$&lt;value&gt;.\n\nThe final test will verify this object is a list and print the results to the Console\n\nOutput tests can verify that output$txt has been updated with input$num:\n\n\n\nCheck module output values\ntestServer(mod_abc_server, {\n  # Test output\n  expect_true(is.list(output$txt))\n  print(output$txt)\n})\n\n\n\nFinally, I’ll run the tests with test_file():\n\n\ntest_file(path = \"/path/to/app/tests/testthat/\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\n Test 1 initial input$num = NULL:  TRUE \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ]\n Test 2 setInputs(num = 3): 3 \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 3 ]\n Test 3 sup_scrpt(): = 'rd': rd \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 4 ]\n Test 4 letter() = C: C \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 5 ]$html\n&lt;em&gt;\n  The \n  &lt;code&gt;3&lt;/code&gt;\n  &lt;code&gt;rd&lt;/code&gt;\n   letter in the alphabet is: \n  &lt;code&gt;C&lt;/code&gt;\n&lt;/em&gt;\n\nThe results show the tests passed! Now I am confident inputs, reactive values (sup_scrpt() & letter()), outputs behave as expected.\n\n\n\nRecap\nThe example above provides a workflow for using testServer() with testthat outside a package environment. The checklist below summarizes the steps required to test your application’s module server functions:\n\nCreate test files (in tests/testthat/)\n\nAll test files should have the test- prefix\n\nVerify inputs with session$setInputs(inputId = &lt;value&gt;)\n\nAll input$ values should initially be NULL\n\nTest reactive values by referring to them as you would in the module server\n\nCompare expected values after changing inputs with session$setInputs()\n\nTest outputs using output$&lt;value&gt; to check changes to the inputs and reactives\n\nCheck output values with output$txt\n\n\nThis concludes running tests on noap. Ideally, Shiny applications are developed as an R package (which I’ll cover in future posts), but now you know how to perform tests if this isn’t the case. The files for this demonstration are located here..\nFor a more comprehensive review of testing, check out the chapters on testing in R packages and Mastering Shiny."
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html",
    "href": "series/shiny-frameworks/devtools/index.html",
    "title": "Creating a shiny app-package",
    "section": "",
    "text": "In this post, I’ll be using devtools and usethis to develop duap, an R package that contains a shiny application (i.e., devtools/usethis app-package).\nThe R package development workflow is well documented in R Packages. I’ve written this post because sometimes I encounter shiny developers who are comfortable with reactivity, modules, HTML/CSS, etc., but they haven’t developed an R package. I’ll walk through converting an existing shiny application into an app-package in detail, because R package development differs from creating a standalone shiny application. My hope is that this post will ‘fill in the gaps’ of package development (and keep you from rebuilding your application entirely from scratch)."
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#outline",
    "href": "series/shiny-frameworks/devtools/index.html#outline",
    "title": "Creating a shiny app-package",
    "section": "Outline",
    "text": "Outline\nI’ll be using the application from RStudio’s Building Web Applications with Shiny tutorial. This is a great resource that can be run locally or on posit.cloud. I’ve organized the app-package development process into three areas: Start, Build, and Use.\n\nStart covers the steps required to begin building a shiny app withing a package framework (from the console and IDE).\nBuild covers the development process, which includes writing and storing code, data, external resources (i.e., data), documentation, and testing.\nUse shows how developers can launch their application using the given framework/package locally (i.e., within the RStudio (Posit) IDE).\n\nThe GitHub repo with the code for duap is located here if you’d like to follow along."
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#start",
    "href": "series/shiny-frameworks/devtools/index.html#start",
    "title": "Creating a shiny app-package",
    "section": "Start",
    "text": "Start\nIt’s highly recommended to build your shiny app as an R package. R packages require more work upfront (and a bit of a learning if you’re not familiar with the process), but the long-term benefits are usually well worth the initial investment of time.\n\nWhat makes an R package?\nIf you’ve been reading R packages or Mastering Shiny, you may have seen one of the following quotes,\n\n“’RStudio and devtools consider any directory containing DESCRIPTION to be a package’ - R Packages\n\n\n‘all a project needs to be a package is a directory of R/ files and a DESCRIPTION file.’ - Packages Chapter of Mastering Shiny\n\nSo which is it–a DESCRIPTION file or a DESCRIPTION file and a directory of R/ files? Typically, R packages contain the following files:\n\nrpkg/\n  ├── DESCRIPTION\n  ├── NAMESPACE\n  ├── rpkg.Rproj\n  ├── R/\n  ├── man/\n  ├── tests/\n  ├── data/ \n  ├── vignettes/ \n  └── inst/ \n\n1 directory, 5 files\n\nHowever, these files are not required to convert an existing shiny app project into an R package. I’ll use the app stored in this bare-bones shiny app (bbsa) to demonstrate. Feel free to download this app and follow along.\nThe initial files in this project are below:\n\nbbsa/\n  ├── README.md\n  ├── app.R\n  ├── bbsa.Rproj\n  ├── movies.RData\n  └── utils.R\n\n1 directory, 5 files\n\nbbsa will run the application stored in app.R, load the data (movies.RData), and source the utility function stored in utils.R. This application has a README.md, but no DESCRIPTION file.\n\nProject .Rproj files\nWhen a new shiny app project is created from the New Project Wizard, the .Rproj file contains the following (if you open it with a text-editor)\n\nVersion: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTeX: XeLaTeX\n\nThese fields are settings for a shiny app project, and none of them are specific to R packages.\nLets see what happens if I create an R/ folder (with the utils.R file) and a DESCRIPTION file.\n\n\nR/ & DESCRIPTION\nThe R/utils.R file will hold the contents of utils.R in the root folder:\n\npoint_plot &lt;- function(df, x_var, y_var, col_var, alpha_var, size_var) {\n    ggplot2::ggplot(data = df,\n      ggplot2::aes(x = .data[[x_var]],\n          y = .data[[y_var]],\n          color = .data[[col_var]])) +\n      ggplot2::geom_point(alpha = alpha_var, size = size_var)\n\n}\n\nAnd the contents of the DESCRIPTION file are below (adapted from R Packages):\nPackage: myShinyAppPkg\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.0.0.9000\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", \n    role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: `use_mit_license()`, `use_gpl3_license()` or friends to pick a\n    license\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nThe bbsa shiny app project now has the following files and folders:\n\nbbsa/\n├── DESCRIPTION\n├── R\n│   └── utils.R\n├── README.md\n├── app.R\n├── bbsa.Rproj\n├── movies.RData\n└── utils.R\n\n2 directories, 7 files\n\nIf I take a quick look at the available panes in the IDE, I can confirm none of the Build tools are available:\n\n\n\n\n\n\n\n\n\n\n(a) shiny app IDE\n\n\n\n\n\nFigure 1: Project IDE panes\n\n\n\n\n\n\nTerminate R session\nI’ll terminate my R session by clicking on Session &gt; Terminate R… &gt; Yes\n\n\n\n\n\n\n\n\n\n\n\n(a) Session &gt; Terminate\n\n\n\n\n\n\n\n\n\n\n\n(b) Click Yes\n\n\n\n\n\n\n\nFigure 2: Terminate your R session\n\n\n\n\n\nPackage .Rproj file\nNow I’ll open the bbsa.Rproj file with a text-editor again (or expand the code below to view the new bbsa.Rproj):\n\n\nshow/hide package .Rproj\nVersion: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTeX: XeLaTeX\n\nBuildType: Package\nPackageUseDevtools: Yes\nPackageInstallArgs: --no-multiarch --with-keep.source\n\n\nI can see three new lines have been added to bbsa.Rproj:\n\nBuildType: Package\n\nPackageUseDevtools: Yes\n\nPackageInstallArgs: --no-multiarch --with-keep.source\n\nIt’s not important that you know the meaning for each of these fields, but you can probably tell they’re for converting our previous project into a package (and you’ll see the third one again during package development!)\nI’ll take another look at the RStudio IDE to review the available panes:\n\n\n\n\n\n\n\n\n\n\n(a) shiny app-package IDE\n\n\n\n\n\nFigure 3: App-package IDE panes\n\n\n\n\nI can see the Build pane has been added–now I can Install, Test, and Check my package with a single click!\n\n\nWhat happened to R/utils.R?\nBut wait–if I open R/utils.R, I notice that file is now empty:\n\n\n\n\n\n\n\n\n\n\n(a) Empty R/ file\n\n\n\n\n\nFigure 4: R/utils.R has been cleared out!\n\n\n\n\n\n\n\n\n\n\nImportantConverting projects to packages with DESCRIPTION files\n\n\n\n\n\n\nAdding a DESCRIPTION file to your RStudio project will convert it to an R package, but any files stored in the standard packages folders (i.e., R/, man, inst/, etc.) will be removed (i.e., wait until the Build pane is available, then create these folders).\n\n\n\n\nNow I’ll cover creating an R package from the Console and using the New Project Wizard\n\n\n\nFrom the Console\nTo create a shiny app package, I’ll install devtools (which also installs usethis).\n\ninstall.packages(\"devtools\")\nlibrary(devtools)\n\nIf I am creating a package from the console, the function for building a new package is usethis::create_package():\n\nusethis::create_package(path = \"path/to/app-package/folder\")\n\nA new RStudio session will open (and the name of the project–i.e., the name of the .Rproj file–will be identical to the package name).\n\n\nFrom the Project Wizard\nIf I am using RStudio’s New Project Wizard to create a new shiny app package, I’d see the following defaults:\n\n\n\n\n\n\nFigure 5: Default usethis::create_package project setup\n\n\n\nThe new package built from the console will have the following folder and files:\nduap/\n  ├── DESCRIPTION\n  ├── NAMESPACE\n  ├── R/\n  └── duap.Rproj\n  \n1 directory, 3 files\nPackages built from the New Project Wizard will have a few additional folders and files:\nduap/\n  ├── DESCRIPTION\n  ├── NAMESPACE\n  ├── R/\n  │   └── hello.R\n  ├── man/\n  │   └── hello.Rd\n  ├── myRPkg.Rproj\n  └── renv/\n      ├── activate.R\n      ├── sandbox/\n      │   └── R-4.2\n      └── settings.dcf\n\n4 directories, 7 files\nThese additional files are:\n\nhello.R in the R/ folder\n\nhello.Rd in the man/ folder\n\na renv/ folder for package management\n\nR/hello.R and man/hello.Rd are boilerplate files and can be deleted, but both package setups have a DESCRIPTION, NAMESPACE, R/ folder, and .Rproj file. These four items can be thought of as the ‘minimal package’ setup required to access RStudio’s Build tools."
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#metadata-files",
    "href": "series/shiny-frameworks/devtools/index.html#metadata-files",
    "title": "Creating a shiny app-package",
    "section": "Metadata files",
    "text": "Metadata files\nR packages have two metadata files: DESCRIPTION and NAMESPACE. Neither of these files have extensions, and both contain vital information for your package to function properly.\nWe’ll manually edit the DESCRIPTION file, but the NAMESPACE file is automatically generated during the development process.\n\nDESCRIPTION\nThe DESCRIPTION file plays an important role in R packages (as we learned above)–that’s why creating this file is the first step when converting an existing app (and when creating a new golem apps).\nThe initial DESCRIPTION file in duap is below:\nPackage: duap\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.0.0.9000\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", \n    role = c(\"aut\", \"cre\"),\n    comment = c(ORCID = \"YOUR-ORCID-ID\"))\nDescription: What the package does (one paragraph).\nLicense: `use_mit_license()`, `use_gpl3_license()` or friends to pick a\n    license\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nThe package name is automatically added, but the remaining fields need to be completed (consult R packages for more information on filling out the DESCRIPTION file).\nThe DESCRIPTION file in the duap prompts the RStudio IDE to activate the Build tools pane (see below):\n\n\n\n\n\n\nFigure 6: Package Build tools"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#application-code",
    "href": "series/shiny-frameworks/devtools/index.html#application-code",
    "title": "Creating a shiny app-package",
    "section": "Application code",
    "text": "Application code\nThe contents of the app.R and utils.R need to be moved into the R/ folder. When developing R packages, new .R files are created with usethis::use_r().\n\nuse_r()\nI’m going to create duap using modules to separate the app into the following digestible mental ‘chunks’:\n\nThe app collects the inputs in the shiny::sidebarPanel()\nThese values are then used to create a plot in the shiny::mainPanel()\n\nBased on this layout, I’ll create one module to collect and return the user-inputs (mod_var_input), and another module to display the plot (mod_display_plot).\nI’ll create these files using usethis::use_r() below:\n\nusethis::use_r(\"mod_var_input\")\n\n✔ Setting active project to '/Users/mjfrigaard/projects/duap'\n• Modify 'R/mod_var_input.R'\n• Call `use_test()` to create a matching test file\n\nusethis::use_r(\"mod_display_plot\")\n\n• Modify 'R/mod_display_plot.R'\n• Call `use_test()` to create a matching test file\nThe display module also relies on a utility function (plot_points()), so I need to create a script for the utility function, which I put in a file with a name similar to the module it belongs to (i.e., utils_display_plot).\n\nusethis::use_r(\"utils_display_plot\")\n\n• Modify 'R/utils_display_plot.R'\n• Call `use_test()` to create a matching test file\nFinally, I’ll place the modules into basic ui and server arguments in a call to shiny::shinyApp():\n\nusethis::use_r(\"moviesApp\")\n\n• Modify 'R/moviesApp.R'\n• Call `use_test()` to create a matching test file\nModules consist of two functions; one in the UI (with a _ui suffix), and another in the server (with a _server suffix), but it’s common practice to combine them in a single file.\nBelow is the mod_var_input module:\n\nThe ui function is stored in mod_var_input_ui:\n\n\nCode\nmod_var_input_ui &lt;- function(id) {\n  ns &lt;- shiny::NS(id)\n  shiny::tagList(\n    shiny::selectInput(\n      inputId = ns(\"y\"),\n      label = \"Y-axis:\",\n      choices = c(\n        \"IMDB rating\" = \"imdb_rating\",\n        \"IMDB number of votes\" = \"imdb_num_votes\",\n        \"Critics Score\" = \"critics_score\",\n        \"Audience Score\" = \"audience_score\",\n        \"Runtime\" = \"runtime\"\n      ),\n      selected = \"audience_score\"\n    ),\n    shiny::selectInput(\n      inputId = ns(\"x\"),\n      label = \"X-axis:\",\n      choices = c(\n        \"IMDB rating\" = \"imdb_rating\",\n        \"IMDB number of votes\" = \"imdb_num_votes\",\n        \"Critics Score\" = \"critics_score\",\n        \"Audience Score\" = \"audience_score\",\n        \"Runtime\" = \"runtime\"\n      ),\n      selected = \"imdb_rating\"\n    ),\n    shiny::selectInput(\n      inputId = ns(\"z\"),\n      label = \"Color by:\",\n      choices = c(\n        \"Title Type\" = \"title_type\",\n        \"Genre\" = \"genre\",\n        \"MPAA Rating\" = \"mpaa_rating\",\n        \"Critics Rating\" = \"critics_rating\",\n        \"Audience Rating\" = \"audience_rating\"\n      ),\n      selected = \"mpaa_rating\"\n    ),\n    shiny::sliderInput(\n      inputId = ns(\"alpha\"),\n      label = \"Alpha:\",\n      min = 0, max = 1, step = 0.1,\n      value = 0.5\n    ),\n    shiny::sliderInput(\n      inputId = ns(\"size\"),\n      label = \"Size:\",\n      min = 0, max = 5,\n      value = 2\n    ),\n    shiny::textInput(\n      inputId = ns(\"plot_title\"),\n      label = \"Plot title\",\n      placeholder = \"Enter plot title\"\n    )\n  )\n}\n\n\nThe server function is stored in mod_var_input_server:\n\n\nCode\nmod_var_input_server &lt;- function(id) {\n\n  shiny::moduleServer(id, function(input, output, session) {\n    return(\n      list(\n        \"x\" = shiny::reactive({\n          input$x\n        }),\n        \"y\" = shiny::reactive({\n          input$y\n        }),\n        \"z\" = shiny::reactive({\n          input$z\n        }),\n        \"alpha\" = shiny::reactive({\n          input$alpha\n        }),\n        \"size\" = shiny::reactive({\n          input$size\n        }),\n        \"plot_title\" = shiny::reactive({\n          input$plot_title\n        })\n      )\n    )\n  })\n}\n\n\n\nView the display module here.\n\n\n\n\nStandalone app function\nAfter I’ve written the modules and utility functions, I need to add these into a standalone app function moviesApp() (stored in R/moviesApp.R).\n\nThis file contains a call to shiny::shinyApp() and includes the module functions (in their relative positions)\n\nNote the ids in each module function pair must match to create the shared namespace.\n\n\nmoviesApp &lt;- function() {\n  # call to shinyApp()\n  shiny::shinyApp(\n\n    # UI ----\n    ui = shiny::fluidPage(\n      shiny::sidebarLayout(\n        shiny::sidebarPanel(\n          # UI input module ----\n          mod_var_input_ui(\"vars\")\n        ),\n        # UI display module ----\n        shiny::mainPanel(\n          mod_display_plot_ui(\"plot\")\n        )\n      )\n    ),\n\n    server = function(input, output, session) {\n      # server input module (capturing inputs) ----\n      selected_vars &lt;- mod_var_input_server(\"vars\")\n      # server display module (rendering outputs) ----\n      mod_display_plot_server(\"plot\", \n                              var_inputs = selected_vars)\n    }\n  )\n}\n\n\n\n\nroxygen2\nWhen I’m confident my code works (and the app renders), I want to make sure these functions are properly documented by describing each function with roxygen2 tags. To quickly insert a roxygen2 skeleton, use the RStudio IDE (or the keyboard shortcut: Option + Shift + Command + R)\nThe standard roxygen2 skeleton tags include @param, @return, @export, and @examples\n\n@param lists the existing arguments (or variables) for the function\n@return should be a description of the object/side-effect/thing the function produces (and any warnings or errors if used incorrectly)\n\nThe following roxygen2 tags will be used to update the NAMESPACE file (which you should never edit manually!)\n\n@export will make the function available to other people when they use your package\n@importFrom vs. @import\n\nit’s always a good idea to be explicit about the external functions and packages you’re using, so most of the time you should use @importFrom (there’s even a handy helper usethis::use_import_from(\"package\", \"function\"))\n\n@import should only be used when “you make such heavy use of so many functions from another package that you want to import its entire namespace. This should be relatively rare.”\n\n\nroxygen2 imports and exports are covered in more depth in R packages..\nYou can see the full code for point_plot() below (or follow this link to view all the modules in the R/ folder):\n\nClick on Code to view\n\n\n\nCode\n#' Plot points (shiny)\n#'\n#' @param df input dataset (tibble or data.frame)\n#' @param x_var x variable\n#' @param y_var y variable\n#' @param col_var color variable\n#' @param alpha_var alpha value\n#' @param size_var size value\n#'\n#' @return plot object\n#' @export point_plot\n#'\n#' @importFrom ggplot2 ggplot aes geom_point\n#'\n#' @examples\n#' require(duap)\n#' movies &lt;- duap::movies\n#' point_plot(df = movies,\n#'   x_var = \"critics_score\",\n#'   y_var = \"imdb_rating\",\n#'   col_var = \"critics_rating\",\n#'   alpha_var = 1/3,\n#'   size_var = 2)\n#' }\npoint_plot &lt;- function(df, x_var, y_var, col_var, alpha_var, size_var) {\n    ggplot2::ggplot(data = df,\n      ggplot2::aes(x = .data[[x_var]],\n          y = .data[[y_var]],\n          color = .data[[col_var]])) +\n      ggplot2::geom_point(alpha = alpha_var, size = size_var)\n\n}\n\n\n\n\n\n\n\n\nTipTip: roxygen2 skeleton\n\n\n\n\n\n\nAs well as generating .Rd files, roxygen will also create a NAMESPACE for you, and will manage the Collate field in DESCRIPTION\n\n\n\n\n\n\nFigure 7: Standard roxygen2 skeleton"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#test-drive",
    "href": "series/shiny-frameworks/devtools/index.html#test-drive",
    "title": "Creating a shiny app-package",
    "section": "Test drive",
    "text": "Test drive\n\n\n“The load_all() function is arguably the most important part of the devtools workflow.” - R Packages, 2ed\n\n\nYou’ll use the devtools::load_all() function frequently while you’re developing your app-package. load_all() simulates how your functions will work when someone else uses your package. This removes the need to define them in the global workspace. It also gives you access to the functions from any add-on packages you’ve imported into your NAMESPACE (i.e., you won’t need to run library()).\nI highly recommend using the keyboard shortcuts:\n\n\n\n\n\n\nImportantdevtools::load_all() keyboard shortcuts\n\n\n\n\n\nmacOS: Cmd + Shift + L\nWindows/Linux: Ctrl + Shift + L\n\n\n\n\nRead more about the many benefits of using load_all() in R packages.\n\nload_all()\nAfter documenting everything with roxygen2, I want to make sure none of the functions are in my Environment (remove with rm() if necessary) and load the functions with devtools::load_all().\n\ndevtools::load_all()\n\nℹ Loading duap"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#namespace-help-pages",
    "href": "series/shiny-frameworks/devtools/index.html#namespace-help-pages",
    "title": "Creating a shiny app-package",
    "section": "NAMESPACE & Help pages",
    "text": "NAMESPACE & Help pages\ndevtools::document() processes the roxygen2 tags to generate the NAMESPACE and the .Rd files in the man/ folder. The .Rd files are used to access the help files (i.e., package::function() can be accessed with ??function).\nManaging your package NAMESPACE file is not something you do directly: it’s handled with the roxygen2 tags we covered above. The keyboard shortcuts for devtools::document() are below:\n\n\n\n\n\n\nImportantdevtools::document() keyboard shortcuts\n\n\n\n\n\nmacOS: Cmd + Shift + D\nWindows/Linux: Ctrl + Shift + D\n\n\n\n\n\ndocument()\nRun devtools::document() when you’ve written a new function with roxygen2 tags or included a package in the DESCRIPTION file under Imports:\n\ndevtools::document()\n\nℹ Updating duap documentation\nFirst time using roxygen2. Upgrading automatically...\nSetting `RoxygenNote` to \"7.2.3\"\nℹ Loading duap\nWriting NAMESPACE\nWriting mod_plot_ui.Rd\nWriting mod_plot_server.Rd\nWriting point_plot.Rd\nWriting mod_var_input_ui.Rd\nWriting mod_var_input_server.Rd\nWriting moviesApp.Rd\n\nNAMESPACE != DESCRIPTION\nIt’s important to understand that devtools::document() will use the roxygen2 tags to create the man/*.Rd files and update the NAMESPACE, but devtools::document() does not update the Imports: section in the DESCRIPTION.\nTo add packages dependencies to the DESCRIPTION, you’ll need to use the usethis::use_package() function. Read more on this topic in Confusion about Imports.\nThe table below shows the connection between roxygen2 tags, the resulting NAMESPACE entry, and what should be listed in the DESCRIPTION.\n\n\n\n\n\n\n\nNoteroxygen2, NAMESPACE & DESCRPTION\n\n\n\n\n\n\n\n\n\n\nroxygen2 tag\n\n\nNAMESPACE directive\n\n\nAdded in DESCRIPTION\n\n\n\n\n\n\n@importFrom\n\n\nimportFrom() : import selected object from another NAMESPACE\n\n\nNothing\n\n\n\n\n@import\n\n\nimport(): import all objects from another package’s NAMESPACE.\n\n\nImports:\n\n\n\n\n@export\n\n\nexport() : export the function, method, generic, or class so it’s available outside of the package (in the NAMESPACE)\n\n\nNothing"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#checking-installation",
    "href": "series/shiny-frameworks/devtools/index.html#checking-installation",
    "title": "Creating a shiny app-package",
    "section": "Checking installation",
    "text": "Checking installation\nAfter loading and documenting the duap package, I want to make sure I can install the package into my library with devtools::install(). The keyboard shortcut for devtools::install() is below:\n\n\n\n\n\n\nImportantdevtools::document() keyboard shortcuts\n\n\n\n\n\nmacOS: Cmd + Shift + B\nWindows/Linux: Ctrl + Shift + B\n\n\n\n\n\ninstall()\n\ndevtools::install()\n\n── R CMD build ────────────────────────────────────────────────────────────────\n✔  checking for file ‘/Users/mjfrigaard/projects/duap/DESCRIPTION’ ...\n─  preparing ‘duap’: (1.8s)\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts (520ms)\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘duap_0.1.0.tar.gz’\n   \nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD INSTALL \n  --install-tests \n* installing to library ...\n* installing *source* package ‘duap’ ...\n** using staged installation ...\n** R\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n** building package indices\n** testing if installed package can be loaded from temporary location\n** testing if installed package can be loaded from final location\n** testing if installed package keeps a record of temporary installation path\n* DONE (duap)\nRestart your R session and ensure you have a clean workspace:\n   Restarting R session...\n\n* Project '~/projects/duap' loaded. [renv 0.16.0]\nThen load your package with library():\n\nlibrary(duap)\n\nYou can also use Install icon in the Build pane, which installs the package, restarts the R session, and loads the package all with one click!\n\n\n\n\n\n\nFigure 8: Build install package\n\n\n\n\n\n\n\n\n\nFigure 9: Build restart and load\n\n\n\n\nRecap: the R/ folder\nThe sequence I’ve demonstrated above (create .R file, write function, document with roxygen2, load, document, install) is the ‘minimal version’ of the full development workflow.\nOnce a ‘beta’ version of the app is deployed, you will want to come back to the app to refactor, write tests, and make sure all the items in devtools::check() pass.\nStoring the application’s code in the R/ folder and (using RStudio’s build tools) keeps files organized, well documented, and self-contained:\n\nAll the code is stored in the R/ folder\nI’ve separated my code into smaller pieces (modules) that can be tested independently (more on this later)\nMy dependencies are being managed by roxygen2 and devtools::document(), which will update the NAMESPACE with any functions tagged with @importFrom (or @import)\n\nI can also access functions I’ve written outside by adding @export\n\n\n\n\n\n\n\n\nFigure 10: Function documentation in man/ folder\n\n\n\nNow that I have the R version/package management being tracked and stored with renv/ & renv.lock, function documentation in the .Rd files, the DESCRIPTION and NAMESPACE, I can move onto adding and using data in a shiny app package."
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#additional-package-files",
    "href": "series/shiny-frameworks/devtools/index.html#additional-package-files",
    "title": "Creating a shiny app-package",
    "section": "Additional package files",
    "text": "Additional package files\nMost app-packages will require files beyond the .R files in the R/ folder. Apps will often use data files when they’re deployed, which we’ll cover next.\n\nuse_data_raw()\nusethis::use_data() or usethis::use_data_raw() make it simple to add data to the application package:\n\nusethis::use_data_raw(\"movies\")\n\n✔ Creating 'data-raw/'\n✔ Writing 'data-raw/movies.R'\n• Modify 'data-raw/movies.R'\n• Finish the data preparation script in 'data-raw/movies.R'\n• Use `usethis::use_data()` to add prepared data to package\nIn the data-raw/movies.R script, I want to import the movies.RData file, but where should I import it from? It depends. In R packages, data is stored in either data/ or data-raw/. To access a copy of the movies dataset in duap (i.e., with duap::movies), I can place the movies.RData file in data-raw/ and import it by adding the following to data-raw/movies.R:\n## code to prepare `movies` dataset goes here\nload(\"data-raw/movies.RData\")\nusethis::use_data(movies, overwrite = TRUE)\nNote data-raw/movies.R includes a call to usethis::use_data(), and when it’s executed, I can see a data/ folder is created and movies is saved as movies.rda:\n\nload(\"data-raw/movies.RData\")\nusethis::use_data(movies, overwrite = TRUE)\n\n✔ Adding 'R' to Depends field in DESCRIPTION\n✔ Creating 'data/'\n✔ Saving 'movies' to 'data/movies.rda'\n• Document your data (see 'https://r-pkgs.org/data.html')"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#installed-files",
    "href": "series/shiny-frameworks/devtools/index.html#installed-files",
    "title": "Creating a shiny app-package",
    "section": "Installed files",
    "text": "Installed files\nThe inst/ folder plays a special role when developing R packages:\n\n\n“When a package is installed, everything in inst/ is copied into the top-level directory of the installed package” - R Packages, 2ed\n\n\nConsider the example folder and files below: file.txt, CITATION, and extdata/my_data.csv:\n\n\n\nSource (development) form\ninst/\n  ├── file.txt\n  ├── CITATION\n  └── extdata/\n        └── my_data.csv\n\n\nBinary (installed) form\nfile.txt\nCITATION\nextdata/\n  └── my_data.csv\n\n\n\nThe neat thing about the inst/ folder is that after we’ve loaded and installed our package, we can access the files in inst/extdata/ with the system.file() function:\nIf I want to test functions in duap using movies.RData (or another dataset), those should be placed in inst/extdata/\n\ninst/\nA great way to understand what files are available in inst/ when your package is to pass system.file() to fs::dir_tree():\n\nfs::dir_tree( # wrap this in a folder tree\n  system.file(package = \"duap\"))\n\n\n\nexpand to see inst/ folder contents\n/path/to/installed/package/duap\n├── DESCRIPTION\n├── INDEX\n├── LICENSE\n├── Meta\n│   ├── Rd.rds\n│   ├── data.rds\n│   ├── features.rds\n│   ├── hsearch.rds\n│   ├── links.rds\n│   ├── nsInfo.rds\n│   └── package.rds\n├── NAMESPACE\n├── R\n│   ├── duap\n│   ├── duap.rdb\n│   └── duap.rdx\n├── data\n│   ├── Rdata.rdb\n│   ├── Rdata.rds\n│   └── Rdata.rdx\n├── extdata\n│   └── movies.RData\n├── help\n│   ├── AnIndex\n│   ├── aliases.rds\n│   ├── duap.rdb\n│   ├── duap.rdx\n│   ├── figures\n│   └── paths.rds\n└── html\n    ├── 00Index.html\n    └── R.css\n\n\nThe system.file() function will show me the path to the locally installed version of the package (hence the /path/to/installed/package/ at the beginning of the path).\nThe inst/exdata/ folder comes in handy for adding example data, but it’s also useful for application development (more on that later).\n\n\n\n\n\n\nTipThe inst/ folder\n\n\n\n\nTake a look at the inst/extdata/ folder readr::readr_example() function to understand more about how this works.\n\n\n\n\nRecap: data and installed files\nR Packages have a consistent and standardized way of storing data, and have designated locations for internal and external data.\n\n\n\n\n\n\nFigure 11: Package data folders"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#documentation",
    "href": "series/shiny-frameworks/devtools/index.html#documentation",
    "title": "Creating a shiny app-package",
    "section": "Documentation",
    "text": "Documentation\nFunction documentation is handled with the R/ folder and roxygen2 comments/tags, but duap needs a README file, and a place for long-form documentation. Fortunately, RMarkdown handles each of these well:\n\nuse_readme_rmd()\nI can create a README file using usethis::use_readme_md() or usethis::use_readme_rmd()\n\nI prefer the .Rmd file because it comes with executable code chunks.\n\nusethis::use_readme_rmd()\n\n✔ Setting active project to '/Users/mjfrigaard/projects/duap'\n✔ Writing 'README.Rmd'\n✔ Adding '^README\\\\.Rmd$' to '.Rbuildignore'\n• Modify 'README.Rmd'\n• Update 'README.Rmd' to include installation instructions.\n✔ Writing '.git/hooks/pre-commit'\n\nWhen I knit README.Rmd, it automatically generates the README.md for the package.\n\n\n\n\nuse_vignette()\nFor long-form documentation I can use vignettes.\n\nVignettes can be created with usethis::use_vignette()\n\nusethis::use_vignette(\"duap\")\n\n✔ Adding 'knitr' to Suggests field in DESCRIPTION\n✔ Setting VignetteBuilder field in DESCRIPTION to 'knitr'\n✔ Adding 'inst/doc' to '.gitignore'\n✔ Creating 'vignettes/'\n✔ Adding '*.html', '*.R' to 'vignettes/.gitignore'\n✔ Adding 'rmarkdown' to Suggests field in DESCRIPTION\n✔ Writing 'vignettes/duap.Rmd'\n• Modify 'vignettes/duap.Rmd'\n\nVignettes are also written in RMarkdown and rendered whenever the package is built/installed.\nduap/\n    └── vignettes/\n            └── duap.Rmd\n\n1 directory, 1 file\nBy combining rmarkdown and knitr, R packages have a documentation framework that has the added benefit of being somewhat fool-proof: vignettes have to successfully render for the package to be installed.\n\n\n\n\n\n\nFigure 12: Package vignettes\n\n\n\n\n\n\n\n\n\nNoteVignette figures\n\n\n\n\n\n\nImages in vignettes are kept in man/figures/\nduap/\n  ├── vignettes/\n  │       └── duap.Rmd\n  └── man/\n      └── figures/\n          └── duap-img-1.png\n\n\n\n\n\n\nRecap: documentation\nThe vignettes folder will long-form documentation about how the application works, use cases, and features (and roxygen2 will document each function).\n\n\n\n\n\n\nFigure 13: Documentation in README and vignettes/"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#tests",
    "href": "series/shiny-frameworks/devtools/index.html#tests",
    "title": "Creating a shiny app-package",
    "section": "Tests",
    "text": "Tests\nTesting is an important part of any package, and apps tend to require additional tests (especially when they’re moving from ‘development’ into ‘production’ environments).\n\nuse_testthat()\nTo apply the testing framework provided by the testthat package. package, I’ll use usethis::use_testthat():\n\nusethis::use_testthat()\n\n✔ Adding 'testthat' to Suggests field in DESCRIPTION\n✔ Setting Config/testthat/edition field in DESCRIPTION to '3'\n✔ Creating 'tests/testthat/'\n✔ Writing 'tests/testthat.R'\n• Call `use_test()` to initialize a basic test file and open it for editing.\nThis creates a new tests/ folder, with a testthat/ sub-folder and script.\nduap/\n    └── tests/\n          ├── testthat/\n          └── testthat.R\n        \n2 directories, 1 file\n\nWriting tests\ntestthat is designed for unit tests (i.e., testing each functional ‘unit’ in the code), but for shiny apps, we need to think beyond standard unit testing. We need to confirm the functions work and return predictable results, but we also need to make sure they play well with each other (integration tests), and that the application can be deployed (system tests).\n\n\nRecap: testing\nTesting is well described in the shiny documentation and in Mastering Shiny. Generally speaking, unit tests are performed with testthat, and module testing can be done with shiny::testServer(). To test the full application (or a specific behavior) use the shinytest2 package.\n\n\n\n\n\n\nFigure 14: Testing framework from testthat"
  },
  {
    "objectID": "series/shiny-frameworks/devtools/index.html#recap",
    "href": "series/shiny-frameworks/devtools/index.html#recap",
    "title": "Creating a shiny app-package",
    "section": "Recap",
    "text": "Recap\nI’ve skipped over some important development steps covered in R packages (license, using Git/GitHub, code coverage, NEWS, etc.), and you should bookmark this text as you start developing shiny app-packages. Hopefully this post has demonstrated that by building shiny apps as R packages, a suite of developer tools are available in the RStudio IDE (and the application files and folders have a uniform structure).\nduap is a substantial improvement over a bare-bones shiny application. An app-package holds the code, data, and documentation and allows us to write and execute unit tests, document help files for our functions with roxygen2, and check installation with devtools::check() and devtools::install(). App-packages can also be converted to pkgdown sites (which make them even easier to share)."
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html",
    "href": "series/shiny-frameworks/leprechaun/index.html",
    "title": "leprechaun shiny app-packages",
    "section": "",
    "text": "ImportantALERT!\n\n\n\n\n\n\nThis post is currently under development. Thank you for your patience.\nThis post is another walk-through of a shiny application using the leprechaun framework. leprechaun apps are lightweight golem apps, “this means applications are leaner, and smaller; hence the name ‘leprechaun.’.” I’ll go through developing a leprechaun shiny app-package (and how it’s different from golem and regular (devtools) app-packages).\ninstall.packages(\"remotes\")\nremotes::install_github(\"devOpifex/leprechaun\")\nFor consistency, I’ll be using the application from the RStudio’s Building Web Applications with Shiny course. These materials are a great resource if you’re new to shiny–even if you’re aren’t, it’s still worth checking out–plus it’s free!"
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html#outline",
    "href": "series/shiny-frameworks/leprechaun/index.html#outline",
    "title": "leprechaun shiny app-packages",
    "section": "Outline",
    "text": "Outline\nThis series focuses on thee technical areas: Start, Build, and Use.\n\nStart covers the steps required to begin building a shiny app with the framework (from the console and IDE), and any additional packages or dependencies.\nBuild covers the development process, which includes writing and storing code, data, external resources (like CSS or JavaScript), testing, etc.\nUse shows how developers can launch their application using the given framework/package locally (i.e., within the RStudio (Posit) IDE), common workflow tips, and any aspects of the framework I found confusing while building the application."
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html#lap",
    "href": "series/shiny-frameworks/leprechaun/index.html#lap",
    "title": "leprechaun shiny app-packages",
    "section": "lap",
    "text": "lap\nleprechaun apps are built using the same methods as R packages (devtools and usethis), but are intended to be a ‘leaner and smaller’ version of golem. The GitHub repo with the lap shiny app-package is here.\n\n\n\n\n\n\nNoteWhat does ‘leaner and smaller’ mean?\n\n\n\n\n\n\nleprechaun doesn’t add itself as a dependency (i.e., no need to add leprechaun to the list of Imports in the DESCRIPTION or NAMESPACE). ‘the golem in the room’ on the package website is worth reading because it covers the differences between the two packages (and why you might choose one over the other)."
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html#start",
    "href": "series/shiny-frameworks/leprechaun/index.html#start",
    "title": "leprechaun shiny app-packages",
    "section": "Start",
    "text": "Start\n\n\nusethis::create_package(\"myLeprechaunApp\")\n\n\n\nClick Code to see output\n\n\n\n\nCode\n✔ Creating '../projects/myLeprechaunApp/'\n✔ Setting active project to '/Users/mjfrigaard/projects/myLeprechaunApp'\n✔ Creating 'R/'\n✔ Writing 'DESCRIPTION'\nPackage: myLeprechaunApp\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.0.0.9000\nAuthors@R (parsed):\n    * First Last &lt;first.last@example.com&gt; [aut, cre] (YOUR-ORCID-ID)\nDescription: What the package does (one paragraph).\nLicense: `use_mit_license()`, `use_gpl3_license()` or friends to\n    pick a license\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\n✔ Writing 'NAMESPACE'\n✔ Writing 'myLeprechaunApp.Rproj'\n✔ Adding '^myLeprechaunApp\\\\.Rproj$' to '.Rbuildignore'\n✔ Adding '.Rproj.user' to '.gitignore'\n✔ Adding '^\\\\.Rproj\\\\.user$' to '.Rbuildignore'\n✔ Opening '/Users/mjfrigaard/projects/myLeprechaunApp/' in new RStudio session\n✔ Setting active project to '&lt;no active project&gt;'\n\n\n\nWhen creating a new leprechaun package in the IDE, it’s identical to the R package setup.\n\n\n\n\n\n\nFigure 1: myLeprechaunApp\n\n\n\nAfter the new project opens, install and load the leprechaun package, then run leprechaun::scaffold():\n\n\ninstall.packages(\"leprechaun\")\nlibrary(leprechaun)\nleprechaun::scaffold()\n\n\n\nClick Code to see output\n\n\n\n\nCode\n── Scaffolding leprechaun app ─────────────────────────────────────────\n\n── Creating lock file ──\n\n✔ Creating .leprechaun\n\n── Adding dependencies ──\n\n✔ Adding 'shiny' to Imports in DESCRIPTION\n✔ Adding 'bslib' to Imports in DESCRIPTION\n✔ Adding 'htmltools' to Imports in DESCRIPTION\n✔ Adding 'pkgload' to Suggests in DESCRIPTION\n\n\n── Generating code ──\n\n✔ Creating R/ui.R\n✔ Creating R/assets.R\n✔ Creating R/run.R\n✔ Creating R/server.R\n✔ Creating R/leprechaun-utils.R\n✔ Creating R/_disable_autoload.R\n✔ Creating R/zzz.R\n✔ Creating R/input-handlers.R\n\n✔ Creating inst/dev\n✔ Creating inst/assets\n✔ Creating inst/img\n✔ Creating inst/run/app.R\n\n── Ignoring files ──\n\n✔ Adding '^\\\\.leprechaun$' to '.Rbuildignore'\n\n\n\nThis results in the following folder tree:\n\n\nmyLeprechaunApp/\n        ├── DESCRIPTION\n        ├── NAMESPACE\n        ├── R/\n        │   ├── _disable_autoload.R\n        │   ├── assets.R\n        │   ├── input-handlers.R\n        │   ├── leprechaun-utils.R\n        │   ├── run.R\n        │   ├── server.R\n        │   ├── ui.R\n        │   └── zzz.R\n        ├── inst/\n        │   ├── assets/\n        │   ├── dev/\n        │   ├── img/\n        │   └── run/\n        │       └── app.R\n        └── myLeprechaunApp.Rproj\n\n7 directories, 12 files\n\n\nThis structure should look familiar if you’ve been following along with this series. The standard R package files and folders (DESCRIPTION, NAMESPACE, R/, and myLeprechaunApp.Rproj) are accompanied by multiple sub-folders in inst/ (recall that inst/ contents are available in the package when the package is installed).\n\nSetup\nIn this section I’ll cover the initial files in the new leprechaun application.\n\nR/\n\nThe R/ folder contents are below:\n\nSome of these files should look familiar (R/ui.R, R/server.R, and R/run.R)\n\n\n\n        └── R/\n            ├── _disable_autoload.R\n            ├── assets.R\n            ├── input-handlers.R\n            ├── leprechaun-utils.R\n            ├── run.R\n            ├── server.R\n            ├── ui.R\n            └── zzz.R\n\n\nThe initial application files are created using leprechaun::scaffold(), which takes the following options as function arguments:\n\nui controls the application layout (can be \"fluidPage\" or \"navbarPage\", defaults to \"navbarPage\")\nbs_version Bootstrap version (“If shiny &gt; 1.6 is installed defaults to version 5, otherwise version 4” )\noverwrite: Overwrite all files?\n\n\nassets.R: contains the serveAssets() function, which will identify the modules using CSS or JavaScript and create dependencies, a list of metadata on the app. If you run the function after initially building your leprechaun app, you’ll see the following:\n\nClick on Code to view code in R/assets.R\n\n\n\n\nCode\n#' Dependencies\n#'\n#' @param modules JavaScript files names that require\n#' the `type = module`.\n#' @importFrom htmltools htmlDependency\n#'\n#' @keywords internal\nserveAssets &lt;- function(modules = NULL) {\n  # JavaScript files\n  javascript &lt;- list.files(\n    system.file(package = \"myLeprechaunApp\"),\n    recursive = TRUE,\n    pattern = \".js$\"\n  )\n\n  modules &lt;- get_modules(javascript, modules)\n  javascript &lt;- remove_modules(javascript, modules)\n\n  # CSS files\n  css &lt;- list.files(\n    system.file(package = \"myLeprechaunApp\"),\n    recursive = TRUE,\n    pattern = \".css$\"\n  )\n\n  # so dependency processes correctly\n  names(css) &lt;- rep(\"file\", length(css))\n  names(javascript) &lt;- rep(\"file\", length(javascript))\n\n  # serve dependencies\n  dependencies &lt;- list()\n\n  standard &lt;- htmlDependency(\n    \"myLeprechaunApp\",\n    version = utils::packageVersion(\"myLeprechaunApp\"),\n    package = \"myLeprechaunApp\",\n    src = \".\",\n    script = javascript,\n    stylesheet = css\n  )\n  dependencies &lt;- append(dependencies, list(standard))\n\n  if (!is.null(modules)) {\n    modules &lt;- htmlDependency(\n      \"myLeprechaunApp-modules\",\n      version = utils::packageVersion(\"myLeprechaunApp\"),\n      package = \"myLeprechaunApp\",\n      src = \".\",\n      script = modules,\n      meta = list(type = \"module\")\n    )\n    dependencies &lt;- append(dependencies, list(modules))\n  }\n\n  return(dependencies)\n}\n\n#' Module\n#'\n#' Retrieve and add modules from a vector of files.\n#'\n#' @param files JavaScript files\n#' @param modules JavaScript files names that require\n#' the `type = module`.\n#' @importFrom htmltools htmlDependency\n#'\n#' @keywords internal\n#' @name js-modules\nremove_modules &lt;- function(files, modules) {\n  if (is.null(modules)) {\n    return(files)\n  }\n\n  # make pattern\n  pattern &lt;- collapse_files(modules)\n\n  # remove modules\n  files[!grepl(pattern, files)]\n}\n\n#' @rdname js-modules\n#' @keywords internal\nget_modules &lt;- function(files, modules) {\n  if (is.null(modules)) {\n    return(NULL)\n  }\n\n  # make pattern\n  pattern &lt;- collapse_files(modules)\n\n  # remove modules\n  files[grepl(pattern, files)]\n}\n\n# collapse files into a pattern\ncollapse_files &lt;- function(files) {\n  pattern &lt;- paste0(files, collapse = \"$|\")\n  paste0(pattern, \"$\")\n}\n\n\n\n\n\nserveAssets()\n\n\n\nClick on Code to view the initial output from serveAssets()\n\n\n\n\nCode\n[[1]]\nList of 10\n $ name      : chr \"myLeprechaunApp\"\n $ version   : chr \"0.0.0.9000\"\n $ src       :List of 1\n  ..$ file: chr \".\"\n $ meta      : NULL\n $ script    : Named chr(0) \n  ..- attr(*, \"names\")= chr(0) \n $ stylesheet: Named chr(0) \n  ..- attr(*, \"names\")= chr(0) \n $ head      : NULL\n $ attachment: NULL\n $ package   : chr \"myLeprechaunApp\"\n $ all_files : logi TRUE\n - attr(*, \"class\")= chr \"html_dependency\"\n\n\n\n_disable_autoload.R is a way to disable the shiny::loadSupport() function. By default, shiny will load any top-level supporting .R files in the R/ directory adjacent to the app.R/server.R/ui.R files.\ninput-handlers.R:\n\nClick on Code to view code in R/input-handlers.R\n\n\n\n\nCode\n#' Input Dataframe\n#' \n#' Converts the input received from the WebSocket\n#' to a data.frame.\n#' \n#' @param data Input data received from WebSocket.\n#' \n#' @keywords internal\nleprechaun_handler_df &lt;- function(data){\n    do.call(\"rbind\", lapply(data))\n}\n\n#' Input List\n#' \n#' Forces the input received from the WebSocket \n#' to a list. This should really not be needed as\n#' it is handled like so by default.\n#' \n#' @param data Input data received from WebSocket.\n#' \n#' @keywords internal\nleprechaun_handler_list &lt;- function(data){\n    return(data)\n}\n\n.onAttach &lt;- function(...) {\n    shiny::registerInputHandler(\n        \"myLeprechaunApp.list\", \n        leprechaun_handler_list, \n        force = TRUE\n    )\n\n    shiny::registerInputHandler(\n        \"myLeprechaunApp.df\", \n        leprechaun_handler_df, \n        force = TRUE\n    )\n}\n\n\n\nleprechaun-utils.R initially contains the make_send_message() function (which is used in the R/server.R below).\n\nClick on Code to view code in R/leprechaun-utils.R\n\n\n\n\nCode\n#' Create a Helper to Send Messages\n#'\n#' Create a function to send custom messages to the front-end,\n#' this function makes it such that the namespace is carried\n#' along.\n#' The namespace is appended as `ns`.\n#' The namespace with the optional hyphen is\n#' included as `ns2`.\n#'\n#' @param session Shiny session to derive namespace\n#' @param prefix A prefix to add to all types.\n#' Note that the prefix is followed by a hyphen `-`.\n#'\n#' @examples\n#' \\dontrun{\n#' send_message &lt;- make_send_message(session)\n#' send_message(\"do-sth\")\n#' send_message(\"do-sth-else\", x = 1)\n#'\n#' # with prefix\n#' send_message &lt;- make_send_message(session, prefix = \"PREFIX\")\n#'\n#' # this sends a message of type:\n#' # PREFIX-so-th\n#' send_message(\"do-sth\")\n#' }\n#'\n#' @noRd\n#' @keywords internal\nmake_send_message &lt;- function(session, prefix = NULL) {\n  ns &lt;- session$ns(NULL)\n\n  ns2 &lt;- ns\n  if (length(ns) &gt; 0 && ns != \"\") {\n    ns2 &lt;- paste0(ns2, \"-\")\n  }\n\n  function(msgId, ...) {\n    if (!is.null(prefix)) {\n      msgId &lt;- sprintf(\"%s-%s\", prefix, msgId)\n    }\n\n    session$sendCustomMessage(\n      msgId,\n      list(\n        ns = ns,\n        ns2 = ns2,\n        ...\n      )\n    )\n  }\n}\n\n\n\nrun.R contains functions for running the production (run()) and development version of the application (run_dev()):\n\nClick on Code to view code in R/run.R\n\n\n\n\nCode\n#' Run\n#' \n#' Run application\n#' \n#' @param ... Additional parameters to pass to [shiny::shinyApp].\n#' \n#' @importFrom shiny shinyApp\n#' \n#' @export \nrun &lt;- function(...){\n    shinyApp(\n        ui = ui,\n        server = server,\n        ...\n    )\n}\n\n#' Run Development\n#' \n#' Runs the development version which includes\n#' the build step.\n#' \n#' @keywords internal\nrun_dev &lt;- function(){\n    file &lt;- system.file(\"run/app.R\", package = \"myLeprechaunApp\")\n    shiny::shinyAppFile(file)\n}\n\n\n\nserver.R by default creates send_message with make_send_message(session) (see R/leprechaun-utils.R above).\n\nClick on Code to view code in R/server.R\n\n\n\n\nCode\n#' Server\n#' \n#' Core server function.\n#' \n#' @param input,output Input and output list objects\n#' containing said registered inputs and outputs.\n#' @param session Shiny session.\n#' \n#' @noRd \n#' @keywords internal\nserver &lt;- function(input, output, session){\n    send_message &lt;- make_send_message(session)  \n}\n\n\n\nui.R holds the ui() and assets() functions. assets() loads the resources called in the R/assets.R file (see serveAssets() function above).\n\nClick on Code to view code in ui()\n\n\n\n\nCode\n#' Shiny UI\n#' \n#' Core UI of package.\n#' \n#' @param req The request object.\n#' \n#' @import shiny\n#' @importFrom bslib bs_theme\n#' \n#' @keywords internal\nui &lt;- function(req) {\n    fluidPage(\n        theme = bs_theme(version = 5),\n        assets(),\n        h1(\"myLeprechaunApp\")\n    )\n}\n\n\n\n\nClick on Code to view code in assets()\n\n\n\n\nCode\n#' Assets\n#' \n#' Includes all assets.\n#' This is a convenience function that wraps\n#' [serveAssets] and allows easily adding additional\n#' remote dependencies (e.g.: CDN) should there be any.\n#' \n#' @importFrom shiny tags\n#' \n#' @keywords internal\nassets &lt;- function() {\n    list(\n        serveAssets(), # base assets (assets.R)\n        tags$head(\n            # Place any additional depdendencies here\n            # e.g.: CDN\n        )   \n    )\n}\n\n\n\nzzz.R contains shiny’s addResourcePath() function for adding images to the application (in inst/img/)\n\nClick on Code to view code in R/zzz.R\n\n\n\n\nCode\n.onLoad &lt;- function(...){\n    shiny::addResourcePath(\n        \"img\",\n        system.file(\"img\", package = \"myLeprechaunApp\")\n    )\n}\n\n\n\n\n\n\ninst/run/app.R\n\napp.R contains a file that looks like it would be used to run the application, but it’s not. This file contains a call to leprechaun::build(), then pkgload::load_all().\n\nClick on Code to view code in inst/run/app.R\n\n\n\n\nCode\n# do not deploy from this file\n# see leprechaun::add_app_file()\nleprechaun::build()\n\npkgload::load_all(\n    path = \"../../\",\n    reset = TRUE,\n    helpers = FALSE\n)\n\nrun()\n\n\n\n\nThis file is not run directly (check leprechaun::add_app_file()):"
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html#build",
    "href": "series/shiny-frameworks/leprechaun/index.html#build",
    "title": "leprechaun shiny app-packages",
    "section": "Build",
    "text": "Build\nBuilding leprechaun apps is similar to golem/R packages. New code is placed in the R/ folder, and application resources (CSS, SASS, JavaScript files) are added using one of the leprechaun::use_* functions:\n\nuse_sass()\nuse_html_utils()\n\nuse_endpoints_utils()\nuse_js_utils()\n\nMore assets can be added using the leprechaun::use_packer() function.\n\nDevelop\nThe leprechaun::scaffold() defaults to a navbarPage(), but I’ll switch to a fluidPage() for this example.\nAfter devtools::load_all() and devtools::document(), restarting and loading the package, I can run the application with run().\n\n\n\n\n\n\nFigure 2: Initial run()\n\n\n\n\nadd_module()\nCreating modules is simple with leprechaun::add_module().\n\nThe initial UI module:\n\n\nleprechaun::add_module(\"var_input\")\n\n\n✔ Creating R/module_var_input.R\n\n\n\nSimilar to golem, this creates functions for the UI and server portions of the module.\n\n\n\n#' var_input UI\n#' \n#' @param id Unique id for module instance.\n#' \n#' @keywords internal\nvar_inputUI &lt;- function(id){\n    ns &lt;- NS(id)\n\n    tagList(\n        h2(\"var_input\"),\n\n    )\n}\n\n\n\nThe initial server module:\n\n\n\n#' var_input Server\n#' \n#' @param id Unique id for module instance.\n#' \n#' @keywords internal\nvar_input_server &lt;- function(id){\n    moduleServer(\n        id,\n        function(\n            input, \n            output, \n            session\n            ){\n\n                ns &lt;- session$ns\n                send_message &lt;- make_send_message(session)\n\n                # your code here\n        }\n    )\n}\n\n# UI\n# var_inputUI('id')\n\n# server\n# var_input_server('id')\n\n\n\nNote the send_message &lt;- make_send_message(session) in var_input_server(). I will show how this is used in the JavaScript section below.\n\n\n\n\n\n\n\n\nTipTip: @keywords internal\n\n\n\n\n\n\nThe module contents are similar to golem, but instead of using the @noRd tag, these functions include @keywords internal (which can be used to document your package).\n\nIn order to this, run usethis::use_package_doc() and a script will be created in R/ with the following contents:\n\n'_PACKAGE'\n\n## usethis namespace: start\n## usethis namespace: end\nNULL\n\n\n\n\n\nThe code for the var_input and plot_display modules are below.\n\nThe R/module_var_input.R file:\n\nClick on Code to view code in R/module_var_input.R\n\n\n\n\nCode\n#' var_input UI\n#'\n#' @param id Unique id for module instance.\n#'\n#' @keywords internal\n#'\n#' @return shiny UI module\n#' @export var_inputUI\n#'\n#' @description A shiny Module.\n#'\n#' @importFrom shiny NS tagList selectInput\n#' @importFrom shiny sliderInput textInput\nvar_inputUI &lt;- function(id){\n    ns &lt;- shiny::NS(id)\n    shiny::tagList(\n    shiny::selectInput(\n      inputId = ns(\"y\"),\n      label = \"Y-axis:\",\n      choices = c(\n        \"IMDB rating\" = \"imdb_rating\",\n        \"IMDB number of votes\" = \"imdb_num_votes\",\n        \"Critics Score\" = \"critics_score\",\n        \"Audience Score\" = \"audience_score\",\n        \"Runtime\" = \"runtime\"\n      ),\n      selected = \"audience_score\"\n    ),\n    shiny::selectInput(\n      inputId = ns(\"x\"),\n      label = \"X-axis:\",\n      choices = c(\n        \"IMDB rating\" = \"imdb_rating\",\n        \"IMDB number of votes\" = \"imdb_num_votes\",\n        \"Critics Score\" = \"critics_score\",\n        \"Audience Score\" = \"audience_score\",\n        \"Runtime\" = \"runtime\"\n      ),\n      selected = \"imdb_rating\"\n    ),\n    shiny::selectInput(\n      inputId = ns(\"z\"),\n      label = \"Color by:\",\n      choices = c(\n        \"Title Type\" = \"title_type\",\n        \"Genre\" = \"genre\",\n        \"MPAA Rating\" = \"mpaa_rating\",\n        \"Critics Rating\" = \"critics_rating\",\n        \"Audience Rating\" = \"audience_rating\"\n      ),\n      selected = \"mpaa_rating\"\n    ),\n    shiny::sliderInput(\n      inputId = ns(\"alpha\"),\n      label = \"Alpha:\",\n      min = 0, max = 1, step = 0.1,\n      value = 0.5\n    ),\n    shiny::sliderInput(\n      inputId = ns(\"size\"),\n      label = \"Size:\",\n      min = 0, max = 5,\n      value = 2\n    ),\n    shiny::textInput(\n      inputId = ns(\"plot_title\"),\n      label = \"Plot title\",\n      placeholder = \"Enter plot title\"\n    )\n    )\n}\n\n#' var_input Server\n#'\n#' @param id Unique id for module instance.\n#'\n#' @keywords internal\n#'\n#' @return shiny server module\n#' @export var_input_server\n#'\n#' @importFrom shiny NS moduleServer reactive\nvar_input_server &lt;- function(id){\n    moduleServer(\n        id,\n        function(\n            input,\n            output,\n            session\n            ){\n\n                ns &lt;- session$ns\n                send_message &lt;- make_send_message(session)\n\n                # your code here\n    return(\n      list(\n        \"x\" = shiny::reactive({\n          input$x\n        }),\n        \"y\" = shiny::reactive({\n          input$y\n        }),\n        \"z\" = shiny::reactive({\n          input$z\n        }),\n        \"alpha\" = shiny::reactive({\n          input$alpha\n        }),\n        \"size\" = shiny::reactive({\n          input$size\n        }),\n        \"plot_title\" = shiny::reactive({\n          input$plot_title\n        })\n        )\n      )\n        }\n    )\n}\n\n# UI\n# var_inputUI('id')\n\n# server\n# var_input_server('id')\n\n\n\nThe R/module_plot_display.R file:\n\nMy plot_dispay module collects the data from var_input and creates the plot with the custom point_plot() function:\n\n\nClick on Code to view code in R/module_plot_display.R\n\n\n\n\nCode\n#' plot_display UI\n#'\n#' @param id Unique id for module instance.\n#'\n#' @return shiny UI module\n#' @export plot_displayUI\n#'\n#' @description A shiny Module.\n#'\n#' @importFrom shiny NS tagList tags\n#' @importFrom shiny plotOutput\nplot_displayUI &lt;- function(id){\n    ns &lt;- shiny::NS(id)\n    shiny::tagList(\n    shiny::tags$br(),\n    shiny::tags$blockquote(\n      shiny::tags$em(\n        shiny::tags$h6(\n          \"The code for this application comes from the \",\n          shiny::tags$a(\"Building web applications with Shiny\",\n            href = \"https://rstudio-education.github.io/shiny-course/\"\n          ),\n          \"tutorial\"\n        )\n      )\n    ),\n    shiny::plotOutput(outputId = ns(\"scatterplot\"))\n    )\n}\n\n#' plot_display Server\n#'\n#' @param id Unique id for module instance.\n#'\n#' @keywords internal\nplot_display_server &lt;- function(id, var_input){\n    moduleServer(\n        id,\n        function(\n            input,\n            output,\n            session\n            ){\n\n                ns &lt;- session$ns\n                send_message &lt;- make_send_message(session)\n\n                # your code here\n    movies &lt;- myLeprechaunApp::movies\n\n    inputs &lt;- shiny::reactive({\n      plot_title &lt;- tools::toTitleCase(var_inputs$plot_title())\n      list(\n        x = var_inputs$x(),\n        y = var_inputs$y(),\n        z = var_inputs$z(),\n        alpha = var_inputs$alpha(),\n        size = var_inputs$size(),\n        plot_title = plot_title\n      )\n    })\n\n    output$scatterplot &lt;- shiny::renderPlot({\n      plot &lt;- point_plot(\n        df = movies,\n        x_var = inputs()$x,\n        y_var = inputs()$y,\n        col_var = inputs()$z,\n        alpha_var = inputs()$alpha,\n        size_var = inputs()$size\n      )\n      plot +\n        ggplot2::labs(\n          title = inputs()$plot_title,\n            x = stringr::str_replace_all(\n                  tools::toTitleCase(\n                      inputs()$x),\n                    \"_\",\n                  \" \"),\n            y = stringr::str_replace_all(\n                  tools::toTitleCase(\n                      inputs()$y),\n                  \"_\",\n                \" \")) +\n        ggplot2::theme_minimal() +\n        ggplot2::theme(legend.position = \"bottom\")\n    })\n        }\n    )\n}\n\n# UI\n# plot_displayUI('id')\n\n# server\n# plot_display_server('id')\n\n\n\n\nAfter creating the modules, adding them to the UI (R/ui.R) and server (R/server.R) is straightforward.\n\nThe R/ui.R file:\n\n\n\nCode\n#' Shiny UI\n#'\n#' Core UI of package.\n#'\n#' @param req The request object.\n#'\n#' @import shiny\n#' @importFrom bslib bs_theme\n#'\n#' @keywords internal\nui &lt;- function(req) {\n  fluidPage(\n    theme = bs_theme(version = 5),\n    assets(),\n    h1(\"myLeprechaunApp\"),\n    # Begin new code --&gt;\n    shiny::sidebarLayout(\n      shiny::sidebarPanel(\n        var_inputUI(\"vars\")\n      ),\n      shiny::mainPanel(\n        plot_displayUI(\"plot\")\n      )\n    )\n    ## End new code &lt;--\n  )\n}\n\n\n\nThe R/server.R file:\n\nThe server also has the make_send_message() function in it by default (more on that below).\n\n\nClick on Code to view code in R/server.R\n\n\n\n\nCode\n#' Server\n#'\n#' Core server function.\n#'\n#' @param input,output Input and output list objects\n#' containing said registered inputs and outputs.\n#' @param session Shiny session.\n#'\n#' @noRd\n#' @keywords internal\nserver &lt;- function(input, output, session){\n\n    send_message &lt;- make_send_message(session)\n\n  ## New code --&gt;\n   selected_vars &lt;- var_input_server(\"vars\")\n\n   plot_display_server(\"plot\", var_inputs = selected_vars)\n   ## New code &lt;--\n\n}\n\n\n\n\nThe other components of myLeprechaunApp were created using the standard usethis package development functions.\n\n\nuse_data_raw()\n\nthe movies data was added to inst/extdata and loaded into the package with usethis::use_data_raw()\n\n\n\n\n\n\n\nNoteAdding data to a package\n\n\n\n\n\n\nAfter calling usethis::use_data_raw('movies'), I can use system.file() to locate the file with the following code in data-raw/movies.R:\n## code to prepare `movies` dataset goes here\npth &lt;- system.file('extdata/movies.RData', package = 'myLeprechaunApp')\nload(pth)\nusethis::use_data(movies, overwrite = TRUE)\n\n\n\n\n\n\nuse_r()\n\nusethis::use_r() created R/utils_plot_display.R to hold the point_plot() function\n\nClick on Code to view code in R/utils_plot_display.R\n\n\n\n\nCode\n#' Plot points (shiny)\n#'\n#' @param df input dataset (tibble or data.frame)\n#' @param x_var x variable\n#' @param y_var y variable\n#' @param col_var color variable\n#' @param alpha_var alpha value\n#' @param size_var size value\n#'\n#' @return plot object\n#' @export point_plot\n#'\n#' @importFrom ggplot2 ggplot aes geom_point\n#'\n#' @examples\n#' \\donttest{\n#' load(\n#'   list.files(\n#'     system.file(\"extdata\", package = \"myLeprechaunApp\"),\n#'    pattern = \"movies\",\n#'    full.names = TRUE)\n#'    )\n#' point_plot(df = movies,\n#'   x_var = \"critics_score\",\n#'   y_var = \"imdb_rating\",\n#'   col_var = \"critics_rating\",\n#'   alpha_var = 1/3,\n#'   size_var = 2)\n#' }\npoint_plot &lt;- function(df, x_var, y_var, col_var, alpha_var, size_var) {\n    ggplot2::ggplot(data = df,\n      ggplot2::aes(x = .data[[x_var]],\n          y = .data[[y_var]],\n          color = .data[[col_var]])) +\n      ggplot2::geom_point(alpha = alpha_var, size = size_var)\n\n}\n\n\n\n\nNow I can run devtools::load_all(), devtools::document(), restart and load the package, then run()\n\n\n\n\n\n\nFigure 3: run myLeprechaunApp\n\n\n\n\n\ninst/\nleprechaun uses the inst/ folder similar to the golem framework, but instead of only loading the files in inst/app/www, leprechaun apps include four sub-folders that are ready at application runtime.\n\npacker\nTo demonstrate how the make_send_message() function works, I’ll walk through the JavaScript example from the package website.\n\nRun packer::scaffold_leprechaun()\n\n\npacker::scaffold_leprechaun()\n\n\n\nClick on Code to view the output from packer::scaffold_leprechaun()\n\n\n\n── Scaffolding leprechaun ──────────────────────────────────────────────\n✔ Initialiased npm\n✔ webpack, webpack-cli, webpack-merge installed with scope \"dev\" \n✔ Added npm scripts\n✔ Created srcjs directory\n✔ Created srcjs/config directory\n✔ Created webpack config files\n\n── Adding files to .gitignore and .Rbuildignore ──\n\n✔ Setting active project to '/Users/mjfrigaard/projects/myLeprechaunApp'\n✔ Adding '^srcjs$' to '.Rbuildignore'\n✔ Adding '^node_modules$' to '.Rbuildignore'\n✔ Adding '^package\\\\.json$' to '.Rbuildignore'\n✔ Adding '^package-lock\\\\.json$' to '.Rbuildignore'\n✔ Adding '^webpack\\\\.dev\\\\.js$' to '.Rbuildignore'\n✔ Adding '^webpack\\\\.prod\\\\.js$' to '.Rbuildignore'\n✔ Adding '^webpack\\\\.common\\\\.js$' to '.Rbuildignore'\n✔ Adding 'node_modules' to '.gitignore'\n\n── Scaffold built ──\n\nℹ Run `bundle` to build the JavaScript files\nℹ Run `leprechaun::use_packer()`\n\n\nRun leprechaun::use_packer()\n\n\nleprechaun::use_packer()\n\n\n\n\n✔ Creating inst/dev/packer.R\n✔ Adding 'packer' to Suggests in DESCRIPTION\n! This requires `leprechaun::build()` or the `leprechaun::build_roclet`\n\n\nRun leprechaun::build()\n\n\nleprechaun::build()\n\n\n\n\n✔ Running packer.R\n✔ Bundled   \n\n\n\nNow I can see what new files have been added to the package/app.\n\nIn the inst/dev/ folder:\n\nI can see the packer.R file has been added\n\n\n\ninst/dev/\n      └── packer.R\n\n1 directory, 1 file\n\n\n\nClick on Code to view the output from packer.R\n\n\n\n\nCode\n#' Bundle for Prod\n#' \n#' Bundles packer using packer.\npacker_bundle &lt;- function(){\n    has_packer &lt;- requireNamespace(\"packer\", quietly = TRUE)\n\n    if(!has_packer){\n        warning(\n            \"Requires `packer` package: `install.packages('packer')`\\n\", \n            \"Skipping.\",\n            call. = FALSE\n        )\n        return()\n    }\n\n    packer::bundle()\n}\n\npacker_bundle()\n\n\n\nIn the srcjs/ folder:\n\nI can see how modules/message.js and index.js create the alert with Shiny.addCustomMessageHandler\n\n\n\nsrcjs/\n    ├── config\n    │   ├── entry_points.json\n    │   ├── externals.json\n    │   ├── loaders.json\n    │   ├── misc.json\n    │   └── output_path.json\n    ├── index.js\n    └── modules\n        └── message.js\n\n\n\nThe JavaScript in modules/message.js and index.js\n\n\n// srcjs/modules/message.js\nexport const message = (msg) =&gt; {\n  alert(msg);\n}\n// srcjs/index.js\nimport { message } from './modules/message.js';\nimport 'shiny';\n\n// In shiny server use:\n// session$sendCustomMessage('show-packer', 'hello packer!')\nShiny.addCustomMessageHandler('show-packer', (msg) =&gt; {\n  message(msg.text);\n})\n\n\nTo use the JS message scripts in srcjs/, I add the following to R/server.R:\n\nIn R/server.R\n\n\n    send_message &lt;- make_send_message(session)\n    send_message(\"show-packer\",\n                  text = \"this is a message from your server()\")\n\n\n\nAfter running devtools::load_all() and devtools::document(), the application loads with an alert:\n\n\n\n\n\n\nFigure 4: send_message()\n\n\n\nI can also include messages from modules.\n\nIn R/module_plot_display.R\n\n\n        send_message &lt;- make_send_message(session)\n        send_message(\"show-packer\",\n          text = \"this is a message from your plot_display module\")\n\n\n\n\n\n\n\n\n\nFigure 5: send_message() (module)\n\n\n\nRead more about sending JavaScript messages here on the shiny website.\n\n\nimg/\nI’ll demonstrate how to use the inst/ folder by adding an image to the application.\n\nAssume I want to add leprechaun.jpg to my UI. I start by adding the file to inst/img/:\n\n\ninst/\n  └── img/\n       └── leprechaun.jpg &lt;- new image file!\n\n\nThen I add the img/ path to the code to UI:\n\n\nui &lt;- function(req) {\n  fluidPage(\n    theme = bs_theme(version = 5),\n    assets(),\n    h1(\"myLeprechaunApp\"),\n    shiny::sidebarLayout(\n      shiny::sidebarPanel(\n        var_inputUI(\"vars\")\n      ),\n      shiny::mainPanel(\n        # new image\n        shiny::tags$img(src = \"img/leprechaun.jpg\"),\n        plot_displayUI(\"plot\")\n      )\n    )\n  )\n}\n\n\n\nOnce again, run devtools::load_all() and devtools::document(), restarting and loading the package, then run the application with run()\n\n\n\n\n\n\nFigure 6: Adding images to inst/img/\n\n\n\n\n\nSass\nleprechaun also has helper functions for adding additional resources (or assets) to an application. I’ll work through the SASS example from the website below.\nTo add a Sass file, I can use leprechaun’s use_sass() function.\n\nRun leprechaun::use_sass() (no arguments):\n\n\nleprechaun::use_sass()\n\n\n\nThis will add files to assets/ and dev/ and I see the following messages:\n\n\n\n✔ Creating scss\n✔ Creating inst/dev/sass.R\n✔ Adding 'sass' to Suggests in DESCRIPTION\n✔ Adding '^scss$' to '.Rbuildignore'\n! This requires `leprechaun::build()` or the `leprechaun::build_roclet`\n\n\n\nBelow are the new files in inst/dev/ and sass/:\n\n\n\ninst/\n    ├── scss/\n    │   ├── _core.scss\n    │   └── main.scss\n    └── dev/\n        └── sass.R\n\n\n\nThe scss/ folder is created by leprechaun::use_sass(), and it includes _core.scss and main.scss.\n\n_core.scss: the original file is below\n\n\nhtml{\n    .error {\n        color: red\n    }\n}\n\n\nI will change the color: from red to green (#38B44A) using $accent: #38B44A;\n\n\n$accent: #38B44A;\n\nhtml{\n    h1 {\n        color: $accent;\n    }\n}\n\n\nThen save this file and run leprechaun::build()\n\n\nleprechaun::build()\n\n\n✔ Running packer.R\n✔ Bundled       \n✔ Running sass.R\n\n\n\n\n\ndev/\n\nThe inst/dev/sass.R file contains a sass_build() function\n\nsass_build() looks in the scss/ folder for main.scss and creates the inst/assets/style.min.css file.\n\n\nClick on Code to view code in inst/dev/sass.R\n\n\n\n\nCode\n#' Build CSS\n#'\n#' Build the sass\nsass_build &lt;- function() {\n  has_sass &lt;- requireNamespace(\"sass\", quietly = TRUE)\n\n  if (!has_sass) {\n    warning(\n      \"Requires `sass` package: `install.packages('sass')`\\n\",\n      \"Skipping.\",\n      call. = FALSE\n    )\n    return()\n  }\n\n  output &lt;- sass::sass(\n    sass::sass_file(\n      \"scss/main.scss\"\n    ),\n    cache = NULL,\n    options = sass::sass_options(\n      output_style = \"compressed\"\n    ),\n    output = \"inst/assets/style.min.css\"\n  )\n  invisible(output)\n}\n\nsass_build()\n\n\n\n\nOnce again, I run devtools::load_all(), devtools::document(), install and restart, then load the package and run()\n\n\n\n\n\n\nFigure 7: run myLeprechaunApp with new Sass\n\n\n\n\n\n\n\n\nassets/\nHow does leprechaun::build() work?\nThe assets/ folder contains the files generated by the .R scripts in the dev/ folder.\n\nThe contents of the inst/dev/ folder:\n\n\ninst/dev/\n      ├── packer.R\n      └── sass.R\n\n1 directory, 2 files\n\n\nThe contents of the inst/assets/ folder:\n\n\ninst/assets/\n        ├── index.js\n        └── style.min.css\n\n1 directory, 2 files\n\n\ninst/dev/sass.R creates inst/assets/style.min.css and inst/dev/packer.R creates inst/assets/index.js\n\n\n“Do not call this function from within the app. It helps build things, not run them.” - build.md guide\n\n\n\ncheck serveAssets()\nAfter running leprechaun::use_sass() and leprechaun::build() (which adds the scss/ folder and the .R script in inst/dev/), I can re-check the serveAssets() function:\n\n\nserveAssets()\n\n\n[[1]]\nList of 10\n $ name      : chr \"myLeprechaunApp\"\n $ version   : chr \"0.0.0.9000\"\n $ src       :List of 1\n  ..$ file: chr \".\"\n $ meta      : NULL\n $ script    : Named chr \"assets/index.js\"\n  ..- attr(*, \"names\")= chr \"file\"\n $ stylesheet: Named chr [1:2] \"assets/style.min.css\" \"html/R.css\"\n  ..- attr(*, \"names\")= chr [1:2] \"file\" \"file\"\n $ head      : NULL\n $ attachment: NULL\n $ package   : chr \"myLeprechaunApp\"\n $ all_files : logi TRUE\n - attr(*, \"class\")= chr \"html_dependency\"\n\n\nThis shows me stylesheet has been updated with \"assets/style.min.css\" and script has been updated with \"assets/index.js\" (these files are loaded into the application when it runs)."
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html#use",
    "href": "series/shiny-frameworks/leprechaun/index.html#use",
    "title": "leprechaun shiny app-packages",
    "section": "Use",
    "text": "Use\nRunning leprechaun apps:\nWhen I initially create a new leprechaun package with leprechaun::scaffold(), I can run the application after a few quick steps:\n\ndevtools::load_all()\ndevtools::document()\nInstall and restart (optional)\nrun()\n\n\n\ndevtools::load_all()\ndevtools::document()\n# install and restart\nlibrary(myLeprechaunApp)\nrun()\n\n\n\n\n\n\n\n\nFigure 8: run myLeprechaunApp\n\n\n\n\n\n\n\n\n\nNoteApp package scripts\n\n\n\n\n\n\nThe output above shows that–unlike golem apps–leprechaun includes the functions in the R/ folder as part of the myLeprechaunApp package.\n\n\n\n\nApp files:\n\nR/: After the initial setup, the R/ folder of a leprechaun app contains standard ui.R, server.R files, as well as the run.R function for running the app.\n\n\nmyLeprechaunApp/\n      └── R/\n          ├── _disable_autoload.R\n          ├── assets.R\n          ├── input-handlers.R\n          ├── leprechaun-utils.R\n          ├── run.R\n          ├── server.R\n          ├── ui.R\n          └── zzz.R\n\n      1 directory, 8 files\n\n\n\nThe additional files are specific to the leprechaun framework and workflow.\n\n\nConfigure:\nleprechaun app configuration files use the config package (similar to golem). Unlike the golem package, it’s not assumed I’ll be using a config.yml file, but I can easily add one with leprechaun::use_config().\n\nuse_config() adds a inst/config.yml and R/config.R\nThe default value in the config.yml files is production: true, which can be read using config_read() in R/config.R.\n\n\nconfig_read()\n\n\n$production\n[1] TRUE\n\n\n\nValues can be added to inst/config.yml using the config file format, then the CONFIG_FILE can be set as an environment variable\n\n\nWorkflow:\n\nThe inst/ folder contains various sub-folders for including external app resources (images, SASS, CSS, JavaScript, etc.).\n\n\nmyLeprechaunApp/\n    └── inst/\n          ├── assets/\n          ├── dev/\n          ├── img/\n          └── run/\n              └── app.R\n\n      5 directories, 1 file\n\n\nleprechaun apps are packages, so the inst/ folders are available to the application at runtime (which I can find using system.file()).\n\nBelow I’ve passed the output from system.file(\".\", package = \"myLeprechaunApp\") to fs::dir_tree() to view it’s contents:\n\n\n\n\nCode\n├── DESCRIPTION\n├── INDEX\n├── Meta/\n│   ├── Rd.rds\n│   ├── data.rds\n│   ├── features.rds\n│   ├── hsearch.rds\n│   ├── links.rds\n│   ├── nsInfo.rds\n│   └── package.rds\n├── NAMESPACE\n├── R/\n│   ├── myLeprechaunApp\n│   ├── myLeprechaunApp.rdb\n│   └── myLeprechaunApp.rdx\n├── assets/\n│   ├── index.js\n│   └── style.min.css\n├── data/\n│   ├── Rdata.rdb\n│   ├── Rdata.rds\n│   └── Rdata.rdx\n├── dev/\n│   ├── packer.R\n│   └── sass.R\n├── extdata/\n│   └── movies.RData\n├── help/\n│   ├── AnIndex\n│   ├── aliases.rds\n│   ├── myLeprechaunApp.rdb\n│   ├── myLeprechaunApp.rdx\n│   └── paths.rds\n├── html/\n│   ├── 00Index.html\n│   └── R.css\n├── img/\n│   └── leprechaun.jpg\n└── run/\n    └── app.R\n\n\n\n\nI can see the inst/ folders and files I’ve created are available to myLeprechaunApp at runtime:\n\n\n\n\nCode\n├── DESCRIPTION\n├── NAMESPACE\n├── assets/\n│   ├── index.js\n│   └── style.min.css\n├── dev/\n│   ├── packer.R\n│   └── sass.R\n├── extdata/ \n│   └── movies.RData\n└── img/\n      └── leprechaun.jpg"
  },
  {
    "objectID": "series/shiny-frameworks/leprechaun/index.html#recap",
    "href": "series/shiny-frameworks/leprechaun/index.html#recap",
    "title": "leprechaun shiny app-packages",
    "section": "Recap",
    "text": "Recap\nleprechaun delivers on its promise to be a ‘leaner and smaller’ version of golem. Most of the features in golem are also accessible in leprechaun. Including multiple inst/ sub-folders makes adding assets to the application easier, and leprechaun has a long list of use_* functions for including Sass, CSS, HTML, and JavaScript. The package website has examples for getting started and adding multiple resources, but unfortunately the function Reference had limited documentation.\nleprechaun doesn’t come with any testing functions, although this can be done using testthat and shinytest2 (just as we would with a standard R package).\nFor the next (and last) post in this series, I will build a shiny application using the rhino package."
  },
  {
    "objectID": "posts/box/index.html",
    "href": "posts/box/index.html",
    "title": "Writing modular code with box",
    "section": "",
    "text": "box provides a precise and concise method for using add-on packages and functions. box also doesn’t require bundling your code into R packages to make it reusable. This post covers tackling some common workflow steps to demonstrate how box modules work."
  },
  {
    "objectID": "posts/box/index.html#what-is-box",
    "href": "posts/box/index.html#what-is-box",
    "title": "Writing modular code with box",
    "section": "",
    "text": "box provides a precise and concise method for using add-on packages and functions. box also doesn’t require bundling your code into R packages to make it reusable. This post covers tackling some common workflow steps to demonstrate how box modules work."
  },
  {
    "objectID": "posts/box/index.html#packages-functions-and-namespaces",
    "href": "posts/box/index.html#packages-functions-and-namespaces",
    "title": "Writing modular code with box",
    "section": "Packages, functions, and namespaces",
    "text": "Packages, functions, and namespaces\nTo understand the problem box solves, we’ll review the typical process for using add-on package functions in a standard R sesson and when developing R packages:\n\nR sessions\n\nAssume I want to use the glue() function from the glue package. The first step is to install it with install.packages(\"glue\")\n\nI’ll use the example from the glue package website:\n\n\n\nshow/hide\ninstall.packages(\"glue\")\n# \n# The downloaded binary packages are in\n#   /var/folders/0x/x5wkbhmx0k74tncn9swz7xpr0000gn/T//Rtmp2id54K/downloaded_packages\n\n\n\n\nTo use the functions from glue, I’ll need to run library(glue) in the same R session.\n\nIf I try to use a function from a package but it hasn’t been attached with library or require, I see the following:\n\n\n\nshow/hide\nname &lt;- \"Fred\"\nglue('My name is {name}.')\n# Error in glue(\"My name is {name}.\"): could not find function \"glue\"\n\n\n\nThe error above can be confusing, because it doesn’t tell us if the package hasn’t been installed, or if the package hasn’t been attached.\nHowever, after installing glue, I can get around using library by explicitly calling the function from the package namespace (i.e., pkg::foo()):\n\n\n\nshow/hide\nname &lt;- \"Fred\"\nglue::glue('My name is {name}.')\n# My name is Fred.\n\n\n\nWhile this method works, it doesn’t attach the package to the search list (which I check with search())\n\n\n\nshow/hide\nbase::search()\n# [1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\" \n# [4] \"package:grDevices\" \"package:utils\"     \"package:datasets\" \n# [7] \"package:methods\"   \"Autoloads\"         \"package:base\"\n\n\n\nlibrary() attaches the glue package in the search list and makes the glue() function available to use (without the package:: prefix)\n\n\n\nshow/hide\nlibrary(glue)\nbase::search()\n#  [1] \".GlobalEnv\"        \"package:glue\"      \"package:stats\"    \n#  [4] \"package:graphics\"  \"package:grDevices\" \"package:utils\"    \n#  [7] \"package:datasets\"  \"package:methods\"   \"Autoloads\"        \n# [10] \"package:base\"\n\n\n\nUnfortunately, library() also attaches all the objects from the glue package to the search() list, even though I’m only using a single function.\n\n\nRead more about namespaces in Advanced R and R packages.\n\n\nR packages\nIf I want to make the code I write using glue reusable, I can bundle it into an R package. Including glue as an add-on package (i.e., packages not loaded automatically with R) is done with the NAMESPACE file (created and edited via roxygen2 tags), and by listing these packages under Imports in the DESCRIPTION file.\n\nIn R/ files:\nAll .R files in R packages are placed in the R/ folder. If these files use add-on packages (i.e., library() or package::fun()), I include the @import or @importFrom tag. If I’d like to include and make my_name() available to users, I use the @export tag:\n\nI’ve converted the use of glue() into a small function below:\n\nmy_name() is saved as R/my_name.R:\n\n\n\nshow/hide\nmy_name &lt;- function(x) {\n  name &lt;- x\n  glue::glue('My name is {name}.')\n}\nmy_name(\"Fred\")\n# My name is Fred.\n\n\n\nBelow is a default roxygen2 skeleton:\n\n\n\nshow/hide\n#' Introduce yourself \n#'\n#' @param x a name \n#'\n#' @return An glued introduction to R\n#' @export my_name\n#'\n#' @examples\n#' my_name(\"Fred\")\nmy_name &lt;- function(x) {\n  name &lt;- x\n  glue::glue('My name is {name}.')\n}\n\n\n\n\n\nAs we can see, the default roxygen2 skeleton doesn’t include @import or @importFrom. The general advice is to prefer @importFrom over @import, because @import imports the entire package namespace (only use this in ‘very special situations’ such as ‘heavy use’ of a package functions).\n\nBelow is an example of using @importFrom:\n\n\n\nshow/hide\n#' Introduce yourself \n#'\n#' @param x a name \n#'\n#' @return An glued introduction to R\n#' @export my_name\n#'\n#' @examples\n#' my_name(\"Fred\")\n#'\n#' @importFrom glue glue\nmy_name &lt;- function(x) {\n  name &lt;- x\n  glue::glue('My name is {name}.')\n}\n\n\n\n\n\n\nNAMESPACE\nWhile developing my R package, I’ll run devtools::load_all() and devtools::document() frequently, and each time the imported functions are available in the current session and the tags are converted into directives in the NAMESPACE file\nimport(package)\nimportFrom(package,function) \n\n\nDESCRIPTION\nA package DESCRIPTION file is managed completely independent of it’s NAMESPACE file. This can be confusing during package development, because it’s easy to assume some kind of connection between the roxygen2 tags, the NAMESPACE file, and the DESCRIPTION file:\n\nHowever, this is not the case:\n\nTo include glue in the DESCRIPTION under Imports, I also need to use usethis::use_package(\"glue\")\nAs noted in R packages, “The Imports field [in the DESCRIPTION file] makes sure that the packages listed there are installed when your package is installed.” The DESCRIPTION file does not make functions available to the package developer (or the user).\n\n\nThe recommended practices for add-on packages are 1) use the namespace-qualified calls in the R/ scripts (i.e., package::function() with an accompanying @importFrom package function tag), and 2) list these packages in the DESCRIPTION file under Imports or Suggests to make sure a package is installed whenever your package is installed (i.e., with usethis::use_package(\"package\"))\nThe table below shows the connection between roxygen2 tags, the resulting NAMESPACE entry, and what should be listed in the DESCRIPTION (this is also covered in R packages)\n\n\n\n\n\n\n\n\nNoteRefresher on roxygen2, NAMESPACE & DESCRPTION\n\n\n\n\n\n\n\n\n\n\nroxygen2 tag\n\n\nNAMESPACE directive\n\n\nDESCRIPTION\n\n\n\n\n\n\n@importFrom\n\n\nimportFrom() : import selected object from another namespace\n\n\nConsider listing under ‘Suggests’\n\n\n\n\n@import\n\n\nimport(): import all objects from another package’s namespace\n\n\nList under ‘Imports’\n\n\n\n\n@export\n\n\nexport() : export the function, method, generic, or class so it’s available outside of the package (in the namespace)\n\n\nNothing to list"
  },
  {
    "objectID": "posts/box/index.html#how-box-is-different",
    "href": "posts/box/index.html#how-box-is-different",
    "title": "Writing modular code with box",
    "section": "How box is different",
    "text": "How box is different\nbox doesn’t require installing or attaching add-on packages. Instead, it uses modules to make package functions available. I’ll demonstrate with a simplified example using the glue() package. Assume I have a project folder pkg/,\n\n\n\nshow/hide\npkg/\n  └── pkg.Rproj\n\n1 directory, 1 file\n\n\n\n\nProjects in RStudio have a hidden folder, .Rproj.user/:\n\nThe the following contents are automatically created with a new .Rproj file:\n\n\n\ncontents of .Rproj\npkg/\n  ├── .Rproj.user\n  │      ├── 8CC5F70E\n  │      │      ├── bibliography-index\n  │      │      ├── ctx\n  │      │      ├── explorer-cache\n  │      │      ├── presentation\n  │      │      ├── profiles-cache\n  │      │      ├── sources\n  │      │      │      └── session-16ca0811\n  │      │      │          └── lock_file\n  │      │      ├── tutorial\n  │      │      └── viewer-cache\n  │      └── shared\n  │          └── notebooks\n  │              └── patch-chunk-names\n  └── pkg.Rproj\n\n14 directories, 3 files\n\n\n\nNone of these contents deal with installing or loading packages, but I’ve included it here for full transparency\n\n\n\nCreate a box module\nI’ll put the modules in a box/fun.R file, which I’ll create from the command-line:\n\n\n\nshow/hide\nmkdir box \ntouch box/fun.R\n\n\n\nNow my pkg folder looks like this:\n\n\n\nshow/hide\npkg/\n  ├── box\n  │    └── fun.R\n  ├── pkg.Rproj\n  └── use.R\n\n2 directories, 3 files\n\n\n\nIn pkg/box/fun.R I’ll add the following:\n\na brief comment with the path to the module\nthe @export tag from roxygen2\na call to box::use(glue[glue])\n\n\n\n\nshow/hide\n# box/fun.R\n#' @export\nbox::use(\n  glue[glue]\n  )\n\n\n\nIn the parent folder, create another file named use.R.\nIn use.R, use the fun module by calling box::use(box/fun)\n\n\n\nshow/hide\nbox::use(box/fun)\n\n\n\nView fun by printing it to the console:\n\n\n\nshow/hide\n# print\nfun\n\n\n\n\nshow/hide\n&lt;module: box/fun&gt;\n\n\n\nThis confirms the module has been created.\n\n\nUsing modules\nThe glue function is available from fun using the $ (like a column in a data.frame or tibble)\n\n\n\nshow/hide\n# use \nx &lt;- \"module\"\nfun$glue('This is a box {x}.')\n\n\n\n\nshow/hide\nThis is a box module.\n\n\n\nbox modules are combinations of named folders and files, but unlike R packages, these folders and files can be nested. The folder/file structure is used for separating modules, the same way we might separate files in a project (i.e., project/data/file.csv and project/code/analysis.R)\n\nbox makes the function and package namespacing explicit by using box::use(package[fun])\nbox also simplifies using module by calling the same function when building/using modules box::use(folder/file):\n\n\n# CREATE MODULE\n# box/fun.R\n#' @export\nbox::use(\n  glue[glue]\n  )\n\n\n# USE MODULE\nbox::use(box/fun)\n\nBelow is a slightly more involved example:"
  },
  {
    "objectID": "posts/box/index.html#module-workflow",
    "href": "posts/box/index.html#module-workflow",
    "title": "Writing modular code with box",
    "section": "Module workflow",
    "text": "Module workflow\nBelow I’m going to create a module that imports, wrangles, and visualizes data from the palmerpenguins package. (which is installed, but not loaded).\n\nbox/import\nThis workflow starts with an import module in a pengbox project. The code below is stored in pengbox/box/import.R:\n\n\n\nimport module\n# box/import.R\nbox::use(\n  readr[read_csv],\n)\n#' @export\nget_raw_csv &lt;- function() {\n  raw_csv_url &lt;- \"https://bit.ly/3SQJ6E3\"\n  read_csv(raw_csv_url)\n}\n\n\n\nIn a the master pengbox/run.R file, I’ll use import like so:\n\n\n\nshow/hide\n# import\nbox::use(box/import)\nstr(import$get_raw_csv(), give.attr = FALSE)\n\n\n\n\n\n\nshow/hide\nspc_tbl_ [344 × 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA ...\n\n\n\nI’ll re-write this module in box/import.R using an alias for readrs read_csv() function (rcsv) and include the readr::cols() function to remove the lengthy message.\nThis code is stored in the box/import.R file:\n\n\n\nimport module with alias\n# box/import.R\nbox::use(\n  readr[rcsv = read_csv, cols]\n)\n#' @export\nraw &lt;- function() {\n  raw_csv_url &lt;- \"https://bit.ly/3SQJ6E3\"\n  # use alias for read_csv()\n  rcsv(raw_csv_url, col_types = cols())\n}\n\n\n\nUsing import with the new module is more concise:\n\n\n\nshow/hide\n# import\nbox::use(box/import)\nstr(import$raw(), give.attr = FALSE)\n\n\n\n\n\n\nshow/hide\nspc_tbl_ [344 × 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA ...\n\n\n\n\n\nbox/prep\nAfter importing the raw penguins data, I’ll write a module for wrangling the data (that also imports the import module).\nThis module takes the following steps:\n\nReset the box.path\n\nImport the box/import module\n\nLoad all the functions from dplyr using [...]\n\nLoad aliases for stringr::str_extract() and janitor::clean_names()\n\nCompose prep() with the wrangling steps\n\n\n\n\nprep module with import\n# box/prep.R\n\n# reset the path\noptions(box.path = getwd())\n\n# import alias import module\nbox::use(box/import)\n\n# wrangle packages, functions, and aliases\nbox::use(\n  dplyr[...],\n  stringr[str_ext = str_extract],\n  janitor[fix_cols = clean_names]\n)\n\n#' @export\nprep = function() {\n  raw &lt;- import$raw()\n  clean_cols &lt;- fix_cols(raw)\n  vars &lt;- select(clean_cols, \n    species, \n    island, \n    bill_length_mm = culmen_length_mm,\n    bill_depth_mm = culmen_depth_mm,\n    flipper_length_mm,\n    body_mass_g,\n    sex)\n  mutate(vars, \n    species = str_ext(species, \"([[:alpha:]]+)\"),\n    sex = factor(sex))\n}\n\n\n\nWe can now the prep module to access the import module for the wrangled dataset.\n\n\n# prepare\nbox::use(box/prep)\npeng_clean &lt;- prep$prep()\nstr(peng_clean, give.attr = FALSE)\n\n\n\n\ntibble [344 × 7] (S3: tbl_df/tbl/data.frame)\n $ species          : chr [1:344] \"Adelie\" \"Adelie\" \"Adelie\" \"Adelie\" ...\n $ island           : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ sex              : Factor w/ 2 levels \"FEMALE\",\"MALE\": 2 1 1 NA 1 2 1 2 NA NA ...\n\n\nThese data look like they’re ready for graphing! Time to write another module…\n\n\nbox/plot\nI will build my visualization with ggplot2 (in the box/plot.R module) and dplyr::filter():\n\n\n\nplot module with prep\n# pengbox/plot.R\n\n# reset the path\noptions(box.path = getwd())\n\n# import prep module\nbox::use(box/prep)\n\n# import ggplot2\nbox::use(\n  dplyr[filter],\n  ggplot2 = ggplot2[ggplot, aes, geom_point, \n                    facet_wrap, labs, theme_minimal])\n\n#' @export\nscatter &lt;- function() {\n  prepped &lt;- prep$prep()\n  # remove missing sex\n  filtered &lt;- filter(prepped, !is.na(sex)) \n    # plot filtered data\n  plotted &lt;- ggplot2$ggplot(data = filtered, \n    ggplot2$aes(\n      x = flipper_length_mm,\n      y = body_mass_g,\n      group = sex\n    )\n  ) +\n    ggplot2$geom_point(\n      ggplot2$aes(color = island)\n    ) +\n    ggplot2$facet_wrap(. ~ sex) +\n    ggplot2$labs(x = \"Flipper Length (mm)\", y = \"Body Mass (g)\", \n      color = \"Island\", title = \"Flipper vs. Body Mass\", \n      subtitle = \"Palmer Penguins\") +\n    ggplot2$theme_minimal()\n  plotted\n}\n\n\n\nCheck our scatter plot with plot$scatter()\n\n\n\nshow/hide\n# plot\nbox::use(box/plot)\nplot$scatter()\n\n\n\n\n\n\n\n\n\n\n\n\nAnd there you have it! A complete pipeline using box modules! And the total project size (files and folders) is much smaller than building an R package:\n\n\n\nshow/hide\npengbox/\n    ├── box\n    │   ├── import.R\n    │   ├── plot.R\n    │   └── prep.R\n    ├── penguins.Rproj\n    └── run.R\n\n2 directories, 5 files\n\n\n\nBelow are the various ways to include packages and functions in box modules:\n\n\n\n\n\n\n\nNoteOptions for creating box modules:\n\n\n\n\n\n\n\n\n\n\nInside box::use()\n\n\nAction\n\n\n\n\n\n\nbox::use( pkg )\n\n\n|imports ‘pkg’, does not attach any function names\n\n\n\n\nbox::use( p = pkg )\n\n\n|imports ‘pkg’ with alias (‘p’), does not attach any function names\n\n\n\n\nbox::use( pkg = pkg[foo, bar] )\n\n\n|imports ‘pkg’ and attaches the function names ‘pkg::foo()’ and ‘pkg::bar()’\n\n\n\n\nbox::use( pkg[my_foo = foo, …]\n\n\n|imports ‘pkg’ with alias for ‘foo’ (‘my_foo’) and attaches all exported function name"
  },
  {
    "objectID": "posts/box/index.html#nesting-modules",
    "href": "posts/box/index.html#nesting-modules",
    "title": "Writing modular code with box",
    "section": "Nesting modules",
    "text": "Nesting modules\nThe same workflow could be re-written as nested modules, with folders separating logical steps in an analysis workflow (or application). Consider the folder structure below:\n\n\n\nshow/hide\npengbox/\n    ├── box\n    │   └── graph\n    │       ├── wrangle\n    │       │   ├── clean\n    │       │   │   ├── import\n    │       │   │   │   └── raw.R\n    │       │   │   └── cols.R\n    │       │   └── vars.R\n    │       └── scatter.R\n    ├── penguins.Rproj\n    └── run.R\n\n6 directories, 6 files\n\n\n\n\nimport\nWith this structure, the raw module is in the import folder:\n\n\n\nshow/hide\npengbox/box/graph/wrangle/clean/import\n                                    └── raw.R\n\n1 directory, 1 file\n\n\n\n\nThe raw module–the first step–is nested in the box/graph/wrangle/clean/import/raw.R file\n\nThe raw module imports the raw .csv data with an aliass for readr’s read_csv()\n\n\n\n\nraw module\n# box/graph/wrangle/clean/import/raw.R\nbox::use(\n  readr[rcsv = read_csv, cols]\n)\n#' @export\ncsv &lt;- function() {\n  raw_csv_url &lt;- \"https://bit.ly/3SQJ6E3\"\n  # use alias for read_csv()\n  rcsv(raw_csv_url, col_types = cols())\n}\n\n\n\n\n\nraw\n\nIn run.R, I run box/graph/wrangle/clean/import/raw to import the raw module\n\nThe csv() function imports the raw data\n\n\n\n\nshow/hide\n# in use.R\nbox::use(box/graph/wrangle/clean/import/raw)\nstr(raw$csv(), give.attr = FALSE)\n\n\n\n\n\n\nraw module output\nspc_tbl_ [344 × 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA ...\n\n\n\n\n\n\n\nclean\nThe clean folder contains the cols module and the snakes() function\n\n\n\nshow/hide\nbox/graph/wrangle/\n              ├── clean\n              │   ├── #import\n              │   │   #└── raw.R\n              │   └── cols.R\n              └── vars.R\n\n3 directories, 3 files\n\n\n\n\nsnakes\n\nThe box/graph/wrangle/clean/cols module standardizes the column names\n\ncols calls the snakes() function, which converts all the column names to lower_snake_case with an alias for janitor::clean_names(), then it imports select from dplyr to subset the columns\n\n\n\n\ncols module\n# box/graph/wrangle/clean/cols.R\n\n# reset the path\noptions(box.path = getwd())\n\n# use import raw module\nbox::use(box/graph/wrangle/clean/import/raw)\n\n# columns\nbox::use(\n  dplyr[select],\n  janitor[fix_cols = clean_names]\n)\n\n#' @export\nsnakes = function() {\n  raw &lt;- raw$csv()\n  clean_cols &lt;- fix_cols(raw)\n  vars &lt;- select(clean_cols, \n    species, \n    island, \n    bill_length_mm = culmen_length_mm,\n    bill_depth_mm = culmen_depth_mm,\n    flipper_length_mm,\n    body_mass_g,\n    sex)\n  return(vars)\n}\n\n\n\n\nBack in run.R, we call the cols module to convert the columns names with snakes():\n\n\n\n# clean columns\nbox::use(box/graph/wrangle/clean/cols)\nnames(cols$snakes())\n\n\n\n\n\ncols module output\n[1] \"species\"           \"island\"            \"bill_length_mm\"    \"bill_depth_mm\"                  \n[5] \"flipper_length_mm\" \"body_mass_g\"       \"sex\" \n\n\n\n\n\n\n\nwrangle\n\nNow that I have standardized columns and the subset of the variables to plot, I can call the vars module to wrangle the plot variables\n\n\n\n\nshow/hide\nbox/graph/wrangle/\n            ├── #clean\n            │   #├── #import\n            │   #│   #└── raw.R\n            │   #└── cols.R\n            └── vars.R\n\n3 directories, 3 files\n\n\n\n\nvars\n\nvars is nested in the wrangle folder, and imports the raw and cols modules\n\nThe vars module imports mutate and filter from dplyr and an alias for stringr::str_extract()\n\n\n\n\nvars module\n# box/graph/wrangle/vars.R\n\n# reset the path\noptions(box.path = getwd())\n\n# use clean names module\nbox::use(box/graph/wrangle/clean/cols)\n\n# wrangle packages/functions\nbox::use(dplyr[mutate, filter],\n  stringr[str_ext = str_extract])\n\n#' @export\nscatter = function() {\n  clean_cols &lt;- cols$snakes()\n  plot_vars &lt;- clean_cols |&gt;\n    mutate(\n      species = str_ext(species, \"([[:alpha:]]+)\"),\n      species = factor(species),\n      island = factor(island),\n      sex = factor(sex)\n    ) |&gt;\n    # remove missing sex\n    filter(!is.na(sex))\n  return(plot_vars)\n}\n\n\n\nIn run.R, we check the structure of the output from vars$scatter()\n\n\n\nshow/hide\n# in run.R\n# wrangle variables \nbox::use(box/graph/wrangle/vars)\nstr(vars$scatter())\n\n\n\n\n\n\nvars module output\ntibble [333 × 7] (S3: tbl_df/tbl/data.frame)                                                     \n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:333] 39.1 39.5 40.3 36.7 39.3 38.9 39.2 41.1 38.6 34.6 ...\n $ bill_depth_mm    : num [1:333] 18.7 17.4 18 19.3 20.6 17.8 19.6 17.6 21.2 21.1 ...\n $ flipper_length_mm: num [1:333] 181 186 195 193 190 181 195 182 191 198 ...\n $ body_mass_g      : num [1:333] 3750 3800 3250 3450 3650 ...\n $ sex              : Factor w/ 2 levels \"FEMALE\",\"MALE\": 2 1 1 1 2 1 2 1 2 2 ...\n\n\n\n\n\n\n\ngraph\nFinally, we get to the graph module. This module import all preceding modules.\n\n\nbox/\n└── graph\n    ├── #wrangle\n    │   #├── #clean\n    │   #│   #├── #import\n    │   #│   #│   #└── raw.R\n    │   #│   #└── cols.R\n    │   #└── vars.R\n    └── scatter.R\n\n5 directories, 4 files\n\n\n\nscatter\n\nThe scatter module imports the vars module with the data that’s been imported, cleaned, and wrangled.\n\nThe ggp2() function includes the ggplot2 functions to build a scatter plot.\n\n\n\n\nscatter module\n# box/graph/scatter.R\n\n# reset the path\noptions(box.path = getwd())\n\n# import plot vars module\nbox::use(box/graph/wrangle/vars)\n\n# import ggplot2\nbox::use(\n  ggplot2 = ggplot2[ggplot, aes, geom_point, \n                    facet_wrap, labs, theme_minimal]\n)\n\n#' @export\nggp2 &lt;- function() {\n  scatter_vars &lt;- vars$scatter()\n  # plot prepped data\n  ggp2_plot &lt;- ggplot2$ggplot(data = scatter_vars, \n    ggplot2$aes(\n      x = flipper_length_mm,\n      y = bill_length_mm,\n      group = island\n    )\n  ) +\n    ggplot2$geom_point(\n      ggplot2$aes(color = species)\n    ) +\n    ggplot2$facet_wrap(. ~ island) +\n    ggplot2$labs(\n      x = \"Flipper Length (mm)\", \n      y = \"Bill length (mm)\", \n      color = \"Species\",\n      group = \"Island\",\n      title = \"Flipper vs. Bill Length\", \n      subtitle = \"Palmer Penguins\"\n    ) +\n    ggplot2$theme_minimal()\n  ggp2_plot\n}\n\n\n\nIn run.R, the final module call produces the plot.\n\n\n# graph\nbox::use(box/graph/scatter)\nscatter$ggp2()"
  },
  {
    "objectID": "posts/box/index.html#recap",
    "href": "posts/box/index.html#recap",
    "title": "Writing modular code with box",
    "section": "Recap",
    "text": "Recap\nIn this post I’ve covered how the box package uses modules to separate your analysis and workflow into small, modular scripts. Nesting modules also adds a flexibility R packages do not have (because everything has to be contained in the R/ folder).\nBoth versions of the projects created in this example ended up with very few lines of code, and didn’t require a creating a NAMESPACE or DESCRIPTION file.\nView the final project here."
  },
  {
    "objectID": "posts/py-apps/index.html",
    "href": "posts/py-apps/index.html",
    "title": "Python Apps",
    "section": "",
    "text": "NoteNote\n\n\n\n\n\n\nThis is the second post on working in VS Code with Python. I’ll cover developing and publishing Python applications using Bokeh, Streamlit, and Dash.\nI’ve been building quite a few Python applications with VS Code lately and thought I’d write some observations on Bokeh, Streamlit, and Dash. I’ll cover managing dependencies, a few key differences between Python and R, and running the applications in VS Code."
  },
  {
    "objectID": "posts/py-apps/index.html#virtual-environments",
    "href": "posts/py-apps/index.html#virtual-environments",
    "title": "Python Apps",
    "section": "Virtual environments",
    "text": "Virtual environments\nPython virtual environments are designed to manage project-specific dependencies and ensure that the correct versions of packages are used in a given project. Similar to the renv package in R, Python comes with a a venv command for creating a virtual environment.1 It’s common practice to name the virtual environment something like myenv or .venv.\npython -m venv .venv\nvenv works by creating a directory with a copy of the Python interpreter and the necessary executables to use it. After creating the virtual environment folder, we can activate it using the following command:\nsource .venv/bin/activate\n# windows\n# myenv\\Scripts\\activate\nIf you’re using VS Code, this activate the following prompt to set your workspace folder:\n\n\n\n\n\n\n\nWorkspace folder\n\n\nClick Yes, then make sure all the dependencies listed in the requirements.txt file are installed in the virtual environment using pip, the package installer for Python.\npip install -r requirements.txt\nAs you’re developing, new dependencies can be recorded in requirements.txt using pip freeze:\npip freeze &gt; requirements.txt\nThe .venv/ directory will store the Python version and packages used in the Python project:\n.venv/\n  └──lib/\n      └── python3.9/\n            └── site-packages/\nPackages installed into .venv/lib/python3.9/site-packages do not affect the global Python installation or other virtual environments. This isolation helps prevent version conflicts and makes dependency management easier.\n\nGit history\nThe virtual environment will store all the dependencies for a project, so it’s a good practice to remove it from any Git repositories. You can do this with the following commands in the terminal:\necho \".venv/\" &gt;&gt; .gitignore\ngit add .gitignore\ngit commit -m \"Add .venv to .gitignore\"\nYou can also remove the .venv directory from the latest commit:\ngit rm -r --cached .venv\ngit commit -m \"Remove .venv directory\"\n\n\n\n\n\n\nTipUsing venv\n\n\n\n\n\n\nvenv allows us to manage dependencies more effectively, ensuring a clean and isolated environment for each Python app project.\n# create a virtual environment\npython -m venv .venv\n\n# activate the virtual environment on macOS/Linux\nsource .venv/bin/activate  \n\n# install necessary packages\npip install dash streamlit bokeh\n\n# save your current environment's packages\npip freeze &gt; requirements.txt\n\n# install the packages in a new environment\npip install -r requirements.txt\n\n# deactivate the virtual environment when done\ndeactivate\n\n\n\n\nBokeh, Streamlit, and Dash are three popular libraries for creating interactive Python applications, particularly for visualizations and dashboards. Below we’ll explore building an application in each framework using the palmerpenuins data. For uniformity, each app will include a scatter plot comparing the numeric variables and a table output."
  },
  {
    "objectID": "posts/py-apps/index.html#bokeh",
    "href": "posts/py-apps/index.html#bokeh",
    "title": "Python Apps",
    "section": "Bokeh",
    "text": "Bokeh\n\n\n\nBokeh is a library in Python specifically designed for creating interactive and visually appealing interactive graphs and charts. Bokeh can also create static HTML files without a server, similar to RMarkdown’s HTML output.\n\nImporting Libraries\nCreate a main.py script and install the following libraries using pip. pandas is for data manipulation, bokeh will be used for the interactive visualizations, and the palmerpenguins package will load the penguins dataset.\n\nimport pandas as pd\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, DataTable, TableColumn, NumberFormatter, Select\nfrom bokeh.plotting import figure, curdoc\nfrom palmerpenguins import load_penguins\n\nin R, we might use dplyr for data manipulation and ggplot2 for visualizations. For interactive visualizations, we might use plotly.\n\n\n\n\n\n\nTipPython vs. R: Key Differences When Importing Libraries\n\n\n\n\n\n\n\nLibrary Import Syntax\nPython emphasizes explicit control over imports and namespaces:\n\nPython uses the import statement\n\nimport package_name\n\nAliases are often used to shorten package names\n\nimport package_name as alias\n\nPython uses from to import specific functions or classes\n\nfrom package_name import specific_function\n\n\nR uses the library() or require() function to import packages. R loads the entire package into the namespace by default. If you have functions with the same name in different packages, you can specify the package explicitly with package::function().\n\n\n\n\n\n\nLoading Data\nThe penguins dataset is loaded into a pandas DataFrame using load_penguins() and the missing data is removed with df.dropna().\n\ndf = load_penguins()\ndf = df.dropna()\n\nA ColumnDataSource is created from the DataFrame, which is used by Bokeh for efficient data handling (this intermediate step doesn’t really have an R equivalent).\n\nsource = ColumnDataSource(df)\n\nA list of numeric columns is defined to use in the scatter plot drop-downs. If we were doing this in R, we could use colnames() or dplyr::select():\n\nnumeric_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n\n\n\nApp Inputs\nTwo drop-down Select() widgets can be created for selecting x and y axes variables.\n\nx_select = Select(title=\"X Axis\", value=\"bill_length_mm\", options=numeric_columns)\ny_select = Select(title=\"Y Axis\", value=\"bill_depth_mm\", options=numeric_columns)\n\nIf this was a Shiny app, we would use selectInput().\n\n\nScatter Plot\nWe can initialize a scatter plot with the default axis labels and data:\n\nscatter_plot = figure(title=\"Scatter Plot\",\n                      x_axis_label='Bill Length (mm)',\n                      y_axis_label='Bill Depth (mm)')\nscatter_plot.scatter(x='bill_length_mm', y='bill_depth_mm', source=source, size=10)\n\nIn ggplot2, this would look like:\n\n\nshow/hide ggplot2 equivalent code\nggplot(df, \n  aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\n\n\n\nInteractivity\nBelow we define update_plot(), a function for updating the scatter plot when a new variable is selected for the x or y axis. It changes axis labels and re-renders the plot with new data.\n\ndef update_plot(attr, old, new):\n    x = x_select.value\n    y = y_select.value\n    scatter_plot.xaxis.axis_label = x.replace('_', ' ').title()\n    scatter_plot.yaxis.axis_label = y.replace('_', ' ').title()\n    scatter_plot.renderers = []  # clear existing renderers\n    scatter_plot.scatter(x=x, y=y, source=source, size=10)\n\nx_select.on_change(\"value\", update_plot)\ny_select.on_change(\"value\", update_plot)\n\nIn shiny, you would use observeEvent() or reactive() to update plots dynamically.\n\n\nTable Display\nThe code below defines columns and their formatters for the data table to be displayed. DataTable() creates data_table, a DataTable widget that displays the data. This is similar to using DT::datatable(df) in R.\n\ncolumns = [\n    TableColumn(field=\"species\", title=\"Species\"),\n    TableColumn(field=\"island\", title=\"Island\"),\n    TableColumn(field=\"bill_length_mm\", title=\"Bill Length (mm)\", formatter=NumberFormatter(format=\"0.0\")),\n    TableColumn(field=\"bill_depth_mm\", title=\"Bill Depth (mm)\", formatter=NumberFormatter(format=\"0.0\")),\n    TableColumn(field=\"flipper_length_mm\", title=\"Flipper Length (mm)\", formatter=NumberFormatter(format=\"0\")),\n    TableColumn(field=\"body_mass_g\", title=\"Body Mass (g)\", formatter=NumberFormatter(format=\"0\")),\n    TableColumn(field=\"sex\", title=\"Sex\"),\n    TableColumn(field=\"year\", title=\"Year\", formatter=NumberFormatter(format=\"0\"))\n]\n\ndata_table = DataTable(source=source, columns=columns, width=800)\n\n\n\nLayout\nThe layout is defined using column and row and added to the current document for rendering. In shiny, you would use fluidPage(), sidebarLayout(), mainPanel(), etc., to arrange UI components.\n\nlayout = column(row(x_select, y_select), scatter_plot, data_table)\ncurdoc().add_root(layout)\n\n\n\nRun the App\nTo run this code, save main.py and use the bokeh serve command:\n\nbokeh serve --show main.py\n\nIn R, you would run a shiny app using shinyApp(ui, server) and the runApp() function.\nThe full code in main.py is available below:\n\n\nshow/hide main.py\nimport pandas as pd\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, DataTable, TableColumn, NumberFormatter, Select\nfrom bokeh.plotting import figure, curdoc\nfrom palmerpenguins import load_penguins\n\n# load the penguins dataset\ndf = load_penguins()\n\n# drop missing data \ndf = df.dropna()\n\n# create ColumnDataSource\nsource = ColumnDataSource(df)\n\n# numeric columns\nnumeric_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n\n# create select widgets for x and y axis\nx_select = Select(title=\"X Axis\", value=\"bill_length_mm\", options=numeric_columns)\ny_select = Select(title=\"Y Axis\", value=\"bill_depth_mm\", options=numeric_columns)\n\n# scatter plot comparing selected variables\nscatter_plot = figure(title=\"Scatter Plot\",\n                      x_axis_label='Bill Length (mm)',\n                      y_axis_label='Bill Depth (mm)')\n\nscatter_plot.scatter(x='bill_length_mm', y='bill_depth_mm', source=source, size=10)\n\ndef update_plot(attr, old, new):\n    x = x_select.value\n    y = y_select.value\n    scatter_plot.xaxis.axis_label = x.replace('_', ' ').title()\n    scatter_plot.yaxis.axis_label = y.replace('_', ' ').title()\n    scatter_plot.renderers = []  # Clear existing renderers\n    scatter_plot.scatter(x=x, y=y, source=source, size=10)\n\nx_select.on_change(\"value\", update_plot)\ny_select.on_change(\"value\", update_plot)\n\n# define columns \ncolumns = [\n    TableColumn(field=\"species\", title=\"Species\"),\n    TableColumn(field=\"island\", title=\"Island\"),\n    TableColumn(field=\"bill_length_mm\", title=\"Bill Length (mm)\", formatter=NumberFormatter(format=\"0.0\")),\n    TableColumn(field=\"bill_depth_mm\", title=\"Bill Depth (mm)\", formatter=NumberFormatter(format=\"0.0\")),\n    TableColumn(field=\"flipper_length_mm\", title=\"Flipper Length (mm)\", formatter=NumberFormatter(format=\"0\")),\n    TableColumn(field=\"body_mass_g\", title=\"Body Mass (g)\", formatter=NumberFormatter(format=\"0\")),\n    TableColumn(field=\"sex\", title=\"Sex\"),\n    TableColumn(field=\"year\", title=\"Year\", formatter=NumberFormatter(format=\"0\"))\n]\n\n# create DataTable\ndata_table = DataTable(source=source, columns=columns, width=800)\n\n# Layout\nlayout = column(row(x_select, y_select), scatter_plot, data_table)\n\n# add layout to curdoc\ncurdoc().add_root(layout)\n\n\n\nAfter running the bokeh serve command, the terminal will display the local URL we can use to view our app:\nStarting Bokeh server version 3.4.2 (running on Tornado 6.4)\nUser authentication hooks NOT provided (default user enabled)\nBokeh app running at: http://localhost:5006/main\nStarting Bokeh server with process id: 88167\nWebSocket connection opened\nServerConnection created\n\n\n\n\n\n\n\nBokeh Python App\n\n\nAs we can see, the layout is simple, and it gets the job done quickly with a modest amount of code. Bokeh is not really designed for full-fledged applications, but it is capable of creating detailed and interactive plots and tables."
  },
  {
    "objectID": "posts/py-apps/index.html#streamlit",
    "href": "posts/py-apps/index.html#streamlit",
    "title": "Python Apps",
    "section": "Streamlit",
    "text": "Streamlit\n\n\n\nStreamlit is another library for creating web applications for data analysis and visualization. It’s known for its simplicity and generally requires less code to build functional applications.\n\nImporting Libraries\nAfter creating and activating a Python virtual environment with venv, ensure you have streamlit, palmerpenguins, and the other necessary libraries installed using pip. Create an app.py file and import the following libraries:\n\nimport streamlit as st\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom palmerpenguins import load_penguins\n\n\n\nLoading Data\nLoad the penguins data as a pandas DataFrame using the load_penguins() function from the palmerpenguins:\n\n# load the dataset\npenguins = load_penguins()\n\n\n\nApp Inputs\nThe code below creates a streamlit application that includes a scatter plot with a dropdown menu for selecting the X-axis and Y-axis variables among the numeric columns (minus year). The scatter plot differentiates the species by color.\n\nst.title sets the title of the app.\n\nst.title('Palmer Penguins Dashboard')\n\nst.write displays text and the datase.t2\n\nst.write(\"### Scatter Plot\")\n\nst.selectbox creates dropdown menus for selecting variables for the scatter plot.\n\nx_axis = st.selectbox('X-axis variable', numeric_columns)\n\n\n\n\nScatter Plot\nThe scatter plot is created using seaborn, a visualization library built on top of matplotlib.\n\nif x_axis and y_axis:\n    fig, ax = plt.subplots()\n    sns.scatterplot(data=penguins, x=x_axis, y=y_axis, hue='species', ax=ax)\n    st.pyplot(fig)\n\n\n\nTable Display\nThe st.dataframe method displays the dataset in a table format within the streamlit app.\n\nst.dataframe(penguins)\n\n\n\n\n\n\n\nTipPython vs. R: Key Syntax Differences\n\n\n\n\n\n\n\nAssignment Operators\n\nPython uses = for assignment.\n\nR typically uses &lt;- for assignment, although = can also be used.\n\nFunction Calls\n\nPython calls st.selectbox() where st is an alias for streamlit.\n\nR can call selectInput() after loading the shiny library, although shiny::selectInput() can be used (if shiny is installed).\n\nData Structures\n\nIn Python, the data is read into a pandas DataFrame.\n\nIn R, the data is read into a tibble, which is part of the tidyverse and is a modern reimagining of the traditional data frame.\n\n\n\n\n\nThe full application code is available below:\n\n\nshow/hide app.py\n# app title\nst.title('Palmer Penguins Dashboard')\n\n# numeric columns for scatter plot\nnumeric_columns = penguins.select_dtypes(include=['float64', 'int64']).columns\n# drop year\nnumeric_columns = numeric_columns.drop('year')\n\n# scatter plot\nst.write(\"### Scatter Plot\")\nx_axis = st.selectbox('X-axis variable', numeric_columns)\ny_axis = st.selectbox('Y-axis variable', numeric_columns, index=1)\n\nif x_axis and y_axis:\n    fig, ax = plt.subplots()\n    sns.scatterplot(data=penguins, x=x_axis, y=y_axis, hue='species', ax=ax)\n    st.pyplot(fig)\n\n# display the dataframe as a table\nst.write(\"### Dataset\")\nst.dataframe(penguins)\n\n# footer\nst.write(\"Data Source: [palmerpenguins](https://github.com/allisonhorst/palmerpenguins)\")\n\n\n\n\nRun the App\nOpen your terminal, navigate to the directory containing app.py, and run:\nstreamlit run app.py\n\n\n\n\n\n\n\nStreamlit Python App\n\n\nWith streamlit we’re able to create an interactive graph and table display with about 1/3 the code we used in Bokeh, which is why they are ideal for quickly building and sharing simpler web apps (similar to flexdashboard in R). However, Streamlit apps have limited customization and may not handle very complex apps or large datasets efficiently."
  },
  {
    "objectID": "posts/py-apps/index.html#dash",
    "href": "posts/py-apps/index.html#dash",
    "title": "Python Apps",
    "section": "Dash",
    "text": "Dash\n\n\n\nDash is a framework developed by Plotly for building analytical web applications using Python. It’s especially well-suited for interactive visualizations and dashboards.\n\nImporting Libraries\nIn an app.py file, we’ll start by importing the following necessary libraries. dash and dash.dependencies 3 are used for building web applications (similar to shiny), pandas is imported for data manipulation, plotly.express is used for creating plots (akin to ggplot2), and dash_bootstrap_components allows us to use Bootstrap themes for styling the app.\n\nimport dash\nfrom dash import dcc, html, dash_table\nfrom dash.dependencies import Input, Output\nimport pandas as pd\nimport plotly.express as px\nimport dash_bootstrap_components as dbc\n\n\n\nLoading Data\nNow that we’ve identified and imported the dependencies, we can read the data into the application using pandas. We can assign the URL to the raw .csv file to url, then have pd.read_csv() read the CSV file into a pandas DataFrame.4\n\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\"\ndf = pd.read_csv(url)\n\n\n\nUtility Function\n\ndef format_label(label):\n    return label.replace('_', ' ').title()\n\nThis function replaces underscores with spaces and capitalizes words. In R, you would define a similar function using gsub() and tools::toTitleCase().\n\n\nDefine Columns\nWe want to omit the year column from the drop-dowwns, so we’ll define numerical_columns outside of the app so we don’t have to repeat this code later. Type float64 or int64 are numeric columns.\n\nnumerical_columns = [col for col in df.select_dtypes(include=['float64', 'int64']).columns if col != 'year']\n\n\n\nInitialize App\ndash.Dash creates a Dash app instance with Bootstrap styling by supplying dbc.themes.BOOTSTRAP to the external_stylesheets argument.5 This is somewhat similar to initializing a Shiny app with shiny::shinyApp().\n\napp = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n\nIn the case of initializing a Dash app, __name__ is passed as an argument to the dash.Dash() constructor to specify the name of the application. We’ll encounter this again when we launch the application below.\n\n\nLayout\nThe majority of the code is contributed to defining the app layout using Bootstrap components.\n\ndbc.Container, dbc.Row, and dbc.Col arrange components in a grid, similar to layout functions in Shiny like fluidPage(), sidebarLayout(), etc.\n\napp.layout = dbc.Container([\n    dbc.Row([\n        dbc.Col([\n\n        ])\n    ])\n])\n\nhtml.H1 creates a header, like tags$h1() in Shiny.\n\n  html.H1(\"Palmer Penguins Dashboard\")\n\ndcc.Dropdown creates dropdown menus for user input, similar to selectInput() in Shiny.\n\n  dcc.Dropdown(\n      id='x-axis',\n      options=[{'label': col, 'value': col} for col in numerical_columns],\n      value='bill_length_mm',\n      clearable=False\n  )\n\ndcc.Graph places a plot in the app, analogous to plotOutput() in Shiny.\n\n  dcc.Graph(id='scatter-plot')\n\ndash_table.DataTable displays data in a table, similar to DT::dataTableOutput() in R.\n\n  dash_table.DataTable(\n      id='table',\n      columns=[{\"name\": i, \"id\": i} for i in df.columns],\n      data=df.to_dict('records'),\n      page_size=10,\n      style_table={'overflowX': 'auto'},\n      style_cell={\n          'height': 'auto',\n          'minWidth': '140px', 'width': '140px', 'maxWidth': '140px',\n          'whiteSpace': 'normal'\n      }\n  )\n\n\n\n\nCallback\nThe callback function updates the scatter plot based on dropdown inputs.\n\nThe @app.callback decorator defines reactive behavior, similar to observeEvent() or reactive() in Shiny.6\n\n  @app.callback(\n      Output('scatter-plot', 'figure'),\n      [Input('x-axis', 'value'),\n       Input('y-axis', 'value')]\n  )\n\nThe function update_scatter_plot takes inputs from dropdowns and updates the plot, using plotly.express and our format_label() utility function to create the scatter plot, similar to using ggplot2 in R.\n\n  def update_scatter_plot(x_axis, y_axis):\n      fig = px.scatter(\n          df, x=x_axis, y=y_axis, color='species',\n          labels={x_axis: format_label(x_axis), y_axis: format_label(y_axis)},\n          title=f'Scatter Plot of {format_label(x_axis)} vs {format_label(y_axis)}'\n      )\n      return fig\n\n\nThe full callback code is below:\n\n\nshow/hide app callback in app.py\n@app.callback(\n    Output('scatter-plot', 'figure'),\n    [Input('x-axis', 'value'),\n     Input('y-axis', 'value')]\n)\ndef update_scatter_plot(x_axis, y_axis):\n    fig = px.scatter(\n        df, x=x_axis, y=y_axis, color='species',\n        labels={x_axis: format_label(x_axis), y_axis: format_label(y_axis)},\n        title=f'Scatter Plot of {format_label(x_axis)} vs {format_label(y_axis)}'\n    )\n    return fig\n\n\n\n\nFor loops\nPython often relies on explicit iteration using for loops, which means Python code tends to use for loops more frequently than R code. The reason for this goes beyond the scope of this blog post, but it’s rooted in the distinct practices and strengths of each language.\nComing from R (and purrr or the apply family of functions), writing for loops can take some getting used to, so I’ve broken down the numerical_columns and dcc.Dropdown() examples from our Dash app.\n\nnumerical_columns = [col for col in df.select_dtypes(include=['float64', 'int64']).columns if col != 'year']\n\n\n[col for col in ...] is a list comprehension–it iterates over each column name (col) in the filtered list of column names.\ndf is a DataFrame, and select_dtypes is a method that filters the DataFrame columns based on their data types. It includes columns with data types float64 and int64 (similar to numeric types in R).\n.columns retrieves the names of the columns that have been filtered by select_dtypes.\nif col != 'year' is the condition to ensure that the column year is excluded from the resulting list, even if it has a numeric type.\n\n\noptions=[{'label': col, 'value': col} for col in numerical_columns]\n\nThis for loop iterates over each column name (col) in the numerical_columns list.\n\nFor each column name, it creates a dictionary ({'label': col, 'value': col}).\nlabel is the text displayed in the Dropdown, and value is the actual value assigned to this option.\n\n\ncolumns=[{\"name\": i, \"id\": i} for i in df.columns]\n\nThis for loop iterates over all columns of the DataFrame df.\n\nFor each column, it creates a dictionary with name and id both set to the column name.\nThese dictionaries are used to define the columns of the dash_table.DataTable().\n\nThe entire app layout code is below:\n\n\nshow/hide full Dash app in app.py\nimport dash\nfrom dash import dcc, html, dash_table\nfrom dash.dependencies import Input, Output\nimport pandas as pd\nimport plotly.express as px\nimport dash_bootstrap_components as dbc\n\n# load the dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\"\ndf = pd.read_csv(url)\n\n# remove the 'year' column \nnumerical_columns = [col for col in df.select_dtypes(include=['float64', 'int64']).columns if col != 'year']\n\n# initialize the Dash app\napp = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n\n# function to replace underscores with spaces\ndef format_label(label):\n    return label.replace('_', ' ').title()\n\n# app layout\napp.layout = dbc.Container([\n    dbc.Row(\n        dbc.Col(\n            html.H1(\"Palmer Penguins Dashboard\"), \n        width=12)\n    ),\n    dbc.Row(\n        html.H3(\"Inputs\")\n    ),\n    dbc.Row([\n        dbc.Col(\n            dcc.Dropdown(\n                id='x-axis',\n                options=[{'label': col, 'value': col} for col in numerical_columns],\n                value='bill_length_mm',\n                clearable=False\n            ), width=3\n        ),\n        dbc.Col(\n            dcc.Dropdown(\n                id='y-axis',\n                options=[{'label': col, 'value': col} for col in numerical_columns],\n                value='bill_depth_mm',\n                clearable=False\n            ), width=3\n        )\n    ]),\n    dbc.Row([\n        dbc.Col([\n            html.H3(\"Scatter Plot\"),\n            dcc.Graph(id='scatter-plot')\n        ], width=6),\n        dbc.Col([\n            html.H3(\"Table\"),\n            dash_table.DataTable(\n                id='table',\n                columns=[{\"name\": i, \"id\": i} for i in df.columns],\n                data=df.to_dict('records'),\n                page_size=10,\n                style_table={'overflowX': 'auto'},\n                style_cell={\n                    'height': 'auto',\n                    'minWidth': '140px', 'width': '140px', 'maxWidth': '140px',\n                    'whiteSpace': 'normal'\n                }\n            )\n        ], width=6)\n    ])\n])\n\n# callback to update the scatter plot\n@app.callback(\n    Output('scatter-plot', 'figure'),\n    [Input('x-axis', 'value'),\n     Input('y-axis', 'value')]\n)\ndef update_scatter_plot(x_axis, y_axis):\n    fig = px.scatter(\n        df, x=x_axis, y=y_axis, color='species',\n        labels={x_axis: format_label(x_axis), y_axis: format_label(y_axis)},\n        title=f'Scatter Plot of {format_label(x_axis)} vs {format_label(y_axis)}'\n    )\n    return fig\n\n# run the app\nif __name__ == '__main__':\n    app.run_server(debug=True)\n\n\n\n\nRun the App\nThe code below runs the application. Note that the __name__ == '__main__' condition corresponds to the dash.Dash(__name__, ...) we used to initialize the application above.\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n\nRun the application by running the following commands in the terminal:\npython app.py\nDash is running on http://127.0.0.1:8050/\n\n * Serving Flask app 'app'\n * Debug mode: on\nUse Cmd/Ctrl + click on the URL to open the web browser with our application:\n\n\n\n\n\n\n\nPenguins Dash App\n\n\nThe Dash application has an interactive scatter plot (with hover features) with a side-by-side table display. The layout functions in Dash give us more control over output placement in the UI, and the additional HTML functions give us the ability to build our application up like a standard webpage (or Shiny app)."
  },
  {
    "objectID": "posts/py-apps/index.html#recap",
    "href": "posts/py-apps/index.html#recap",
    "title": "Python Apps",
    "section": "Recap",
    "text": "Recap\nIn summary, Bokeh is excellent for creating detailed and interactive visualizations, comparable to ggplot2 and plotly for interactive plots, but it’s not focused on developing complete applications. Streamlit is very user-friendly and ideal for quickly building and sharing simpler web apps, but with fewer options for customization. Dash is capable of developing highly customizable and complex web applications (similar to Shiny), but has a steeper learning curve than Streamlit.\nYou can view the code used to create the apps in this repo."
  },
  {
    "objectID": "posts/py-apps/index.html#footnotes",
    "href": "posts/py-apps/index.html#footnotes",
    "title": "Python Apps",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nvenv is a module that comes built-in with Python 3.3 and later versions, so we do not need to install it separately.↩︎\nst.write() is incredibly versatile. We’re passing it Markdown-formatted text in this example, but it can be used to display DataFrames, models, and more.↩︎\nWatch The Dash Callback - Input, Output, State, and more on the Charming Data YouTube channel.↩︎\npd.read_csv is analogous to read.csv or readr::read_csv in R.↩︎\nRead all the arguments for dash.Dash in the documentation.↩︎\nRead more about Dash callback definitions in the documentation.↩︎"
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html",
    "href": "posts/p1-tests-unit-tests/index.html",
    "title": "Behavior Driven Unit Tests",
    "section": "",
    "text": "packages\nlibrary(testthat)\nlibrary(lobstr)\nlibrary(dplyr)\nlibrary(shiny)\nlibrary(covr)\nThis post is the first in a series on testing Shiny applications. We’ll cover developing and testing a set of utility functions for a Shiny app-package using testhat. If you’d like to follow along, all the code we’ll be using is contained in the utap branch of the sapkgs repo on GitHub.\n# renv::install(\"mjfrigaard/utap\")\nlibrary(utap)\nTesting the code in Shiny app-packages can be more complicated than testing the code in a typical R package, because app-packages contain two types of code:\nThese two types of code require different types of tests. Utility functions are usually accompanied by unit tests similar to the tests you’d find in a standard R package1, while the application’s reactive code can be tested using Shiny’s testServer() function, and the system tests can be built using the shinytest2 package.\nThis post will cover writing unit tests for a set of utility functions using testthat and covr. Any tips or time-savers I’ve found will be in green callout boxes:"
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html#what-are-unit-tests",
    "href": "posts/p1-tests-unit-tests/index.html#what-are-unit-tests",
    "title": "Behavior Driven Unit Tests",
    "section": "What are unit tests?",
    "text": "What are unit tests?\n\n\n\n\n“A unit test is a piece of code that invokes a unit of work and checks one specific end result of that unit of work. If the assumptions on the end result turn out to be wrong, the unit test has failed. A unit test’s scope can span as little as a method or as much as multiple classes.” - The Art of Unit Testing, 2nd edition\n\nThinking of functions as ‘units of work’ and their desired behavior as an ‘end results’ provides a useful mental model (especially during behavior-driven development. These terms also align nicely with the testing advice offered by testthat:\n\nStrive to test each behaviour in one and only one test. Then if that behaviour later changes you only need to update a single test.\n\nIn app-packages, the testthat package provides a comprehensive and flexible framework for performing unit tests.\n\ntestthat\nGet started with testthat by running usethis::use_testthat(). This function will create following files and folders:\ntests/\n  ├── testthat/\n  └── testthat.R\nTo create new tests, we’ll run usethis::use_test(\"&lt;name&gt;\") (with \"select_class\" being the name of the function we’d like to test).\n\nusethis::use_test(\"select_class\")\n\n✔ Setting active project to '/projects/apps/utap'\n✔ Writing 'tests/testthat/test-select_class.R'\n• Modify 'tests/testthat/test-select_class.R'\n\nTest files\nNew test files are be created and opened from the tests/testthat/ folder (with a test- prefix). Each function we’re testing should have it’s own .R file the R/ folder and a corresponding test- file in the tests/testthat/ folder (we’ll see how this helps with interactive testing in the IDE below). The initial contents of a new test file contains the boilerplate code below:\n\n\n\ntest_that(\"multiplication works\", {\n  expect_equal(2 * 2, 4)\n})\n\n\n\n\n\ntestthat test file\n\n\n\n\n\n\n\nTest structure\ntest_that() sets the test “scope” or “execution environment”, and encapsulates the test code and expectations. Note the use of curly brackets after the code argument:\n\n\n\n\n\n\nFigure 1: testthat test\n\n\n\n\n\nExpectations\nTest expectations are the code that comes into direct contact with the unit of work and end result for each function. It’s likely we’ll have multiple expectations for any given function, so we store these in tests and use the desc to describe the test context (all testthat expectations have an expect_* prefix):\n\n\n\n\n\n\nexpect_* functions\n\n\n\n\n\n\n\nexpectations\n\n\n\n\n\n\n\n\nKeyboard shortcuts\nI highly recommend using a shortcut while developing tests because it will improve your ability to iterate quickly.2\n\n\n\ndevtools function\ntest()\n\n\n \n\n\nKeyboard shortcut\nCtrl/Cmd + Shift + T\n\n\n\n\n\n\ntest_active_file()\n\n\n \n\n\nCtrl/Cmd + T\n\n\n\n\n\n\ntest_coverage_active_file()\n\n\n \n\n\nCtrl/Cmd + Shift + R"
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html#behavior-driven-development",
    "href": "posts/p1-tests-unit-tests/index.html#behavior-driven-development",
    "title": "Behavior Driven Unit Tests",
    "section": "Behavior-Driven Development",
    "text": "Behavior-Driven Development\nBehavior-driven development (or behavior-driven testing) is helpful if you find yourself communicating with users and/or stakeholders while developing Shiny apps. BDD centers around “conversation and examples to specify how you expect a system to behave”3 and it’s supported with testthats describe() and it() functions.4\n\n\n\n\n\n\nNoteBDD features & scenarios\n\n\n\n\n\n\nIn BDD, requirements are written plain language ‘feature files’ using a series of keywords:\nFeature:  \n  As a \n  I want \n  So that\n  \n  Background:\n    Given \n    And  \n    \n  Scenario:  \n    When \n    And  \n    Then \n    \nThe Feature is a high-level description (usually with a title and description). As a describes the end user the feature is intended for, their needs (I want), and the desired result (So that).\nThe Background can include any steps or conditions that exist before each scenario.\nA Scenario is a series of steps outlining a concrete examples that illustrates a feature. When is used to describe an event, or an action. Then describes what will verify the expected outcome is observable by the user. And combines Given with When or Then.\nRead more about Gherkin on the Cucumber website..\n\n\n\n\n\nSpecifications\nIn R packages, micro-iteration is defined as, “the interactive phase where you initiate and refine a function and its tests in tandem.” In app development, this stage might after you’ve received needs or specifications by an end-user or stakeholder.\nIf we’re using BDD, we’ll translate these specifications into functional requirements, then start writing test(s). After outlining the tests, we’ll write the function(s) to pass the test.\ntestthat’s describe() and it() functions and Gherkin syntax can clarify this process because we can describe what it is we want to test before getting stuck writing any test code.\nLet’s assume we’ve been asked to design an application that automatically to populates the user drop-downs with variables based on their format: binary, numeric, categorical, and–a subset of categorical–facet.5\n\nFeatures & Background: use the description (entered as a character string in the first argument of describe()) to capture the “unit of work” for each function. Feature and Background information can be included in nested describe() blocks.\n\n\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n})\n\n\nScenario: Every new Scenario keyword should have a corresponding it() or test_that() call.6 Try to be as specific as possible (while staying short and sweet) when describing the scenarios.\n\n\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n    it(\"Scenario: Given a data frame with a mix of columns\n      When I call pull_cols() with type 'binary'\n      Then I should receive a list of 'binary' column names\", code = {\n      \n    })\n  \n})\n\n\nExpectations: The Then keywords capture our expectations (and expect_*() function). In this case, it’s the ‘list of column names that match the \"&lt;type&gt;\" criteria’\n\n\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n    it(\"Scenario: Given a data frame with a mix of columns\n      When I call pull_cols() with type 'binary'\n      Then I should receive a list of 'binary' column names\", code = {\n      \n      expect_equal(is.logical(object))\n      \n    })\n  \n})\n\nIt’s worth noting that, at least conceptually, scenarios and expectations arise first. We’re usually working backwards from a desired “end result” a function is supposed to produce (i.e., compute a value, download a file, create a column, etc.).\n\nRequirements\nFor example, calling pull_cols(df, \"bin\") would ‘pull’ all the binary columns from an input data.frame or tibble (the example below uses palmerpenguins::penguins):\n\npull_cols(palmerpenguins::penguins, type = \"bin\")\n\n\n##  sex \n## \"sex\" \n\nThe return values can be passed to updateSelectInput() in the server to provide column names by type (i.e., numeric, binary, etc). pull_colls() can be used to quickly group variables into groups for data visualizations or table displays.\nFor example, categorical variables with 3-5 levels can be mapped to a facet layer (if using ggplot2). See the hypothetical UI output example below:\n\n# UI code\nselectInput(\n  inputId = ns(\"facet\"),\n  label = \"Select Facet Column\",\n  choices = c(\"\", NULL)\n)\n\n\n# pull facet columns from data\nfacet_cols &lt;- reactive({\n  pull_cols(df = ds(), type = \"facet\")\n})\n# update facet inputs\nobserve({\n  updateSelectInput(\n    session = session,\n    inputId = \"facet\",\n    choices = facet_cols()\n  )\n}) |&gt;\n  bindEvent(facet_cols())\n\nIn the example above, pull_cols() is passed a reactive dataset (data()), and the output is used to update the selectInput():\n\n\n\nSelect Facet Column\n\nspecies\nisland\n\n\n\n\n\n\nThe first step of pull_cols() will be to identify and extract columns based on their class, so we’ll create a test for select_class(), a function with a class parameter that supports multiple column types. The roxygen2 documentation for select_class() is below:\n\n\nshow/hide roxygen2 documentation\n#' Select Column Class\n#'\n#' `select_class()` selects columns from a data.frame based on the specified\n#' `class`. Options include logical, integer, double, character, factor, ordered,\n#' and list column types.\n#'\n#' @param df A `data.frame` from which columns will be selected.\n#' @param class Character vector specifying the class(es) of columns to select.\n#'   Supported values are:\n#'   * \"logical\" (\"lo\")  \n#'   * \"integer\" (\"in\")  \n#'   * \"double\" (\"do\")  \n#'   * \"character\" (\"ch\")  \n#'   * \"factor\" (\"fa\")   \n#'   * \"ordered\" (\"or\")   \n#'   * \"list\" (\"li\")\n#'   \n#' @param return_tbl Logical indicating whether to return the result as a\n#'   `data.frame`. If `FALSE`, a vector of selected column names is returned.\n#'\n#' @return A `data.frame` or vector of column names, depending on `return_tbl`.\n\n\nWe’ve also included a return_tbl argument that allows select_class() to return the column names.\n\n\nAbstract folder trees\nWhile developing R functions, I’ve found the ast() function from the lobstr package can be great for keeping track of nested function calls.\nselect_class() will have a nested is_class() function, which contains a series of test for objects (i.e., is.logical(), is.integer(), etc.). To keep track of nested functions in R/ files, sometimes I’ll outline the function in an abstract function tree and store this in a vignette.7\nBelow is an example tree for select_class():\n\n\n\nSyntax:\n\n\nlobstr::ast(\n    select_class(\n      is_class()\n      )\n)\n\n\n\n\nOutput:\n\n\n\n█─select_class \n└─█─is_class \n\n\n\n\nThe tree above is simple–it only has two functions so far–but as packages grow these abstract displays become more important for tracking function calls (and tests!).\n\n\n\n\n\n\nTipTIP! Function Names\n\n\n\n\n\n\nComing up with names for functions can be challenging. I like to follow the tidyverse style guide and use short verbs as a prefix (make_, get_, check_ etc.) that will give ‘future’ me hints as to their behavior.\nI like to stick to naming conventions I’m familiar with. For example, select_class() has similar behavior to dplyr::select(), and pull_cols() is more like dplyr::pull().\n\n\n\n\nOutlining functions with lobstr::ast() can helpful if we plan on iterating multiple, smaller functions. For example, before making a binary vector of column names, we need to verify the column has only two values. Binary variables can come in multiple flavors (logical, integer, character, factor, ordered, etc.), so check_binary_vec() will have a series of ‘checks’ for each column type.\nBelow is an abstract folder tree outlining pull_binary_cols(), the function called to extract a named character vector of binary column names:\n\n\n█─pull_binary_cols \n├─█─select_class \n│ └─█─is_class \n└─█─make_binary_vec \n  └─█─check_binary_vec \n    ├─█─check_log_binary \n    ├─█─check_int_binary \n    ├─█─check_chr_binary \n    ├─█─check_fct_binary \n    └─█─check_ord_binary \n\n\npull_binary_cols() calls select_class() then passes the selected columns to make_binary_vec(), where check_binary_vec() determines if it’s one of the five types of possible binary variables.\n\npull_binary_cols(palmerpenguins::penguins)\n##   sex \n## \"sex\"\n\n\npull_binary_cols(dplyr::starwars)\n##   gender \n## \"gender\"\n\nThe pull_facet_cols() outline is similar, except that it calls the pull_binary_cols() first, then selects the columns and determines if any remaining have 3-5 categorical levels:\n\n\n█─pull_facet_cols \n├─█─pull_binary_cols \n├─█─select_class \n│ └─█─is_class \n└─█─make_facet_vec \n  └─█─check_facet_vec \n    ├─█─check_chr_facet \n    └─█─check_fct_facet"
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html#test-tools",
    "href": "posts/p1-tests-unit-tests/index.html#test-tools",
    "title": "Behavior Driven Unit Tests",
    "section": "Test tools",
    "text": "Test tools\nBefore we can start developing the tests for pull_cols(), we’ll need data. We can define test data inside the it() call for select_class():\n\ndescribe(\"select_class() returned objects\", code = {\n  it(\"df returned\", {\n    # define test data\n    test_data &lt;- data.frame(\n      log_var = c(TRUE, FALSE, TRUE),\n      int_var = c(1L, 2L, 3L),\n      dbl_var = c(1.1, 2.2, 3.3),\n      chr_var = paste0(rep(\"item:\", times = 3), 1:3))\n  })\n})\n\nThis is helpful because it’s clear what test_data contains, and many times a small dataset will suffice. However, larger, more complex test data should be stored as a test fixture.\n\nTest fixtures\nCreating test fixtures is covered in R packages, but I’ll summarize the key points:\n\nTest data (and other objects) can either be created within a test, or as a persistent test fixture\nTest data fixtures should be stored in tests/testthat/fixtures/&lt;test_data.rds&gt;\nThe code used to create any test data fixtures should be stored in the same folder with a make_ prefix (i.e., tests/testthat/fixtures/&lt;make_test_data.R&gt;)\n\nThis is easier to picture with a demonstration: In the tests/testthat/ folder, I’ll create a new fixtures folder, and add a make_test_data.R file.8\ntests/testthat/\n        └── fixtures/\n                └── make_test_data.R\nIn make_test_data.R, I’ll create test_data using the code above and save test_data in tests/testthat/fixtures/ as test_data.rds:\ntests/testthat/\n        └── fixtures/\n                ├── make_test_data.R\n                └── test_data.rds\nTo load the data into my test, I’ll add the following to the top of the test context:\n\ndescribe(\"select_class() returned objects\", code = {\n  \n  test_data &lt;- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n  \n})\n\ntestthat::test_path() will load the data from the testing directory when I’m ready to run my test.\nThe select_class() function should also be able to return a data.frame/tibble of the specified class, or a named vector of the column names. testthat’s expect_* functions have a lot of options for writing very specific tests.\n\ndescribe(\"select_class() returned objects\", code = {\n  \n  it(\"df returned\", {\n    # define/load test data\n    expect_s3_class(object, \"data.frame\")\n  })\n  \n  it(\"tibble returned\", {\n    # define/load test data\n    expect_s3_class(object,\n      class = c(\"tbl_df\", \"tbl\", \"data.frame\")\n    )\n  })\n  \n  it(\"string returned\", {\n    # define/load test data\n    expect_type(object = object, type = \"character\")\n  })\n  \n  it(\"named vector returned\", {\n    # define/load test data\n    expect_named(object = object, expected = \"log_var\")\n  })\n})\n\nselect_class() should also return the columns according to the class argument. For the logical, integer, double, character, and list columns, we can assess each returned object with expect_type(). However, with the factor and ordered columns, we’ll use the expect_s3_class().\n\n\nshow/hide select_class() tests\n# check classes ----\ndescribe(\"select_class() return classes\", code = {\n  ## check logical ----\n    it(\"logical works\", {\n      test_data &lt;- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n      # define obj\n      obj &lt;- select_class(df = test_data, class = \"logical\")\n      # test type\n      expect_type(obj[[1]], type = \"logical\")\n    })\n    ## check integer ----\n    it(\"integer works\", {\n      # integer test code\n      })\n  ## check double ----\n    it(\"double works\", {\n      # double test code\n    })\n  ## check character ----\n    it(\"character works\", {\n      # character test code\n    })\n    ## check list ----\n    it(\"list works\", {\n      # list test code\n    })\n  ## check factor ----\n    it(\"factor works\", {\n      test_data &lt;- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n      obj &lt;- select_class(df = test_data, class = \"factor\")\n      expect_s3_class(obj[[1]], class = \"factor\")\n    })\n  ## check factor (ordered) ----\n    it(\"ordered works\", {\n      # ordered factor test code\n    })\n\n})\n\n\nUsing describe() and it() allows us to outline tests for select_class(), and including test fixtures makes it easier to test all possible classes returned.\nWhen we’ve covered my intended ‘end results’ for select_class() (i.e., what we expect to happen when it works and we expect to happen when it doesn’t), we cam write the function:\n\n\nselect_column_class()\nselect_class &lt;- function(df, class, return_tbl = TRUE) {\n  if (!is.data.frame(df)) stop(\"df must be a dataframe\")\n\n  # define classes\n  valid_classes &lt;- c(\"logical\", \"integer\", \"double\", \"numeric\", \"character\",\n                     \"factor\", \"ordered\", \"list\")\n  class &lt;- match.arg(class, choices = valid_classes, several.ok = TRUE)\n\n  # helper function to check classes\n  is_class &lt;- function(x, cls) {\n    cls &lt;- match(cls, valid_classes)\n    cls_name &lt;- valid_classes[cls]\n    switch(cls_name,\n           logical = is.logical(x),\n           integer = is.integer(x),\n           double = is.double(x),\n           numeric = is.numeric(x),\n           character = is.character(x),\n           factor = is.factor(x),\n           ordered = is.ordered(x),\n           list = is.list(x),\n           FALSE)\n  }\n\n  selected_cols &lt;- sapply(df, function(x) any(sapply(class, is_class, x = x)))\n\n  col_names &lt;- names(df)[selected_cols]\n\n  if (return_tbl) {\n    return(df[, col_names, drop = FALSE])\n  } else {\n    return(setNames(object = col_names, nm = col_names))\n  }\n}\n\n\nBelow is a summary of tips for adding data your tests.\n\n\n\n\n\n\n\n\n\n(a) Unit test fixtures\n\n\n\n\n\nFigure 2: Unit test fixtures\n\n\n\n\n\nTest helpers\nTest helpers can be stored in tests/testthat/helper.R. Test helpers are functions or code that 1) is too long to repeat with each test, and 2) doesn’t take too much time or memory to run. Read more about test helpers here..\nFor this application, I’ve created a set of test helpers to make different forms of test data (because we’ll be repeatedly defining columns with slightly different attributes).\nFor example, col_maker() can be used to create a tibble with columns based on the col_type, size, and missing:\n\ncol_maker(col_type = c(\"log\", \"int\", \"dbl\", \n                       \"chr\", \"fct\", \"ord\"),\n          size = 3,\n          missing = TRUE)\n## # A tibble: 3 × 6\n##   log_var int_var dbl_var chr_var fct_var ord_var\n##   &lt;lgl&gt;     &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;fct&gt;   &lt;ord&gt;  \n## 1 TRUE          1     0.1 item:1  group 1 level 1\n## 2 FALSE        20    NA   &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n## 3 NA           NA     0.1 item:1  group 1 level 1\n\nI can also create tibbles with custom columns using individual helper _maker() functions:\n\ntibble::tibble(\n    log_var = log_maker(size = 3),\n    chr_var = chr_maker(size = 3, lvls = 3),\n    ord_var = ord_maker(size = 3, lvls = 2)\n)\n## # A tibble: 3 × 3\n##   log_var chr_var ord_var\n##   &lt;lgl&gt;   &lt;chr&gt;   &lt;ord&gt;  \n## 1 TRUE    item:1  level 1\n## 2 FALSE   item:2  level 2\n## 3 TRUE    item:3  level 1\n\nThese helpers make it easier to iterate through the test expectations and function development, because tibbles like the one above can be developed inside each test.\nBelow is an example for testing if pull_binary_cols() will correctly identify the logical columns (for both return objects):\n\n\nusing test helpers\ndescribe(\"pull_binary_cols() works\", {\n    it(\"logical tibble (with missing)\", code = {\n      test_data &lt;- tibble::tibble(log = log_maker(size = 2, missing = TRUE))\n      expect_equal(pull_binary_cols(test_data),\n      expected = c(log = \"log\"))\n    })\n    it(\"logical tibble\", code = {\n      test_data &lt;- tibble::tibble(log = log_maker(size = 2, missing = FALSE))\n      expect_equal(pull_binary_cols(test_data),\n      expected = c(log = \"log\"))\n    })\n})\n\n\nSometimes it will still make sense to create the test data inside the test scope (i.e. inside the it() or test_that() call). For example, I was pull_binary_cols() to identify integer columns with binary values (0, 1). I should make these test data explicit:\n\n\nusing test helpers\nit(\"test integer with binary values (0, 1, NA)\", code = {\n  test_data &lt;- data.frame(int = c(0L, 1L))\n  expect_equal(pull_binary_cols(test_data),\n  expected = c(int = \"int\"))\n})\nit(\"test integer with binary values and missing (0, 1, NA)\", code = {\n  test_data &lt;- data.frame(int = c(0L, 1L, NA_integer_))\n  expect_equal(pull_binary_cols(test_data),\n  expected = c(int = \"int\"))\n})\n\n\nWhen I’m confident with the pull_binary_cols() function and it’s tests, I’ll run devtools:::test_active_file().\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 9 ]\n\n\nTest coverage\nHow many tests should I write?\nIn testthat code coverage measures the extent to which the tests in the tests/testthat/ folder cover the possible execution paths of the functions in the R/ folder.\nCode test coverage is a way to confirm that the unit tests are robust enough to verify that your code behaves as expected. In R packages, code coverage is discussed in the testing chapter using the covr package.\nDuring development, check the code coverage of a test file with devtools::test_coverage_active_file(). Sometimes this function can be temperamental, so I use the combination of covr functions below:\n\ncovr::file_coverage(\n  source_files = \"R/&lt;function_file.R&gt;\", \n  test_files = \"tests/testthat/test-&lt;function_file.R&gt;\") |&gt;\n  covr::report()\n\nBelow is the test coverage for make_binary_vec()–a smaller helper function for pull_binary_cols()–in the Viewer when devtools::test_coverage_active_file() is entered in the Console:\n\n\n\n\n\n\n\n\n\n(a) Test coverage\n\n\n\n\n\nFigure 3: Unit test coverage interactively\n\n\n\nWe can see from the output we don’t have 100% test coverage for make_binary_vec(). When we click on the file path in the table we can se what execution paths aren’t being tested:\n\n\n\n\n\n\n\n\n\n(a) Behavior not tested in make_binary_vec()\n\n\n\n\n\nFigure 4: The area in red is the untested portion of make_binary_vec()\n\n\n\nIt’s probably not worth chasing down the remaining 17% on this function because I’ve outlined it’s primary requirements in the BDD functions:\n\ndescribe(\"make_binary_vec() works\", {\n    it(\"logical\", {\n      # test code\n    })\n  it(\"integer\", {\n      # test code\n    })\n  it(\"character\", {\n      # test code\n    })\n  it(\"factor\", {\n      # test code\n    })\n})\n\nStriving for a high percentage of coverage is a good practice, it doesn’t guarantee that the function always behaves as expected. Unit tests might execute a line of code, but still not catch a bug due to the design of the test (it’s easy to have high coverage if the unit tests are shallow and don’t check for any potential edge cases).\nAfter developing the functions in utap, the files in the R/ folder are organized into names based on the ‘main function and its supporting helpers’:\nR/\n├── check_binary_vec.R\n├── check_facet_vec.R\n├── make_binary_vec.R\n├── make_facet_vec.R\n├── nin.R\n├── pull_binary_cols.R\n├── pull_cat_cols.R\n├── pull_cols.R\n├── pull_facet_cols.R\n├── pull_numeric_cols.R\n├── select_class.R\n└── utap-package.R\nThe tests/testthat/ folder file names have identical names as the files in the R/ folder.\ntests\n├── testthat\n│   ├── _snaps\n│   ├── fixtures\n│   │   ├── make_test_data.R\n│   │   └── test_data.rds\n│   ├── helper.R\n│   ├── test-check_binary_vec.R\n│   ├── test-check_facet_vec.R\n│   ├── test-make_binary_vec.R\n│   ├── test-nin.R\n│   ├── test-pull_binary_cols.R\n│   ├── test-pull_cat_cols.R\n│   ├── test-pull_cols.R\n│   ├── test-pull_facet_cols.R\n│   ├── test-pull_numeric_cols.R\n│   └── test-select_class.R\n└── testthat.R\n\n4 directories, 14 files\nIt’s common for R packages to have a general R/utils.R file that defines the ‘utility’ functions, but these files can become a catch-all for any functions that don’t have a clear home (read more here).\nFor example, I could stored the %nin% operator in R/utils.R (but it removes the ability to run test_coverage_active_file():\nWhen I’ve completed a set of test files, I can use devtools::test() to check if they’re passing.\n\ndevtools::test()\n\n==&gt; devtools::test()\n\nℹ Testing utap\n✔ | F W  S  OK | Context\n✔ |         23 | check_binary_vec\n✔ |          3 | check_facet_vec\n✔ |          4 | make_binary_vec\n✔ |          3 | nin          \n✔ |          9 | pull_binary_cols\n✔ |          4 | pull_cat_cols\n✔ |          4 | pull_cols    \n✔ |         15 | pull_facet_cols\n✔ |          2 | pull_numeric_cols\n✔ |         14 | select_class \n\n══ Results ═══════════════════\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 81 ]\n\n🎯 Your tests hit the mark 🎯\nThe output above shows all tests are passing (and some helpful words of encouragement!). To check the code coverage for the utap package, I can run devtools::test_coverage() to view the output in the Viewer.\n\ndevtools::test_coverage()\n\nℹ Computing test coverage for utap\n\n\n\n\n\n\n\n\n\n(a) test_coverage() for entire package\n\n\n\n\n\nFigure 5: devtools::test_coverage()\n\n\n\nClicking on any of the Files will open the Source tab and give a summary like the one above from test_coverage_active_file(). I can also use covr::package_coverage() in the Console for simpler output:\n\n\n\n\n\n\n\n\n\n(a) package_coverage() for entire package\n\n\n\n\n\nFigure 6: covr::package_coverage()\n\n\n\n\n\n\n\n\n\nTipTIPS: Unit tests\n\n\n\n\n\n\nThe advice on unit tests below (in bold) comes from Effective Software Testing, 2022. I’ve included descriptions of how testthat satisfies each recommendation:\n\nUnit tests should be fast: the text recommends unit tests take a ‘couple of milliseconds’ to execute. testthat tests typically fall within this threshold (and provide time measurements to identify bottlenecks).\nUnit tests are easy to control: i.e., ‘input values and the expected result value are easy to adapt or modify in the test.’ testthat expectations give us ample access to 1) the expected result and 2) the observed result.\nUnit tests are easy to write: i.e., ‘do not require a complicated setup or additional work’. When used combination with usethis, testthat unit tests can be set up, created, written, and run with a few lines of code."
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html#other-code-metrics",
    "href": "posts/p1-tests-unit-tests/index.html#other-code-metrics",
    "title": "Behavior Driven Unit Tests",
    "section": "Other code metrics",
    "text": "Other code metrics\nSometimes it’s interesting to view the relationship between function size and number of tests using the cloc package..\n\nlibrary(cloc)\n\ncloc stands for Count Lines of Code, and it’s a rough metric used to gauge code complexity. It’s simple, but apparently provides “just as much predictive power as more elaborate constructs like cyclomatic complexity.”source\nBelow is a count of the lines of code in each file in the R folder:\n\ncloc::cloc_by_file(\"R\")\n\n# A tibble: 13 × 6\n   source filename                language   loc blank_lines comment_lines\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;chr&gt;    &lt;int&gt;       &lt;int&gt;         &lt;int&gt;\n 1 R      \"R/select_class.R\"      R           27           5            31\n 2 R      \"R/check_binary_vec.R\"  R           24           0            14\n 3 R      \"R/make_facet_vec.R\"    R           19           0            19\n 4 R      \"R/pull_numeric_cols.R\" R           19           1            23\n 5 R      \"R/pull_binary_cols.R\"  R           14           0            19\n 6 R      \"R/pull_facet_cols.R\"   R           14           0            37\n 7 R      \"R/check_facet_vec.R\"   R           13           0            14\n 8 R      \"R/pull_cat_cols.R\"     R           13           0            18\n 9 R      \"R/make_binary_vec.R\"   R           10           0            19\n10 R      \"R/pull_cols.R\"         R            8           0            15\n11 R      \"R/nin.R\"               R            3           0             9\n12 R      \"R/utap-package.R\"      R            2           0             6\n13 R      \"\"                      SUM        166           6           224\nThis output also confirms the relationship between lines of code and tests."
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html#recap",
    "href": "posts/p1-tests-unit-tests/index.html#recap",
    "title": "Behavior Driven Unit Tests",
    "section": "Recap",
    "text": "Recap\nThis post has been an introduction to unit testing utility functions in a Shiny app-package. When I’m confident the utility functions are working, I’ll start adding them into modules (and testing with testServer() or shinytest2). Files names can change a lot throughout the course of developing a Shiny app-package, so it’s helpful to adopt (or create) a naming convention.9\nWhich particular file naming convention you choose isn’t as important as adopting a convention and implementing it."
  },
  {
    "objectID": "posts/p1-tests-unit-tests/index.html#footnotes",
    "href": "posts/p1-tests-unit-tests/index.html#footnotes",
    "title": "Behavior Driven Unit Tests",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLearn more about R packages in R Packages, 2ed↩︎\nR Packages, 2ed also suggests binding test_active_file() and test_coverage_active_file() to keyboard shortcuts.↩︎\nRead more about behavior-driven development in BDD in Action, 2ed↩︎\ndescribe() and it() are discussed in the testthat documentation.↩︎\nThe variable names would automatically populate the choices argument for a selectInput()↩︎\ntestthat’s it() function is essentially identical to test_that().↩︎\nBoth functions are placed in R/select_class.R, and both unit tests are also in the tests/testthat/test-select_class.R file.↩︎\nThe fixtures name is not required, but it always make sense to keep folder names explicit.↩︎\nIf you’re using the golem framework to develop your shiny app-package, the utils_ and fct_ prefixes are used to define two different types of utility/helper functions. utils_ files contain ‘small helper functions and’top-level functions defining your user interface and your server function’. fct_ files contain ‘the business logic, which are potentially large functions…the backbone of the application and may not be specific to a given module’.↩︎"
  },
  {
    "objectID": "posts/purrr1.0/index.html",
    "href": "posts/purrr1.0/index.html",
    "title": "purrr updates (v1.0.0)",
    "section": "",
    "text": "show/hide\n# remotes::install_github(\"tidyverse/purrr\", \n#                   force = TRUE, quiet = TRUE)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(sloop)\nlibrary(stringr)\nlibrary(snakecase)\nlibrary(waldo)\nThis post is going to cover the recent updates to the purrr package. The release of version 1.0.0 (and dev version v1.0.1) had some breaking changes, which I will cover below. But first, I’ll dive into some attributes of R’s functions and objects that make purrr particularly useful, and I’ll work through iteration problems I’ve encountered (and solved with purrr)."
  },
  {
    "objectID": "posts/purrr1.0/index.html#generic-functions-s3-objects",
    "href": "posts/purrr1.0/index.html#generic-functions-s3-objects",
    "title": "purrr updates (v1.0.0)",
    "section": "Generic functions & S3 objects",
    "text": "Generic functions & S3 objects\nR’s syntax avoids explicit iteration by allowing certain generic functions to be used across different types (or objects). For example, the base plot() and summary() functions are S3 generic function:\n\n\n\nshow/hide\nsloop::ftype(plot)\n## [1] \"S3\"      \"generic\"\nsloop::ftype(summary)\n## [1] \"S3\"      \"generic\"\n\n\n\nWhich means plot() can be applied to S3 objects, like time-series (ts) and rectangular datasets (data.frame):\n\n\n\nshow/hide\nsloop::otype(datasets::LakeHuron)\n## [1] \"S3\"\nclass(datasets::LakeHuron)\n## [1] \"ts\"\nsloop::otype(datasets::chickwts)\n## [1] \"S3\"\nclass(datasets::chickwts)\n## [1] \"data.frame\"\n\n\n\n\nshow/hide\nsummary(datasets::LakeHuron)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   576.0   578.1   579.1   579.0   579.9   581.9\nsummary(datasets::chickwts)\n##      weight             feed   \n##  Min.   :108.0   casein   :12  \n##  1st Qu.:204.5   horsebean:10  \n##  Median :258.0   linseed  :12  \n##  Mean   :261.3   meatmeal :11  \n##  3rd Qu.:323.5   soybean  :14  \n##  Max.   :423.0   sunflower:12\n\n\n\nshow/hide\nplot(datasets::LakeHuron)\nplot(datasets::chickwts)\n\n\n\n\n\n\n\nTime-series plot\n\n\n\n\n\n\n\nScatter Plot\n\n\n\n\n\n\nsummary() is a particularly versatile function, because it can be used on data.frames, a single column in a data.frame, model outputs, and more.\n\nClick Code below to view an example using summary()\n\n\n\n\nshow/hide\n# get summary of columns ----------------------------------------------------\nsummary(mtcars$hp)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    52.0    96.5   123.0   146.7   180.0   335.0\nsummary(mtcars$mpg)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   10.40   15.43   19.20   20.09   22.80   33.90\n\n# store model output  -------------------------------------------------------\nlm_mod &lt;- lm(formula = mpg ~ hp, data = mtcars)\nlm_mod\n## \n## Call:\n## lm(formula = mpg ~ hp, data = mtcars)\n## \n## Coefficients:\n## (Intercept)           hp  \n##    30.09886     -0.06823\n\n# get summary of model output -----------------------------------------------\nsummary(lm_mod)\n## \n## Call:\n## lm(formula = mpg ~ hp, data = mtcars)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.7121 -2.1122 -0.8854  1.5819  8.2360 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 30.09886    1.63392  18.421  &lt; 2e-16 ***\n## hp          -0.06823    0.01012  -6.742 1.79e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.863 on 30 degrees of freedom\n## Multiple R-squared:  0.6024, Adjusted R-squared:  0.5892 \n## F-statistic: 45.46 on 1 and 30 DF,  p-value: 1.788e-07\n\n# pass the output from one S3 generic to another S3 generic -----------------\ncoef(summary(lm_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) 30.09886054  1.6339210 18.421246 6.642736e-18\n## hp          -0.06822828  0.0101193 -6.742389 1.787835e-07"
  },
  {
    "objectID": "posts/purrr1.0/index.html#fp-oop",
    "href": "posts/purrr1.0/index.html#fp-oop",
    "title": "purrr updates (v1.0.0)",
    "section": "FP + OOP",
    "text": "FP + OOP\n\nFunctional programming is complementary to object-oriented programming, which has been the dominant programming paradigm for the last several decades. - Advanced R, 2nd edition\n\nplot() and summary() are parametric polymorphic (generic) functions, which means they have slightly different behaviors based on the objects passed into them.\nAs I can see, generic functions are flexible and efficient because of not having to re-define a new function for each input object–outputs from generic functions will automatically change (in part) depending on the structure of the object provided to them.\nThe relationship between functions and objects is what makes purrr (and other tools for iteration) extremely helpful for solving iteration problems we commonly encounter when working with data. Similar to generic functions, these functions allow us to express iterative behavior using a complete and consistent set of tools."
  },
  {
    "objectID": "posts/purrr1.0/index.html#iteration-problems",
    "href": "posts/purrr1.0/index.html#iteration-problems",
    "title": "purrr updates (v1.0.0)",
    "section": "Iteration problems",
    "text": "Iteration problems\nIn programming, iteration refers to defining an input and applying an operation over every part of it. Some examples of problems that iteration can solve include:\n\nYou have a list of objects and you’d like to apply a function (or a series of functions) over the elements in the list\nYou have a folder full of files you’d like to rename or copy to a new directory\nYou’d like to download a collection of files from separate URLS\nYou have several years of data, and each year is contained in separate file. You’d like to read these data into R, combine them into a single dataset\nYou have a non-rectangular (i.e., list) of datasets you’d like to split into individual data.frames, then export these into separate file paths.\n\nThese are all problems I’ve personally encountered that required a variety of iteration tools to tackle. I’ll start with the first example because the principles remain the same (regardless of the size/scope of the problem):"
  },
  {
    "objectID": "posts/purrr1.0/index.html#lapply",
    "href": "posts/purrr1.0/index.html#lapply",
    "title": "purrr updates (v1.0.0)",
    "section": "lapply()",
    "text": "lapply()\nSticking with the my_list and tolower() example, the apply function I want is lapply() (pronounced ‘l-apply’), and the l stands for list.\nlapply() has only two required arguments:\n\nX the object we want to iterate over\nFUN being the function we want iterated\n\n\n\n\nshow/hide\nlapply(X = my_list, FUN = tolower)\n## $words\n## [1] \"move\"     \"thursday\" \"sister\"   \"join\"     \"last\"    \n## \n## $sentences\n## [1] \"the theft of the pearl pin was kept secret.\"    \n## [2] \"it snowed, rained, and hailed the same morning.\"\n## [3] \"it caught its hind paw in a rusty trap.\"        \n## \n## $letters\n##  [1] \"w\" \"g\" \"t\" \"q\" \"x\" \"s\" \"o\" \"p\" \"u\" \"l\""
  },
  {
    "objectID": "posts/purrr1.0/index.html#sapply",
    "href": "posts/purrr1.0/index.html#sapply",
    "title": "purrr updates (v1.0.0)",
    "section": "sapply()",
    "text": "sapply()\nsapply() attempts to simplify the result depending on the X argument. If X is a list containing vectors where every element has the same length (and it’s greater than 1), then sapply() returns a matrix:\n\n\n\nshow/hide\nstr(my_list[1])\n## List of 1\n##  $ words: chr [1:5] \"MOvE\" \"tHURsDAy\" \"SISter\" \"jOiN\" ...\nsapply(X = my_list[1], FUN = tolower)\n##      words     \n## [1,] \"move\"    \n## [2,] \"thursday\"\n## [3,] \"sister\"  \n## [4,] \"join\"    \n## [5,] \"last\"\n\n\n\nIf a vector is passed to X where every element is length 1, then a vector is returned:\n\n\n\nshow/hide\nstr(my_list[[1]])\n##  chr [1:5] \"MOvE\" \"tHURsDAy\" \"SISter\" \"jOiN\" \"lASt\"\nsapply(X = my_list[[1]], FUN = tolower) \n##       MOvE   tHURsDAy     SISter       jOiN       lASt \n##     \"move\" \"thursday\"   \"sister\"     \"join\"     \"last\"\n\n\n\nFinally, if X is a list where elements have a length greater than 1, then a list is returned (making it identical to lapply()\n\n\n\nshow/hide\nwaldo::compare(\n  x = sapply(X = my_list, FUN = tolower), \n  y = lapply(X = my_list, FUN = tolower)\n)\n## ✔ No differences\n\n\n\nThis is because sapply is a wrapper around lapply, but has simplify and USE.NAMES set to FALSE (see what happens below when I change them to TRUE)\n\n\n\nshow/hide\nwaldo::compare(\n  \n  x = lapply(X = my_list[[1]], FUN = tolower), \n  \n  y = sapply(X = my_list[[1]], FUN = tolower, \n              simplify = TRUE, USE.NAMES = TRUE)\n  \n  )\n## `old` is a list\n## `new` is a character vector ('move', 'thursday', 'sister', 'join', 'last')"
  },
  {
    "objectID": "posts/purrr1.0/index.html#anonmymous-functions",
    "href": "posts/purrr1.0/index.html#anonmymous-functions",
    "title": "purrr updates (v1.0.0)",
    "section": "Anonmymous functions",
    "text": "Anonmymous functions\nThe FUN argument can also take anonymous (undefined) functions. For example, if I wanted to access the second elements in my_list, I could pass an anonymous function the FUN (with the index):\n\n\n\nshow/hide\nlapply(X = my_list, FUN = function(x) x[[2]])\n## $words\n## [1] \"tHURsDAy\"\n## \n## $sentences\n## [1] \"iT snOWed, RAINEd, AND HaIled ThE samE MOrNiNG.\"\n## \n## $letters\n## [1] \"G\""
  },
  {
    "objectID": "posts/purrr1.0/index.html#vapply",
    "href": "posts/purrr1.0/index.html#vapply",
    "title": "purrr updates (v1.0.0)",
    "section": "vapply()",
    "text": "vapply()\nFinally vapply() is unique in that it always simplifies the returned output. If we repeat the example above, we see the returned value is character vector:\n\n\n\nshow/hide\nvapply(X = my_list, \n  FUN = function(x) x[[2]], \n  FUN.VALUE = character(1))\n##                                             words \n##                                        \"tHURsDAy\" \n##                                         sentences \n## \"iT snOWed, RAINEd, AND HaIled ThE samE MOrNiNG.\" \n##                                           letters \n##                                               \"G\"\n\n\n\nThe apply functions get us much further than writing for loops because we can 1) iterate over vectors and lists, 2) control the output objects, and 3) write less code. Unlike generic functions, apply functions are designed to work with specific object types, and return values depending on these objects.\nOne downside of apply functions is they don’t play well with data.frames or tibbles. However, we can control their return values (and manually supply these to tibble::tibble() or data.frame()\n\n\n\nshow/hide\ntibble::tibble(\n  words = vapply(X = my_list[[1]][1:3], \n                FUN = `[`, \n                FUN.VALUE = character(1)),\n  sentences = vapply(X = my_list[[2]][1:3], \n                    FUN = `[`, \n                    FUN.VALUE = character(1)),\n  letters = vapply(X = my_list[[3]][1:3], \n                  FUN = `[`, \n                  FUN.VALUE = character(1)))\n\n\n\nAnother downside of the apply functions is they’re not very uniform. Each function has slight variations in their arguments and rules for return values. This is where purrr comes in…"
  },
  {
    "objectID": "posts/purrr1.0/index.html#do-it-for-one-element",
    "href": "posts/purrr1.0/index.html#do-it-for-one-element",
    "title": "purrr updates (v1.0.0)",
    "section": "1. Do it for one element",
    "text": "1. Do it for one element\nThe goal with the first step is to get a minimal working example with a single element from the object I want to iterate over (with the function I want to iterate with).\nFor this example, I need to subset my_list for a single element at position [[1]], [[2]], or [[3]] (or using one of the vector names).\nI’ll then pass this element to tolower() and make sure it’s the desired behavior:\n\n# subset an element from the list\n? &lt;- my_list[[?]]\n# apply a function to extracted element\ntolower(?)\n\n\n? &lt;- my_list[[?]] = subset element from the list (my_list)\ntolower(?) = apply operation (i.e., function) to extracted element.\n\n\n\n\nshow/hide\nmy_words &lt;- my_list[['words']]\ntolower(my_words)\n## [1] \"move\"     \"thursday\" \"sister\"   \"join\"     \"last\"\n\n\n\nNow that I have a working example for one element, in the next step I’ll abstract these parts into the function arguments."
  },
  {
    "objectID": "posts/purrr1.0/index.html#turn-it-into-a-recipe",
    "href": "posts/purrr1.0/index.html#turn-it-into-a-recipe",
    "title": "purrr updates (v1.0.0)",
    "section": "2. Turn it into a recipe",
    "text": "2. Turn it into a recipe\nA standard purrr recipe defines .x (the object) and .f (the function), followed by any additional function arguments.\n\n.x = a list or atomic vector\n.f = the function we want to apply over every element in .x\n\n\n.x = my_list, .f = tolower"
  },
  {
    "objectID": "posts/purrr1.0/index.html#map-it-across-all-elements",
    "href": "posts/purrr1.0/index.html#map-it-across-all-elements",
    "title": "purrr updates (v1.0.0)",
    "section": "3. map() it across all elements",
    "text": "3. map() it across all elements\nIn purrr::map(), the .x argument is the object (list or atomic vector) I want to iterate over, and .f is the function (i.e., operation) I want applied to every element of .x\nIf I want to convert the case of every element in my_list to lowercase with tolower() I would use the following standard purrr::map() format:\n\n\n\nshow/hide\npurrr::map(.x = my_list, .f = tolower)\n## $words\n## [1] \"move\"     \"thursday\" \"sister\"   \"join\"     \"last\"    \n## \n## $sentences\n## [1] \"the theft of the pearl pin was kept secret.\"    \n## [2] \"it snowed, rained, and hailed the same morning.\"\n## [3] \"it caught its hind paw in a rusty trap.\"        \n## \n## $letters\n##  [1] \"w\" \"g\" \"t\" \"q\" \"x\" \"s\" \"o\" \"p\" \"u\" \"l\"\n\n\n\nAnd there you have it! map() is the core function and workhorse of the purrr package. It’s important to note that purrr::map() always returns a list, regardless of the object supplied to .x."
  },
  {
    "objectID": "posts/purrr1.0/index.html#map-updates",
    "href": "posts/purrr1.0/index.html#map-updates",
    "title": "purrr updates (v1.0.0)",
    "section": "map() updates",
    "text": "map() updates\nAs noted above, by default purrr::map() returns a list. If I’d like to return a vector, I can use one of the map_ variations (there’s one for each vector type).\n\nBy mapping the is.&lt;type&gt;() functions the elements in mixed_list, I can test which elements in mixed_list return TRUE:\n\nmap_lgl(): returns a logical vector\n\n\n\n\nshow/hide\nmixed_list |&gt; purrr::map_lgl(\\(x) is.logical(x))\n\n\nbooleans integers  doubles  strings    dates \n    TRUE    FALSE    FALSE    FALSE    FALSE \n\n\n\n\nmap_int(): returns an integer vector\n\n\n\n\nshow/hide\nmixed_list |&gt; purrr::map_int(\\(x) is.integer(x))\n\n\nbooleans integers  doubles  strings    dates \n       0        1        0        0        0 \n\n\n\n\nmap_dbl(): returns a double vector\n\n\n\n\nshow/hide\nmixed_list |&gt; purrr::map_dbl(\\(x) is.double(x))\n\n\nbooleans integers  doubles  strings    dates \n       0        0        1        0        1 \n\n\n\n\nmap_chr(): returns a character vector\n\n\n\n\nshow/hide\nmixed_list |&gt; purrr::map_chr(\\(x) is.character(x))\n\n\nWarning: Automatic coercion from logical to character was deprecated in purrr 1.0.0.\nℹ Please use an explicit call to `as.character()` within `map_chr()` instead.\n\n\nbooleans integers  doubles  strings    dates \n \"FALSE\"  \"FALSE\"  \"FALSE\"   \"TRUE\"  \"FALSE\" \n\n\n\n\nWhen we test for characters in mixed_list, we see the following warning:\n\n\nWarning: Automatic coercion from logical to character was deprecated in purrr 1.0.0. Please use an explicit call to as.character() within map_chr() instead\n\n\nAs we can see from the output above, the logical return values from is.character() are coerced to characters (this behavior is now deprecated).\n\nmap_vec()\n\nHowever, the previous purrr::map_raw() function has been replaced with purrr::map_vec(), which “simplifies to the common type of the output.” I’ll demonstrate below with the characters in mixed_list:\n\n\n\nshow/hide\nmixed_list |&gt; purrr::map_vec(\\(x) is.character(x))\n## booleans integers  doubles  strings    dates \n##    FALSE    FALSE    FALSE     TRUE    FALSE\n\n\n\nNotice the difference in output? The results are the same as above, but output is not commented (##). The same is true when I test the dates in mixed_list using lubridate::is.Date():\n\n\n\nshow/hide\nmixed_list |&gt; purrr::map_vec(\\(x) lubridate::is.Date(x))\n## booleans integers  doubles  strings    dates \n##    FALSE    FALSE    FALSE    FALSE     TRUE"
  },
  {
    "objectID": "posts/purrr1.0/index.html#anonymous-functions",
    "href": "posts/purrr1.0/index.html#anonymous-functions",
    "title": "purrr updates (v1.0.0)",
    "section": "Anonymous functions",
    "text": "Anonymous functions\nR introduced the shorthand anonymous function syntax in version 4.1.0:\n\n“\\(x) x + 1 is parsed as function(x) x + 1.”\n\nBelow is a comparison of an anonymous (unnamed) function and the updated shorthand syntax:\n\nStandard anonymous function\n\n\n\nshow/hide\n(function(x) tolower(x))(\"pIrAtES Ship\")\n## [1] \"pirates ship\"\n\n\n\nThe updated anonymous syntax is below:\n\n\n\nshow/hide\n(\\(x) tolower(x))(\"pIrAtES Ship\")\n## [1] \"pirates ship\"\n\n\n\n\nWriting the code above using an anonymous function would look like this:\n\n\n\nshow/hide\nmy_list |&gt; purrr::map(\\(x) tolower(x))\n## $words\n## [1] \"move\"     \"thursday\" \"sister\"   \"join\"     \"last\"    \n## \n## $sentences\n## [1] \"the theft of the pearl pin was kept secret.\"    \n## [2] \"it snowed, rained, and hailed the same morning.\"\n## [3] \"it caught its hind paw in a rusty trap.\"        \n## \n## $letters\n##  [1] \"w\" \"g\" \"t\" \"q\" \"x\" \"s\" \"o\" \"p\" \"u\" \"l\"\n\n\n\nAnonymous functions make it easier to understand which arguments belong to which function and will tend to yield better error messages.\nI’ll confirm the outputs from both methods are identical using waldo::compare():\n\n\n\nshow/hide\nwaldo::compare(\n  x = purrr::map(.x = my_list, .f = tolower), \n  y = my_list |&gt; purrr::map(\\(x) tolower(x)))\n## ✔ No differences\n\n\n\n\n\n\n\n\n\nImportantThe formula (~ .x + 1)\n\n\n\n\n\nPrior to purrr v1.0.0, I could also use the formula syntax, but now it’s “only recommended if you require backward compatibility with older versions of R.” I’ll cover the formula syntax briefly because you’re likely to encounter it.\n\n\nThe formula syntax is typically used with pipes, so the contents of purrr::map() become the right-hand side of the formula, with the function we want to iterate (&lt;FUNCTION&gt;) and a placeholder (.x) in the appropriate argument.\n\n\n&lt;OBJECT&gt; |&gt; purrr::map(~ &lt;FUNCTION&gt;(.x))\n\n\nFor the example above, my_list is ‘piped’ to purrr::map(), where the formula maps the tolower() function (using the .x placeholder).\n\n\n# written as normal expression\n my_list |&gt; purrr::map(~ tolower(.x))\n\n\nJenny Bryan offers a great description on her purrr tutorial,\n\n“[formula syntax] should start with the ~ symbol and then look like a typical top-level expression, as you might write in a script. Use .x to refer to the input, i.e. an individual element of the primary vector or list.”\n\nI can double-check to see that the output from two variations are identical using waldo::compare().\n\n\n\n\nshow/hide\nwaldo::compare(\n  x = my_list |&gt; purrr::map(\\(x) tolower(x)), \n  y = my_list |&gt; purrr::map(~ tolower(.x)))\n## ✔ No differences"
  },
  {
    "objectID": "posts/purrr1.0/index.html#downloading-files",
    "href": "posts/purrr1.0/index.html#downloading-files",
    "title": "purrr updates (v1.0.0)",
    "section": "Downloading files",
    "text": "Downloading files\n\nYou’d like to download a collection of files from separate URLS\n\nI have a collection of 30 .csv files from Doing Data Science by Cathy O’Neil and Rachel Schutt (O’Reilly Media) in a GitHub repo. Let’s assume I want to download one week of these files into my RStudio session (without downloading the repo).\nI’ll navigate to the raw url for the first data file (nyt1.csv), then paste this into a character vector:\n\n\n\nshow/hide\nnyt_url &lt;- \"https://raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt1.csv\"\n\n\n\nKnowing that all of the files on GitHub with have a similar sheme and domain, I can use nyt_url to generate urls for each of the 7 files.\n\nFirst I get the folder of the files on GitHub with fs::path_dir()\n\n\n\n\nshow/hide\n# create file urls \nnyt_dir_url &lt;- fs::path_dir(nyt_url)\nnyt_dir_url\n\n\n[1] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main\"\n\n\n\n\nI create a vector with the 7 file names\n\n\n\n\nshow/hide\n# create file names for 7th through 13th\nnyt_file_nms &lt;- paste0(\"nyt\", 7:13, \".csv\")\nnyt_file_nms\n\n\n[1] \"nyt7.csv\"  \"nyt8.csv\"  \"nyt9.csv\"  \"nyt10.csv\" \"nyt11.csv\" \"nyt12.csv\"\n[7] \"nyt13.csv\"\n\n\n\n\nI combine the directory portion of the url with file name in nyt_file_urls\n\n\n\n\nshow/hide\n# combine\nnyt_file_urls &lt;- paste(nyt_dir_url, nyt_file_nms, sep = \"/\")\nnyt_file_urls\n\n\n[1] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt7.csv\" \n[2] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt8.csv\" \n[3] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt9.csv\" \n[4] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt10.csv\"\n[5] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt11.csv\"\n[6] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt12.csv\"\n[7] \"https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt13.csv\"\n\n\n\nI’ll need another vector of destination file names on my local machine, which I can do by combining the file names (nyt_file_nms) with the local destination folder (dds-nyt).\n\n\n\nshow/hide\nnyt_local_pths &lt;- paste(\"dds-nyt\", nyt_file_nms, sep = \"/\")\nnyt_local_pths\n\n\n[1] \"dds-nyt/nyt7.csv\"  \"dds-nyt/nyt8.csv\"  \"dds-nyt/nyt9.csv\" \n[4] \"dds-nyt/nyt10.csv\" \"dds-nyt/nyt11.csv\" \"dds-nyt/nyt12.csv\"\n[7] \"dds-nyt/nyt13.csv\"\n\n\n\nAfter creating the destination folder, I’ll use the download.file() function to test downloading a single .csv files into my local folder (dds-nyt/). download.file() has a progress bar which tells me if the file downloaded successfully.\n\n\nshow/hide\n# do it for one\nfs::dir_create(\"dds-nyt\")\ndownload.file(url = nyt_file_urls[1], destfile = nyt_local_pths[1])\n\ntrying URL 'https:/raw.githubusercontent.com/mjfrigaard/dds-data/main/nyt1.csv'\nContent type 'text/plain; charset=utf-8' length 4920381 bytes (4.7 MB)\n==================================================\ndownloaded 4.7 MB\n\ndownload.file() takes two inputs (url and destfile), which changes the recipe a bit, because I need a purrr function with the following:\n\n.x the input vector of existing url paths\n.y the output vector of destination file paths\nAdditional arguments passed from download.file() (like quiet = TRUE)\n\nIn this case, I don’t need purrr to return value–I just need the purrr function to iterate over the items and write them to the new location.\nwalk() is ideal for this circumstance:\n\n“walk() returns the input .x (invisibly)” and “The return value of .f() is ignored”\n\nWhat do ‘return .x invisibly’ and ‘the side-effect of .f’ mean?\n\nReturn invisibly\nThe previous purrr functions I covered varied in the kinds of values they returned (lists vs. vectors), but for some operations I won’t need a return value. If I’m ever curious about whether I should be using map() or walk(), I’ll ask myself, “would it make sense to assign the output from this function to an object?”\nIf the answer is no, then I probably need to be thinking walk() instead of map()\n\n\nSide-effects\nIn the help documentation walk()’s description states, “calls .f for its side-effect”, which can be generally interpreted as, “there’s nothing to assign the output from that function to.”\n\n\npurrr progress bars\nI’ll use walk2() below and add .progress = TRUE to view the purrr progress bar (and quiet = TRUE to silence the download.file() progress bar).\n\n\n\nshow/hide\nwalk2(.x = nyt_file_urls, .y = nyt_local_pths, .f =  download.file, \n      .progress = TRUE, quiet = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI can confirm the download using fs::dir_tree()\n\n\n\nshow/hide\nfs::dir_tree(\"dds-nyt\")\n## dds-nyt\n## ├── nyt10.csv\n## ├── nyt11.csv\n## ├── nyt12.csv\n## ├── nyt13.csv\n## ├── nyt7.csv\n## ├── nyt8.csv\n## └── nyt9.csv"
  },
  {
    "objectID": "posts/purrr1.0/index.html#copying-a-directory-of-files",
    "href": "posts/purrr1.0/index.html#copying-a-directory-of-files",
    "title": "purrr updates (v1.0.0)",
    "section": "Copying a directory of files",
    "text": "Copying a directory of files\n\nYou have a folder of files you’d like to rename or copy to a new directory\n\nThe collection of 7 .csv files from Doing Data Science by Cathy O’Neil and Rachel Schutt (O’Reilly Media) are now in the dds-nyt/ folder.\nAs with any project, I don’t want to alter the raw data, so I’m going to copy these files into dds-nyt-raw/ and dds-nyt-processed/. I also want the processed file names to have a date stamp prefix.\n\n\n\nshow/hide\nfile_pths &lt;- list.files(\"dds-nyt\", full.names = TRUE, pattern = \".csv$\")\nfile_pths\n## [1] \"dds-nyt/nyt10.csv\" \"dds-nyt/nyt11.csv\" \"dds-nyt/nyt12.csv\"\n## [4] \"dds-nyt/nyt13.csv\" \"dds-nyt/nyt7.csv\"  \"dds-nyt/nyt8.csv\" \n## [7] \"dds-nyt/nyt9.csv\"\n\n\n\nI’ll start with the raw data folder. I need to create a vector of the new raw file paths and names: raw_file_pths (the raw data paths will have the original file names)\n\n\n\nshow/hide\n# do it for one\ngsub(pattern = \"^dds-nyt\",\n  replacement = \"dds-nyt/raw\",\n  x = file_pths[1])\n## [1] \"dds-nyt/raw/nyt10.csv\"\n\n# write the recipe\nfile_pths |&gt; purrr::map_chr(\\(x) gsub(x, \n                                pattern = \"^dds-nyt\", \n                                replacement = \"dds-nyt/raw\")) |&gt; head()\n## [1] \"dds-nyt/raw/nyt10.csv\" \"dds-nyt/raw/nyt11.csv\" \"dds-nyt/raw/nyt12.csv\"\n## [4] \"dds-nyt/raw/nyt13.csv\" \"dds-nyt/raw/nyt7.csv\"  \"dds-nyt/raw/nyt8.csv\"\n\n# map it across all\nraw_file_pths &lt;- file_pths |&gt; \n                  purrr::map_chr(\\(x) gsub(x, \n                                        pattern = \"^dds-nyt\", \n                                        replacement = \"dds-nyt/raw\"))\n\n\n\nBefore copying the files, I need to create the destination folder for the raw data (dds-nyt/raw). Then, I’ll make sure I can copy the first element from file_pths into the path in the first element of raw_file_pths:\n\n\n\nshow/hide\nfs::dir_create(\"dds-nyt/raw\")\n# do it for one\nfs::file_copy(\n  path = file_pths[1], \n  new_path = raw_file_pths[1], \n  overwrite = TRUE)\nfs::dir_tree(\"dds-nyt/raw\", type = \"any\")\n## dds-nyt/raw\n## └── nyt10.csv\n\n\n\nI can see this is working, so I can use purrr::walk2() to move all the files from dds-nyt/ to dds-nyt/raw/\n\n\n\nshow/hide\npurrr::walk2(.x = file_pths, .y = raw_file_pths, .f = fs::file_copy, \n      .progress = TRUE, overwrite = TRUE)\nfs::dir_tree(\"dds-nyt/raw\", type = \"any\")\n## dds-nyt/raw\n## ├── nyt10.csv\n## ├── nyt11.csv\n## ├── nyt12.csv\n## ├── nyt13.csv\n## ├── nyt7.csv\n## ├── nyt8.csv\n## └── nyt9.csv\n\n\n\nNow that I’ve copied the files into their respective folders, I’ll need to remove the files from their original location in the parent dds-nyt folder.\nFortunately, I have a vector of these files in file_pths, and I can test removal with fs::file_delete():\n\n\n\nshow/hide\nfs::file_delete(file_pths[1])\n\n\n\nGreat! Now that I know this will work, I’ll use walk() because I want .x returned invisibly and the side-effect of .f.\nBut I’ve also deleted the first element in file_pths, so when fs::file_delete() goes looking for that file, it will find nothing and returned an error.\n\n\n\nshow/hide\nError in `map()`:\nℹ In index: 1.\nCaused by error:\n! [ENOENT] Failed to remove 'dds-nyt/nyt10.csv': no such file or directory\n\n\n\nI can protect against this by supplying the output from list.files() directly to purrr::walk2(), but include a pattern so it only matches the .csv files.\n\n\n\nshow/hide\npurrr:::walk(\n  # list CURRENT files \n    .x = list.files(\n      path = \"dds-nyt\",\n      pattern = \".csv$\",\n      full.names = TRUE),\n    # map function\n    .f = fs::file_delete)\n\n\n\nAnd confirm the new folder contents and structure\n\n\n\nshow/hide\nfs::dir_tree(\"dds-nyt\", type = \"any\", recurse = TRUE)\n## dds-nyt\n## └── raw\n##     ├── nyt10.csv\n##     ├── nyt11.csv\n##     ├── nyt12.csv\n##     ├── nyt13.csv\n##     ├── nyt7.csv\n##     ├── nyt8.csv\n##     └── nyt9.csv"
  },
  {
    "objectID": "posts/purrr1.0/index.html#import-multiple-datasets",
    "href": "posts/purrr1.0/index.html#import-multiple-datasets",
    "title": "purrr updates (v1.0.0)",
    "section": "Import multiple datasets",
    "text": "Import multiple datasets\n\nYou have several days of data, and each day is contained in separate file. You’d like to read these data into R, and combine them into a single dataset\n\nNow that I have separate raw and processed folders, I can import the NYT data into R. Below I’ve imported a single file from the raw data folder to examine it’s contents:\n\n\n\nshow/hide\nnyt1 &lt;- vroom::vroom(file = raw_file_pths[1],\n  delim = \",\", \n  show_col_types = FALSE)\nstr(nyt1)\n## spc_tbl_ [452,766 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ Age        : num [1:452766] 59 0 19 44 30 33 41 41 0 23 ...\n##  $ Gender     : num [1:452766] 1 0 0 1 1 1 0 0 0 1 ...\n##  $ Impressions: num [1:452766] 4 7 5 5 4 3 1 3 9 1 ...\n##  $ Clicks     : num [1:452766] 0 1 0 0 0 0 0 0 1 0 ...\n##  $ Signed_In  : num [1:452766] 1 0 1 1 1 1 1 1 0 1 ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   Age = col_double(),\n##   ..   Gender = col_double(),\n##   ..   Impressions = col_double(),\n##   ..   Clicks = col_double(),\n##   ..   Signed_In = col_double(),\n##   ..   .delim = \",\"\n##   .. )\n##  - attr(*, \"problems\")=&lt;externalptr&gt;\n\n\n\nEach nyt file contains daily ads shown and clicks recorded on the New York Times home page. The rows represent users, and the variables are: Age, Gender (0 = female, 1 = male), Impressions (number impressions), Clicks (number clicks), and a binary indicator for signed in or not Signed_in.\nI’ll add some hypothetical wrangling steps to make this example more realistic.\n\nCreate age_group, an ordered factor which contains six levels of Age (“&lt;18”, “18-24”, “25-34”, “35-44”, “45-54”, “55-64”, and “65+”)\nCreate ctr_rate or click-through rate, calculated as the number of clicks / the number of impressions. Round it to 3 digits.\nCreate female, a factor version of Gender, where when Gender = 0, then female = \"yes\", and when Gender = 1, then female = \"no\"\nCreate signed_in, a factor variable with levels \"no\" and \"yes\" from the Signed_In = 0 and 1\n\nI’ve bundled all of these steps into a function (nyt_data_processing()) that I can pass each dataset through:\n\n\n\nshow/hide\nnyt_data_processing &lt;- function(nyt_csv) {\n  orig_nms &lt;- c(\"Age\", \"Gender\", \"Impressions\", \"Clicks\", \"Signed_In\")\n  nyt_nms &lt;- names(nyt_csv)\n  if (isFALSE(identical(x = orig_nms, y = nyt_nms))) {\n    cli::cli_abort(\"these data don't have the correct columns!\")\n  } else {\n    nyt_proc &lt;- nyt_csv |&gt;\n      dplyr::mutate(\n        # create age_group variable\n        age_group = case_when(\n          Age &lt; 18 ~ \"&lt;18\",\n          Age &gt;= 18 & Age &lt; 25 ~ \"18-24\",\n          Age &gt;= 25 & Age &lt; 35 ~ \"25-34\",\n          Age &gt;= 35 & Age &lt; 45 ~ \"35-44\",\n          Age &gt;= 45 & Age &lt; 55 ~ \"45-54\",\n          Age &gt;= 55 & Age &lt; 65 ~ \"55-64\",\n          Age &gt;= 65 ~ \"65+\"\n        ),\n        # factor age_group (ordered)\n        age_group = factor(age_group,\n          levels = c(\n            \"&lt;18\", \"18-24\", \"25-34\",\n            \"35-44\", \"45-54\", \"55-64\", \"65+\"\n          ),\n          ordered = TRUE\n        ),\n        # create CTR variable\n        ctr_rate = round(x = Clicks / Impressions, digits = 3),\n        # create new Female variable\n        female = case_when(\n          Gender == 0 ~ \"yes\",\n          Gender == 1 ~ \"no\",\n          TRUE ~ NA_character_\n        ),\n        # factor female (un-ordered)\n        female = factor(female,\n          levels = c(\"no\", \"yes\")\n        ),\n        Signed_In = case_when(\n          Signed_In == 0 ~ \"no\", \n          Signed_In == 1 ~ \"yes\", \n          TRUE ~ NA_character_),\n        # factor Signed_In (un-ordered) \n        Signed_In = factor(Signed_In, levels = c(\"no\", \"yes\"))) |&gt;\n      # format columns\n      janitor::clean_names()\n  }\n  return(nyt_proc)\n}\n\n\n\nI’ll do some quick checks to make sure it only works with the raw data columns:\n\n\n\nshow/hide\nnyt1_proc &lt;- nyt_data_processing(nyt1)\nstr(nyt1_proc)\n## spc_tbl_ [452,766 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ age        : num [1:452766] 59 0 19 44 30 33 41 41 0 23 ...\n##  $ gender     : num [1:452766] 1 0 0 1 1 1 0 0 0 1 ...\n##  $ impressions: num [1:452766] 4 7 5 5 4 3 1 3 9 1 ...\n##  $ clicks     : num [1:452766] 0 1 0 0 0 0 0 0 1 0 ...\n##  $ signed_in  : Factor w/ 2 levels \"no\",\"yes\": 2 1 2 2 2 2 2 2 1 2 ...\n##  $ age_group  : Ord.factor w/ 7 levels \"&lt;18\"&lt;\"18-24\"&lt;..: 6 1 2 4 3 3 4 4 1 2 ...\n##  $ ctr_rate   : num [1:452766] 0 0.143 0 0 0 0 0 0 0.111 0 ...\n##  $ female     : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 1 1 1 2 2 2 1 ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   Age = col_double(),\n##   ..   Gender = col_double(),\n##   ..   Impressions = col_double(),\n##   ..   Clicks = col_double(),\n##   ..   Signed_In = col_double(),\n##   ..   .delim = \",\"\n##   .. )\n##  - attr(*, \"problems\")=&lt;externalptr&gt;\n\n\n\nI’ll run nyt_data_processing() against a processed data file (nyt1_proc)\n\n\n\nshow/hide\nnyt_data_processing(nyt1_proc)\n## Error in `nyt_data_processing()`:\n## ! these data don't have the correct columns!\n\n\n\nNow I’m ready to write the import step. First I’ll store the raw file paths in raw_data_pths\n\n\n\nshow/hide\nraw_data_pths &lt;- list.files(path = \"dds-nyt/raw\", pattern = \".csv$\", full.names = TRUE)\n\n\n\nWe’ll test purrr::map() and vroom::vroom() to import the .csv files in raw_data_pths into a list. I also add utils::head() and dplyr::glimpse() to limit the output.\n\n\n\nshow/hide\nraw_data_pths |&gt; \n  # import\n  purrr::map(\n    vroom::vroom, \n        delim = \",\", show_col_types = FALSE) |&gt; \n  utils::head(2) |&gt; \n  dplyr::glimpse()\n## List of 2\n##  $ : spc_tbl_ [452,766 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##   ..$ Age        : num [1:452766] 59 0 19 44 30 33 41 41 0 23 ...\n##   ..$ Gender     : num [1:452766] 1 0 0 1 1 1 0 0 0 1 ...\n##   ..$ Impressions: num [1:452766] 4 7 5 5 4 3 1 3 9 1 ...\n##   ..$ Clicks     : num [1:452766] 0 1 0 0 0 0 0 0 1 0 ...\n##   ..$ Signed_In  : num [1:452766] 1 0 1 1 1 1 1 1 0 1 ...\n##   ..- attr(*, \"spec\")=\n##   .. .. cols(\n##   .. ..   Age = col_double(),\n##   .. ..   Gender = col_double(),\n##   .. ..   Impressions = col_double(),\n##   .. ..   Clicks = col_double(),\n##   .. ..   Signed_In = col_double(),\n##   .. ..   .delim = \",\"\n##   .. .. )\n##   ..- attr(*, \"problems\")=&lt;externalptr&gt; \n##  $ : spc_tbl_ [478,066 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##   ..$ Age        : num [1:478066] 28 51 29 20 19 0 58 42 35 44 ...\n##   ..$ Gender     : num [1:478066] 1 0 1 1 0 0 0 0 1 0 ...\n##   ..$ Impressions: num [1:478066] 8 5 2 4 5 3 5 6 8 4 ...\n##   ..$ Clicks     : num [1:478066] 0 0 0 0 0 1 1 0 0 0 ...\n##   ..$ Signed_In  : num [1:478066] 1 1 1 1 1 0 1 1 1 1 ...\n##   ..- attr(*, \"spec\")=\n##   .. .. cols(\n##   .. ..   Age = col_double(),\n##   .. ..   Gender = col_double(),\n##   .. ..   Impressions = col_double(),\n##   .. ..   Clicks = col_double(),\n##   .. ..   Signed_In = col_double(),\n##   .. ..   .delim = \",\"\n##   .. .. )\n##   ..- attr(*, \"problems\")=&lt;externalptr&gt;\n\n\n\nThis returns a list, but you may have noticed I don’t have a great way for keeping track of the data files in the list–this is where purrr::set_names() comes in handy.\npurrr::set_names() works a lot like names(), but purrr::set_names() will automatically set the names of x to as.character(x) if no names are provided to nm. See below:\n\n\n\nshow/hide\nraw_data_pths |&gt; purrr::set_names()\n##   dds-nyt/raw/nyt10.csv   dds-nyt/raw/nyt11.csv   dds-nyt/raw/nyt12.csv \n## \"dds-nyt/raw/nyt10.csv\" \"dds-nyt/raw/nyt11.csv\" \"dds-nyt/raw/nyt12.csv\" \n##   dds-nyt/raw/nyt13.csv    dds-nyt/raw/nyt7.csv    dds-nyt/raw/nyt8.csv \n## \"dds-nyt/raw/nyt13.csv\"  \"dds-nyt/raw/nyt7.csv\"  \"dds-nyt/raw/nyt8.csv\" \n##    dds-nyt/raw/nyt9.csv \n##  \"dds-nyt/raw/nyt9.csv\"\n\n\n\nNow the imported file will have their file path and name associated with the dataset:\n\n\n\nshow/hide\nraw_data_pths |&gt; \n  # names \n  purrr::set_names() |&gt; \n  # import  \n    purrr::map(\n      vroom::vroom, \n          delim = \",\", show_col_types = FALSE) |&gt; \n  utils::head(2) |&gt; \n  dplyr::glimpse()\n## List of 2\n##  $ dds-nyt/raw/nyt10.csv: spc_tbl_ [452,766 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##   ..$ Age        : num [1:452766] 59 0 19 44 30 33 41 41 0 23 ...\n##   ..$ Gender     : num [1:452766] 1 0 0 1 1 1 0 0 0 1 ...\n##   ..$ Impressions: num [1:452766] 4 7 5 5 4 3 1 3 9 1 ...\n##   ..$ Clicks     : num [1:452766] 0 1 0 0 0 0 0 0 1 0 ...\n##   ..$ Signed_In  : num [1:452766] 1 0 1 1 1 1 1 1 0 1 ...\n##   ..- attr(*, \"spec\")=\n##   .. .. cols(\n##   .. ..   Age = col_double(),\n##   .. ..   Gender = col_double(),\n##   .. ..   Impressions = col_double(),\n##   .. ..   Clicks = col_double(),\n##   .. ..   Signed_In = col_double(),\n##   .. ..   .delim = \",\"\n##   .. .. )\n##   ..- attr(*, \"problems\")=&lt;externalptr&gt; \n##  $ dds-nyt/raw/nyt11.csv: spc_tbl_ [478,066 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##   ..$ Age        : num [1:478066] 28 51 29 20 19 0 58 42 35 44 ...\n##   ..$ Gender     : num [1:478066] 1 0 1 1 0 0 0 0 1 0 ...\n##   ..$ Impressions: num [1:478066] 8 5 2 4 5 3 5 6 8 4 ...\n##   ..$ Clicks     : num [1:478066] 0 0 0 0 0 1 1 0 0 0 ...\n##   ..$ Signed_In  : num [1:478066] 1 1 1 1 1 0 1 1 1 1 ...\n##   ..- attr(*, \"spec\")=\n##   .. .. cols(\n##   .. ..   Age = col_double(),\n##   .. ..   Gender = col_double(),\n##   .. ..   Impressions = col_double(),\n##   .. ..   Clicks = col_double(),\n##   .. ..   Signed_In = col_double(),\n##   .. ..   .delim = \",\"\n##   .. .. )\n##   ..- attr(*, \"problems\")=&lt;externalptr&gt;\n\n\n\nTo add the wrangling function, I can pipe in another call to purrr::map(), and add nyt_data_processing().\n\n\n\nshow/hide\nraw_data_pths |&gt; \n  # names \n  purrr::set_names() |&gt; \n  # import \n    purrr::map(\n      vroom::vroom, \n          delim = \",\", show_col_types = FALSE) |&gt; \n  # wrangle \n  purrr::map(.f = nyt_data_processing) |&gt; \n  utils::head(2) |&gt; \n  dplyr::glimpse()\n## List of 2\n##  $ dds-nyt/raw/nyt10.csv: spc_tbl_ [452,766 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##   ..$ age        : num [1:452766] 59 0 19 44 30 33 41 41 0 23 ...\n##   ..$ gender     : num [1:452766] 1 0 0 1 1 1 0 0 0 1 ...\n##   ..$ impressions: num [1:452766] 4 7 5 5 4 3 1 3 9 1 ...\n##   ..$ clicks     : num [1:452766] 0 1 0 0 0 0 0 0 1 0 ...\n##   ..$ signed_in  : Factor w/ 2 levels \"no\",\"yes\": 2 1 2 2 2 2 2 2 1 2 ...\n##   ..$ age_group  : Ord.factor w/ 7 levels \"&lt;18\"&lt;\"18-24\"&lt;..: 6 1 2 4 3 3 4 4 1 2 ...\n##   ..$ ctr_rate   : num [1:452766] 0 0.143 0 0 0 0 0 0 0.111 0 ...\n##   ..$ female     : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 1 1 1 2 2 2 1 ...\n##   ..- attr(*, \"spec\")=\n##   .. .. cols(\n##   .. ..   Age = col_double(),\n##   .. ..   Gender = col_double(),\n##   .. ..   Impressions = col_double(),\n##   .. ..   Clicks = col_double(),\n##   .. ..   Signed_In = col_double(),\n##   .. ..   .delim = \",\"\n##   .. .. )\n##   ..- attr(*, \"problems\")=&lt;externalptr&gt; \n##  $ dds-nyt/raw/nyt11.csv: spc_tbl_ [478,066 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##   ..$ age        : num [1:478066] 28 51 29 20 19 0 58 42 35 44 ...\n##   ..$ gender     : num [1:478066] 1 0 1 1 0 0 0 0 1 0 ...\n##   ..$ impressions: num [1:478066] 8 5 2 4 5 3 5 6 8 4 ...\n##   ..$ clicks     : num [1:478066] 0 0 0 0 0 1 1 0 0 0 ...\n##   ..$ signed_in  : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 2 1 2 2 2 2 ...\n##   ..$ age_group  : Ord.factor w/ 7 levels \"&lt;18\"&lt;\"18-24\"&lt;..: 3 5 3 2 2 1 6 4 4 4 ...\n##   ..$ ctr_rate   : num [1:478066] 0 0 0 0 0 0.333 0.2 0 0 0 ...\n##   ..$ female     : Factor w/ 2 levels \"no\",\"yes\": 1 2 1 1 2 2 2 2 1 2 ...\n##   ..- attr(*, \"spec\")=\n##   .. .. cols(\n##   .. ..   Age = col_double(),\n##   .. ..   Gender = col_double(),\n##   .. ..   Impressions = col_double(),\n##   .. ..   Clicks = col_double(),\n##   .. ..   Signed_In = col_double(),\n##   .. ..   .delim = \",\"\n##   .. .. )\n##   ..- attr(*, \"problems\")=&lt;externalptr&gt;\n\n\n\n\nlist_rbind()\nFor the final step, I’ll bind all the data into a data.frame with the updated purrr::list_rbind() function (set names_to = \"id\").\n\n\n\nshow/hide\nraw_data_pths |&gt; \n  # names \n  purrr::set_names() |&gt; \n  # import \n    purrr::map(\n      vroom::vroom, \n          delim = \",\", show_col_types = FALSE) |&gt; \n  # wrangle \n  purrr::map(.f = nyt_data_processing) |&gt; \n  # bind\n  purrr::list_rbind(names_to = \"id\") |&gt; \n  dplyr::glimpse()\n## Rows: 3,488,345\n## Columns: 9\n## $ id          &lt;chr&gt; \"dds-nyt/raw/nyt10.csv\", \"dds-nyt/raw/nyt10.csv\", \"dds-nyt…\n## $ age         &lt;dbl&gt; 59, 0, 19, 44, 30, 33, 41, 41, 0, 23, 28, 34, 0, 17, 33, 6…\n## $ gender      &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0…\n## $ impressions &lt;dbl&gt; 4, 7, 5, 5, 4, 3, 1, 3, 9, 1, 4, 4, 7, 3, 7, 6, 6, 2, 7, 2…\n## $ clicks      &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n## $ signed_in   &lt;fct&gt; yes, no, yes, yes, yes, yes, yes, yes, no, yes, yes, yes, …\n## $ age_group   &lt;ord&gt; 55-64, &lt;18, 18-24, 35-44, 25-34, 25-34, 35-44, 35-44, &lt;18,…\n## $ ctr_rate    &lt;dbl&gt; 0.000, 0.143, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.…\n## $ female      &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, no, no, no, yes, …\n\n\n\nNow that we have a complete recipe, I store the result in nyt_data_proc. I can also confirm all files were imported and wrangled by checking the count() of id.\n\n\n\nshow/hide\nnyt_data_proc &lt;- raw_data_pths |&gt; \n  # names \n  purrr::set_names() |&gt; \n  # import \n    purrr::map(\n      vroom::vroom, \n          delim = \",\", show_col_types = FALSE) |&gt; \n  # wrangle \n  purrr::map(.f = nyt_data_processing) |&gt; \n  # bind\n  purrr::list_rbind(names_to = \"id\") \n\n\n\n\nshow/hide\nnyt_data_proc |&gt; dplyr::count(id)\n## # A tibble: 7 × 2\n##   id                         n\n##   &lt;chr&gt;                  &lt;int&gt;\n## 1 dds-nyt/raw/nyt10.csv 452766\n## 2 dds-nyt/raw/nyt11.csv 478066\n## 3 dds-nyt/raw/nyt12.csv 396308\n## 4 dds-nyt/raw/nyt13.csv 786044\n## 5 dds-nyt/raw/nyt7.csv  452493\n## 6 dds-nyt/raw/nyt8.csv  463196\n## 7 dds-nyt/raw/nyt9.csv  459472"
  },
  {
    "objectID": "posts/purrr1.0/index.html#export-multiple-datasets",
    "href": "posts/purrr1.0/index.html#export-multiple-datasets",
    "title": "purrr updates (v1.0.0)",
    "section": "Export multiple datasets",
    "text": "Export multiple datasets\n\nYou have a dataset you’d like to split into individual data.frames, then export these into separate file paths\n\nI have a processed dataset with seven data files (nyt_data_proc), and I want to export these into seven processed data files in a dds-nyt/processed/ folder.\nCreating a vector of processed data file paths is a little more involved because I wanted to add a date prefix to the exported files, and because I want to add this path as a variable in the nyt_data_proc dataset.\nBelow I create a new file_nm and proc_file_pth column to nyt_data_proc:\n\n\n\nshow/hide\n# create file names \nnyt_data_proc &lt;- dplyr::mutate(.data = nyt_data_proc,\n        file_nm = tools::file_path_sans_ext(base::basename(id)),\n        proc_file_pth = paste0(\"dds-nyt/processed/\", \n                        as.character(Sys.Date()), \"-\", \n                        file_nm))\nnyt_data_proc |&gt; dplyr::count(proc_file_pth)\n## # A tibble: 7 × 2\n##   proc_file_pth                           n\n##   &lt;chr&gt;                               &lt;int&gt;\n## 1 dds-nyt/processed/2023-12-16-nyt10 452766\n## 2 dds-nyt/processed/2023-12-16-nyt11 478066\n## 3 dds-nyt/processed/2023-12-16-nyt12 396308\n## 4 dds-nyt/processed/2023-12-16-nyt13 786044\n## 5 dds-nyt/processed/2023-12-16-nyt7  452493\n## 6 dds-nyt/processed/2023-12-16-nyt8  463196\n## 7 dds-nyt/processed/2023-12-16-nyt9  459472\n\n\n\nNote that I don’t include the file extension in proc_file_pth, because I might want to use different file types when I’m exporting.\nI’ll cover two methods for exporting datasets from a list.\nIn this first method, I’ll use the base::split() function to split nyt_data_proc by the proc_file_pth variable into a list of data frames. I’ll also use utils::head(), purrr::walk(), and dplyr::glimpse() to view the output.\n\n\n\nshow/hide\nsplit(x = nyt_data_proc, f = nyt_data_proc$proc_file_pth) |&gt;\n  utils::head(3) |&gt; \n  purrr::walk(.f = glimpse)\n## Rows: 452,766\n## Columns: 11\n## $ id            &lt;chr&gt; \"dds-nyt/raw/nyt10.csv\", \"dds-nyt/raw/nyt10.csv\", \"dds-n…\n## $ age           &lt;dbl&gt; 59, 0, 19, 44, 30, 33, 41, 41, 0, 23, 28, 34, 0, 17, 33,…\n## $ gender        &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,…\n## $ impressions   &lt;dbl&gt; 4, 7, 5, 5, 4, 3, 1, 3, 9, 1, 4, 4, 7, 3, 7, 6, 6, 2, 7,…\n## $ clicks        &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ signed_in     &lt;fct&gt; yes, no, yes, yes, yes, yes, yes, yes, no, yes, yes, yes…\n## $ age_group     &lt;ord&gt; 55-64, &lt;18, 18-24, 35-44, 25-34, 25-34, 35-44, 35-44, &lt;1…\n## $ ctr_rate      &lt;dbl&gt; 0.000, 0.143, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, …\n## $ female        &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, no, no, no, yes…\n## $ file_nm       &lt;chr&gt; \"nyt10\", \"nyt10\", \"nyt10\", \"nyt10\", \"nyt10\", \"nyt10\", \"n…\n## $ proc_file_pth &lt;chr&gt; \"dds-nyt/processed/2023-12-16-nyt10\", \"dds-nyt/processed…\n## Rows: 478,066\n## Columns: 11\n## $ id            &lt;chr&gt; \"dds-nyt/raw/nyt11.csv\", \"dds-nyt/raw/nyt11.csv\", \"dds-n…\n## $ age           &lt;dbl&gt; 28, 51, 29, 20, 19, 0, 58, 42, 35, 44, 62, 20, 0, 0, 43,…\n## $ gender        &lt;dbl&gt; 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ impressions   &lt;dbl&gt; 8, 5, 2, 4, 5, 3, 5, 6, 8, 4, 6, 4, 5, 4, 4, 5, 3, 2, 5,…\n## $ clicks        &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,…\n## $ signed_in     &lt;fct&gt; yes, yes, yes, yes, yes, no, yes, yes, yes, yes, yes, ye…\n## $ age_group     &lt;ord&gt; 25-34, 45-54, 25-34, 18-24, 18-24, &lt;18, 55-64, 35-44, 35…\n## $ ctr_rate      &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, 0.333, 0.200, 0.000, …\n## $ female        &lt;fct&gt; no, yes, no, no, yes, yes, yes, yes, no, yes, yes, yes, …\n## $ file_nm       &lt;chr&gt; \"nyt11\", \"nyt11\", \"nyt11\", \"nyt11\", \"nyt11\", \"nyt11\", \"n…\n## $ proc_file_pth &lt;chr&gt; \"dds-nyt/processed/2023-12-16-nyt11\", \"dds-nyt/processed…\n## Rows: 396,308\n## Columns: 11\n## $ id            &lt;chr&gt; \"dds-nyt/raw/nyt12.csv\", \"dds-nyt/raw/nyt12.csv\", \"dds-n…\n## $ age           &lt;dbl&gt; 29, 0, 27, 0, 69, 0, 0, 39, 53, 27, 0, 13, 26, 63, 79, 0…\n## $ gender        &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,…\n## $ impressions   &lt;dbl&gt; 4, 1, 2, 5, 9, 1, 6, 4, 7, 3, 1, 1, 2, 5, 6, 7, 3, 1, 5,…\n## $ clicks        &lt;dbl&gt; 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,…\n## $ signed_in     &lt;fct&gt; yes, no, yes, no, yes, no, no, yes, yes, yes, no, yes, y…\n## $ age_group     &lt;ord&gt; 25-34, &lt;18, 25-34, &lt;18, 65+, &lt;18, &lt;18, 35-44, 45-54, 25-…\n## $ ctr_rate      &lt;dbl&gt; 0.250, 0.000, 0.000, 0.200, 0.111, 0.000, 0.000, 0.000, …\n## $ female        &lt;fct&gt; yes, yes, yes, yes, no, yes, yes, no, yes, no, yes, no, …\n## $ file_nm       &lt;chr&gt; \"nyt12\", \"nyt12\", \"nyt12\", \"nyt12\", \"nyt12\", \"nyt12\", \"n…\n## $ proc_file_pth &lt;chr&gt; \"dds-nyt/processed/2023-12-16-nyt12\", \"dds-nyt/processed…\n\n\n\nI can see this is returning a list of data frames as expected, so now I need to pass this list into purrr::walk2() so I can iterate vroom::vroom_write() over the processed data paths in proc_file_pth.\n\nFirst I create the processed data folder (dds-nyt/processed/)\n\n\n\n\nshow/hide\nfs::dir_create(\"dds-nyt/processed/\")\n\n\n\n\nSecond, I create the .x argument, which is the split list of nyt_data_proc by proc_file_pth\n\n\n\n\nshow/hide\n# split nyt_data_proc (.x)\nby_proc_pths &lt;- nyt_data_proc |&gt; \n  split(nyt_data_proc$proc_file_pth)\n\n\n\n\nThird, I get the unique processed data paths in the proc_file_pth column and store it as a vector for the .y\n\n\n\n\nshow/hide\n# get unique processed paths in nyt_data_proc (.y) with .csv extension\nproc_pths &lt;- paste0(unique(nyt_data_proc$proc_file_pth), \".csv\")\nproc_pths\n## [1] \"dds-nyt/processed/2023-12-16-nyt10.csv\"\n## [2] \"dds-nyt/processed/2023-12-16-nyt11.csv\"\n## [3] \"dds-nyt/processed/2023-12-16-nyt12.csv\"\n## [4] \"dds-nyt/processed/2023-12-16-nyt13.csv\"\n## [5] \"dds-nyt/processed/2023-12-16-nyt7.csv\" \n## [6] \"dds-nyt/processed/2023-12-16-nyt8.csv\" \n## [7] \"dds-nyt/processed/2023-12-16-nyt9.csv\"\n\n\n\nNow I can perform purrr::walk2() on by_proc_pths using proc_pths and vroom::vroom_write():\n\n\n\nshow/hide\n# iterate with .f\nwalk2(.x = by_proc_pths, .y = proc_pths, \n      .f = vroom::vroom_write, delim = \",\")\n# or as an anonymous function \n\n\n\nOr I could write this as an an anonymous function:\n\n\n\nshow/hide\nnyt_data_proc |&gt; \n  split(nyt_data_proc$proc_file_pth) |&gt; \n  walk2(.y = proc_pths, \n    \\(x, y)\n    vroom::vroom_write(x = x, \n      file = y,  delim = \",\"))\n\n\n\nI’ll want to perform a sanity check on this output with the first exported item in dds-nyt/processed and check it against the nyt1_proc data to evaluate the differences.\n\n\n\nshow/hide\nnyt1_proc_check_01 &lt;- vroom::vroom(file = proc_pths[1], # grab the first file\n                                   delim = \",\", show_col_types = FALSE)\n\n\n\nI’ll check the differences with diffobj::diffStr(). Click on Code below to view the differences:\n\n\n\nshow/hide\nwaldo::compare(\n  x = names(nyt1_proc),\n  y = names(nyt1_proc_check_01), \n  max_diffs = 20)\n##     old           | new                 \n## [1] \"age\"         - \"id\"            [1] \n## [2] \"gender\"      - \"age\"           [2] \n## [3] \"impressions\" - \"gender\"        [3] \n## [4] \"clicks\"      - \"impressions\"   [4] \n## [5] \"signed_in\"   - \"clicks\"        [5] \n## [6] \"age_group\"   - \"signed_in\"     [6] \n## [7] \"ctr_rate\"    - \"age_group\"     [7] \n## [8] \"female\"      - \"ctr_rate\"      [8] \n##                   - \"female\"        [9] \n##                   - \"file_nm\"       [10]\n##                   - \"proc_file_pth\" [11]\n\n\n\nThese are differences I’d expect, given the two data frames will have slightly different columns (id, file_nm, and proc_file_pth)\n\ngroup_walk()\nAnother option involves the group_walk() function from dplyr (WARNING: this is experimental). But I need to remove the processed folder so I’m not confusing myself:\n\n\n\nshow/hide\nwalk(.x = list.files(path = \"dds-nyt/processed\", \n                     full.names = TRUE, \n                     pattern = \".csv$\"),\n    .f = fs::file_delete)\nfs::dir_tree(\"dds-nyt\", recurse = TRUE)\n## dds-nyt\n## ├── processed\n## └── raw\n##     ├── nyt10.csv\n##     ├── nyt11.csv\n##     ├── nyt12.csv\n##     ├── nyt13.csv\n##     ├── nyt7.csv\n##     ├── nyt8.csv\n##     └── nyt9.csv\n\n\n\nThe help file on group_walk() gives an example with purrr’s formula syntax (which I’ve adapted below):\n\n\n\nshow/hide\nnyt_data_proc |&gt; \n  dplyr::group_by(proc_file_pth) |&gt;   \n  dplyr::group_walk( ~vroom::vroom_write(x = .x, \n                          file = paste0(.y$proc_file_pth, \".csv\"),\n                          delim = \",\"))\n\n\n\nI’ve also re-written this as an anonymous function (which is more stable, since the formula syntax is no longer recommended).\n\n\n\nshow/hide\n# now re-create\nfs::dir_create(\"dds-nyt/processed/\")\nnyt_data_proc |&gt; \n  dplyr::group_by(proc_file_pth) |&gt;   \n  dplyr::group_walk(\\(x, y) \n    vroom::vroom_write(\n    x = x, \n    file = paste0(y$proc_file_pth, \".csv\"),\n    delim = \", \")\n    )\n# check\nfs::dir_tree(\"dds-nyt/processed/\", pattern = \"csv$\")\n## dds-nyt/processed/\n## ├── 2023-12-16-nyt10.csv\n## ├── 2023-12-16-nyt11.csv\n## ├── 2023-12-16-nyt12.csv\n## ├── 2023-12-16-nyt13.csv\n## ├── 2023-12-16-nyt7.csv\n## ├── 2023-12-16-nyt8.csv\n## └── 2023-12-16-nyt9.csv\n\n\n\nOnce again, I’ll import the first file in the new processed data folder and check it against the columns nyt1_proc_check_01 data to evaluate the differences.\n\n\n\nshow/hide\n# now re-check\nnyt1_proc_check_02 &lt;- vroom::vroom(file = proc_pths[1], # grab the first file\n                                   delim = \",\", show_col_types = FALSE)\n\n\n\n\n\n\nshow/hide\nwaldo::compare(\n  x = names(nyt1_proc_check_01),\n  y = names(nyt1_proc_check_02), \n  max_diffs = 20)\n## `old[8:11]`: \"ctr_rate\" \"female\" \"file_nm\" \"proc_file_pth\"\n## `new[8:10]`: \"ctr_rate\" \"female\" \"file_nm\""
  },
  {
    "objectID": "posts/p4-test-system-shiny/index.html",
    "href": "posts/p4-test-system-shiny/index.html",
    "title": "Shiny system tests with shinytest2",
    "section": "",
    "text": "ImportantNOTE\n\n\n\n\n\n\nThis post has been shortened from the original version. I felt it was too long and duplicative of other resources written better elsewhere. If you’d like to read the previous version, you can find it in the series section.\nThis is the fourth post in a series on testing Shiny applications. The previous posts have covered using BDD in unit tests, testing apps outside of an R package structure, and testing module server functions. In this post, we’ll be covering testing Shiny applications using testthat and shinytest2."
  },
  {
    "objectID": "posts/p4-test-system-shiny/index.html#app-packages",
    "href": "posts/p4-test-system-shiny/index.html#app-packages",
    "title": "Shiny system tests with shinytest2",
    "section": "App-Packages",
    "text": "App-Packages\nIn the previous post, we stored the modules and applications from the Shiny modules chapter of Mastering Shiny in the mstsap package. The msst2ap package contains shinytest2 tests for the Shiny apps in Mastering Shiny (hence the name: Mastering Shiny shinytest2 app-package).\nYou can install msst2ap using the following:\n\ninstall.packages(\"remotes\")\nremotes::install_github(\n  \"https://github.com/mjfrigaard/msst2ap\"\n)\n\nI’ve stored development versions of the applications in the inst/dev/ folder of msst2ap:\ninst\n└── dev\n    ├── datasetApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    ├── gghistApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    ├── histogramApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    ├── selectDataVarApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    └── selectVarApp\n        ├── DESCRIPTION\n        ├── R\n        │   └── modules.R\n        ├── README.md\n        └── app.R\n\n12 directories, 20 files\n\nUsing system.file()\nThe apps stored in the inst/dev/ directory of msst2ap can be passed to the app_dir argument of AppDriver$new() with system.file():\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$view()\n})\n\n\n\n\nSetting inputs\nThe first things we’ll check is changing the dataset-dataset input from ability.cov to attitude using app$set_inputs() (Note that this uses the module notation above (i.e., \"id-inputId\"):\n\ntest_that(\"mstsap::datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n})\n\nIf you can see both windows, you’ll see the application values change in the Chromium browser:\n\n\n\n\n\n\n\n\n\n\n\n\n(a) app$set_inputs()\n\n\n\n\n\n\n\nFigure 1: Set application inputs with app$set_inputs()\n\n\n\n\n\n\nChecking inputs\nWe can capture values in a list inside the test by including a call to app$get_values() and assigning the output to app_values.\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n  app_values &lt;- app$get_values()\n})\n\napp_values has a similar structure to the .json snapshot covered above (i.e., with input, output, and export):\n\nstr(app_values)\n\nList of 3\n $ input :List of 1\n  ..$ dataset-dataset: chr \"attitude\"\n $ output:List of 2\n  ..$ data: chr \"&lt;table  class = 'table shiny-table table- spacing-s' style = 'width:auto;'&gt;\\n&lt;thead&gt; &lt;tr\"..\n  ..$ vals: chr \"$`dataset-dataset`\\n[1] \\\"attitude\\\"\\n\"\n $ export: Named list()\nWe can use waldo::compare() to verify the input in app_values to verify the value that we changed with app$set_inputs()\n\nwaldo::compare(\n  x = app_values$input$`dataset-dataset`,\n  y = \"attitude\"\n)\n\n✔ No differences\nwaldo::compare() can easily be adapted to a new test expectation:\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n  app_values &lt;- app$get_values()\n  waldo::compare(x = app_values$input$`dataset-dataset`,\n                 y = \"attitude\")\n  testthat::expect_equal(\n    object = app_values$input$`dataset-dataset`,\n    expected = \"attitude\")\n})\n\nAt the end of the test, I’ll add a call app$stop() to close the Chromium app.\n\ntest_that(\"{shinytest2}: datasetApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"datasetApp\",\n                                             package = \"msst2ap\"),\n                       height = 600,\n                       width = 800)\n  app$set_inputs(`dataset-dataset` = \"attitude\")\n  app_values &lt;- app$get_values()\n  waldo::compare(x = app_values$input$`dataset-dataset`,\n                 y = \"attitude\")\n  testthat::expect_equal(\n    object = app_values$input$`dataset-dataset`,\n    expected = \"attitude\")\n  app$stop()\n})"
  },
  {
    "objectID": "posts/p4-test-system-shiny/index.html#exporting-test-values",
    "href": "posts/p4-test-system-shiny/index.html#exporting-test-values",
    "title": "Shiny system tests with shinytest2",
    "section": "Exporting test values",
    "text": "Exporting test values\nThe shinytest2 documentation repeatedly1 recommends2 exporting test values from Shiny applications. We’ll use the application stored in inst/dev/selectVarApp/ to explore exporting test values.\nThe application in the inst/dev/selectVarApp/ folder of msst2ap includes a call to exportTestValues() and the test.mode option set to TRUE in the call to shinyApp().3\n\nserver &lt;- function(input, output, session) {\n  data &lt;- datasetServer(\"data\")\n  var &lt;- selectVarServer(\"var\", data, filter = filter)\n\n  output$out &lt;- renderTable(head(var()))\n\n  output$vals &lt;- renderPrint({\n    x &lt;- reactiveValuesToList(input,\n      all.names = TRUE\n    )\n    print(x)\n  })\n\n  exportTestValues(\n    var = var(),\n    data = data()\n  )\n}\n\nThe test for this application contains the same system.file() call to create the AppDriver object:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n})\n\nAfter entering app$view() in the Console, the application opens in the Chromium headless browser again:\n\napp$view()\n\nWe can see selectVarApp has been launched in showcase mode, so the README and code files are displayed in the UI.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) app$view()\n\n\n\n\n\n\n\nFigure 2: View selectVarApp() application with app$view()\n\n\n\n\nIn our test file, we’ll use app$set_values() to change the $`data-dataset` and $`var-var` inputs:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n  \n1  app$set_inputs(`data-dataset` = \"mtcars\")\n})\n\n\n1\n\nChange $`data-dataset` to mtcars\n\n\n\n\nWe’ll also change the variable input from mpg to wt and verify the output in the UI:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n  \n1  app$set_inputs(`data-dataset` = \"mtcars\")\n2  app$set_inputs(`var-var` = \"wt\")\n})\n\n\n1\n\nChange $`data-dataset` to mtcars\n\n2\n\nChange $`var-var` to wt\n\n\n\n\nThe printed reactiveValuesToList() is updated UI when the selectInput() changes:\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Set data-dataset\n\n\n\n\n\n\n\nFigure 3: View selectVarApp() after setting data-dataset and var-var with app$set_inputs()\n\n\n\n\n\nGetting values\nWe’ll use app$get_values() to store the exported input, output, and export test values in app_values:\n\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n\n1  app$set_inputs(`data-dataset` = \"mtcars\")\n2  app$set_inputs(`var-var` = \"wt\")\n\n3  app_values &lt;- app$get_values()\n})\n\n\n1\n\nChange $`data-dataset` to mtcars\n\n2\n\nChange $`var-var` to wt\n\n3\n\nAssign to app_values list\n\n\n\n\napp_values is a list (similar to the .json snapshot file), but now we’ve explicitly exported values from the server in selectVarApp():\n\nnames(app_values$export)\n\n\n[1] \"data\" \"var\" \n\n\n\nExpectations\nWe can use app_values to verify the structure of each exported object:\n\ndata should be a data.frame()\n\n\ntestthat::expect_true(\n  object = is.data.frame(app_values$export$data)\n)\n\n\nvar should be have one column:\n\n\ntestthat::expect_true(\n  object = ncol(app_values$export$var) == 1)\n\nOnce again, we end the test with a call to app$stop(). The completed test for selectVarApp() is below:\n\n\nshow/hide mstsap::selectVarApp test\ntestthat::test_that(\"{shinytest2}: selectVarApp\", {\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"selectVarApp\",\n                                             package = \"msst2ap\"),\n                       height = 1200, width = 1000)\n\n  app$set_inputs(`data-dataset` = \"mtcars\")\n  app$set_inputs(`var-var` = \"wt\")\n\n  app_values &lt;- app$get_values()\n\n  testthat::expect_true(\n    object = is.data.frame(app_values$export$data))\n\n  testthat::expect_true(\n    object = ncol(app_values$export$var) == 1)\n\n  app$stop()\n})"
  },
  {
    "objectID": "posts/p4-test-system-shiny/index.html#testing-complex-outputs",
    "href": "posts/p4-test-system-shiny/index.html#testing-complex-outputs",
    "title": "Shiny system tests with shinytest2",
    "section": "Testing complex outputs",
    "text": "Testing complex outputs\nmsst2ap has the histogramApp() from Mastering Shiny in inst/dev/histogramApp/, and a ggplot2 version of the histogramApp() in the inst/dev/ggHistApp/ folder:\n\ninst\n└── dev\n    ├── ggHistApp\n    │   ├── DESCRIPTION\n    │   ├── R\n    │   │   └── modules.R\n    │   ├── README.md\n    │   └── app.R\n    └── histogramApp\n        ├── DESCRIPTION\n        ├── R\n        │   └── modules.R\n        ├── README.md\n        └── app.R\n\n6 directories, 8 files\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) histogramApp()\n\n\n\n\n\n\n\n\n\n\n\n(b) ggHistApp()\n\n\n\n\n\n\n\nFigure 4: histogramApp() vs. ggHistApp()\n\n\n\n\n\nTesting reactive values\nThe module server functions in histogramApp() return two values: data and x:\n\nserver &lt;- function(input, output, session) {\n  \n  data &lt;- datasetServer(\"data\")\n  x &lt;- selectVarServer(\"var\", data)\n  \n  histogramServer(\"hist\", x)\n\n  output$vals &lt;- shiny::renderPrint({\n    x &lt;- shiny::reactiveValuesToList(input,\n                            all.names = TRUE)\n    print(x)\n  })\n\n}\n\ndata is returned reactive from datasetServer() and becomes an input parameter for selectVarServer(), and x is the returned reactive.\nBoth of these are reactive values, but they aren’t treated like returned values from the reactive() function (i.e., they don’t have parentheses). These are passed in the server as reactive expressions, which we can confirm using exportTestValues():\n\n\nshow/hide msst2ap::histogramApp() server\nserver &lt;- function(input, output, session) {\n  data &lt;- datasetServer(\"data\")\n  x &lt;- selectVarServer(\"var\", data)\n  histogramServer(\"hist\", x)\n\n  # remaining code omitted\n  \n1  exportTestValues(\n      data = data,\n      x = x\n    )\n}\n\n\n\n1\n\nWe’ve also added options(shiny.testmode = TRUE) to the top of the app.R file.\n\n\n\n\nIn the test for histogramApp(), we’ll create the app with AppDriver$new() and change the three inputs using app$set_inputs():\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n  app_values &lt;- app$get_values()\n  names(app_values)\n})\n\n[1] \"data\" \"x\"  \nWe’ll test is these are reactive functions by combining rlang::is_function() and shiny::is.reactive():\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n  app_values &lt;- app$get_values()\n  names(app_values)\n  expect_equal(\n    rlang::is_function(app_values$export$data),\n    shiny::is.reactive(app_values$export$data))\n  expect_equal(\n    rlang::is_function(app_values$export$x),\n    shiny::is.reactive(app_values$export$x))\n})\n\n\n\nUsing app logs\nshinytest2 also has the handy get_logs() that allows us to check the logs for specific functionality. Below is the output from get_logs() from histogramApp():\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n1  app_logs &lt;- app$get_logs()\n2  str(app_logs)\n})\n\n\n1\n\nCreate app logs\n\n2\n\nView log structure\n\n\n\n\nClasses ‘shinytest2_log’ and 'data.frame':  56 obs. of  5 variables:\n $ workerid : chr  NA NA NA NA ...\n $ timestamp: POSIXct, format: \"2024-03-31 04:47:41\" \"2024-03-31 04:47:41\" ...\n $ location : chr  \"shinytest2\" \"shinytest2\" \"shinytest2\" \"shinytest2\" ...\n $ level    : chr  \"info\" \"info\" \"info\" \"info\" ...\n $ message  : chr  \"Start AppDriver initialization\" \"Starting Shiny app\" \"Creating \"..\nAfter changing the three inputs with set_inputs(), we can check the output to see these actions were included in the logs:\n\ntest_that(\"{shinytest2}: histogramApp\", {\n  app &lt;- AppDriver$new(system.file(\"dev\", \"histogramApp\",\n                                  package = \"msst2ap\"),\n                       height = 750,\n                       width = 1200)\n  app$set_inputs(`data-dataset` = \"attitude\")\n  app$set_inputs(`var-var` = \"privileges\")\n  app$set_inputs(`hist-bins` = 15)\n  app_values &lt;- app$get_values()\n  names(app_values)\n  expect_equal(\n    rlang::is_function(app_values$export$data),\n    shiny::is.reactive(app_values$export$data))\n  expect_equal(\n    rlang::is_function(app_values$export$x),\n    shiny::is.reactive(app_values$export$x))\n  app$set_inputs(`hist-bins` = 15)\n1  app_logs &lt;- app$get_logs()\n2  ds_msg &lt;- subset(app_logs,\n                   message == \"Setting inputs: 'data-dataset'\")\n  expect_equal(nrow(ds_msg), 1L)\n3  var_msg &lt;- subset(app_logs,\n                    message == \"Setting inputs: 'var-var'\")\n  expect_equal(nrow(var_msg), 1L)\n4  hist_msg &lt;- subset(app_logs,\n                     message == \"Setting inputs: 'hist-bins'\")\n  expect_equal(nrow(hist_msg), 1L)\n})\n\n\n1\n\nCreate app logs\n\n\n2\n\nCreate and test dataset\n\n\n3\n\nCreate and test variable\n\n\n4\n\nCreate and test bins\n\n\n\n\nLogs can also be passed from the test to the application using log_message().\n\n\nVerify initial inputs\nThe ggHistApp() app is similar to histogramApp(), but instead of passing a reactive vector to hist(), ggHistServer() passes a reactive one-column data.frame (x()) to the ggplot2 functions. We’ll add exportTestValues() to a development version of ggHistServer() in inst/dev/: 4\n\n\nshow/hide ggHistServer()\nggHistServer &lt;- function(id, x, title = reactive(\"Histogram\")) {\n  stopifnot(is.reactive(x))\n  stopifnot(is.reactive(title))\n\n  moduleServer(id, function(input, output, session) {\n    \n1    gg2_plot &lt;- reactive({\n      ggplot2::ggplot(\n          mapping =\n            ggplot2::aes(purrr::as_vector(x()))\n        ) +\n          ggplot2::geom_histogram(bins = input$bins) +\n          ggplot2::labs(\n            title = paste0(title(), \" [bins = \", input$bins, \"]\"),\n            y = \"Count\",\n            x = names(x())\n          ) +\n          ggplot2::theme_minimal()\n    })\n\n2    observe({\n      output$hist &lt;- renderPlot({gg2_plot()}, res = 124)\n    }) |&gt; \n      bindEvent(c(x(), title(), input$bins))\n\n3    exportTestValues(\n      bins = input$bins,\n      x = x(),\n      title = title()\n    )\n\n    # remaining code omitted\n    \n  })\n}\n\n\n\n1\n\nBuild ggplot2 graph\n\n2\n\nRender plot\n\n\n3\n\nExport bins, x() and title()\n\n\n\n\nThe version of ggHistServer() above replaces the ggHistServer() used in the standalone app function).5 The remaining modules from mstsap are explicitly namespaced. The code below identifies the location of each module in ggHistApp(): 6\n\n\nshow/hide ggHistApp()\nggHistApp &lt;- function() {\n  ui &lt;- fluidPage(\n    sidebarLayout(\n      sidebarPanel(\n        mstsap::datasetInput(\"data\", is.data.frame),\n        mstsap::selectVarInput(\"var\"),\n      ),\n      mainPanel(\n1        histogramOutput(\"hist\"),\n        code(\"app vals\"),\n        verbatimTextOutput(\"vals\")\n      )\n    )\n  )\n\n  server &lt;- function(input, output, session) {\n    data &lt;- mstsap::datasetServer(\"data\")\n2    x &lt;- ggSelectVarServer(\"var\", data)\n3    ggHistServer(\"hist\", x)\n\n    output$vals &lt;- renderPrint({\n        x &lt;- reactiveValuesToList(input,\n          all.names = TRUE)\n        print(x, width = 30, max.levels = NULL)},\n      width = 30)\n  }\n  \n4    exportTestValues(\n      x = x(),\n      data = data(),\n      react_x = x,\n      react_data = data\n    )\n\n  shinyApp(ui, server)\n}\nggHistApp()\n\n\n\n1\n\nFrom R/histogramOutput.R\n\n\n2\n\nFrom R/ggSelectVarServer.R\n\n\n3\n\nFrom inst/dev/ggHistApp/R/modules.R\n\n4\n\nExported test values\n\n\n\n\nIn the test-shinytest2-ggHistApp.R test file, I’ll verify the vdiffr package is installed, then create the AppDriver object with a call to system.file() and set the height and width:\n\ntest_that(\"{shinytest2}: ggHistApp\", {\n  skip_if_not_installed(\"vdiffr\")\n  app_pth &lt;- system.file(\"dev\", \"ggHistApp\",\n                                  package = \"msst2ap\")\n  app &lt;- AppDriver$new(app_pth,\n                       height = 750, width = 1200)\n})\n\nView the application in the Chromium browser by running app$view() in the Console:\n\napp$view()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) app$view()\n\n\n\n\n\n\n\nFigure 5: View ggHistApp() application with app$view()\n\n\n\n\nThe first expectations in the example test the default input values:\n\ntestthat::test_that(\"{shinytest2}: gghistApp\", {\n  testthat::skip_if_not_installed(\"vdiffr\")\n\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"gghistApp\",\n                                             package = \"msst2ap\"),\n                       height = 750, width = 1200)\n\n1  app_init_data &lt;- app$get_value(input = \"data-dataset\")\n  waldo::compare(app_init_data, \"BOD\")\n  expect_equal(\n    object = app_init_data,\n    expected = \"BOD\")\n\n2  app_init_var &lt;- app$get_value(input = \"var-var\")\n  waldo::compare(app_init_var, \"Time\")\n  expect_equal(\n    object = app_init_var,\n    expected = \"Time\")\n})\n\n\n1\n\nVerify initial data\n\n2\n\nVerify initial variable\n\n\n\n\n\n\nSet and verify export\nNext, we check changing the input values with app$set_values(id-inputId):\n\ntestthat::test_that(\"{shinytest2}: gghistApp\", {\n  testthat::skip_if_not_installed(\"vdiffr\")\n\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"gghistApp\",\n                                             package = \"msst2ap\"),\n                       height = 750, width = 1200)\n\n1  app_init_data &lt;- app$get_value(input = \"data-dataset\")\n  waldo::compare(app_init_data, \"BOD\")\n  expect_equal(\n    object = app_init_data,\n    expected = \"BOD\")\n\n2  app_init_var &lt;- app$get_value(input = \"var-var\")\n  waldo::compare(app_init_var, \"Time\")\n  expect_equal(\n    object = app_init_var,\n    expected = \"Time\")\n  \n3  app$set_inputs(`data-dataset` = \"mtcars\")\n  app_exp_x_01 &lt;- app$get_value(export = \"hist-x\")\n  waldo::compare(\n    x = app_exp_x_01,\n    y = mtcars[1])\n  expect_equal(\n    object = app_exp_x_01,\n    expected = mtcars[1])\n\n4  app$set_inputs(`var-var` = \"disp\")\n  app_exp_plot_obj_01 &lt;- app$get_value(export = \"hist-plot_obj\")\n  waldo::compare(\n    x = app_exp_plot_obj_01,\n    y = purrr::as_vector(mtcars['disp']))\n  expect_equal(\n    object = app_exp_plot_obj_01,\n    expected = purrr::as_vector(mtcars['disp']))\n\n5  app$set_inputs(`hist-bins` = 15)\n  app_set_bins_01 &lt;- app$get_value(input = \"hist-bins\")\n  waldo::compare(app_set_bins_01, 15L)\n  expect_equal(\n    object = app_set_bins_01,\n    expected = 15)\n})\n\n\n1\n\nVerify initial data\n\n2\n\nVerify initial variable\n\n3\n\nVerify exported data\n\n4\n\nVerify exported var\n\n5\n\nVerify histogram changes\n\n\n\n\n\n\nVerify exports\nFinally, we’ll test the exported values by creating app$get_values()$export and checking it’s contents:\n\ntestthat::test_that(\"{shinytest2}: gghistApp\", {\n  testthat::skip_if_not_installed(\"vdiffr\")\n\n  app &lt;- AppDriver$new(app_dir = system.file(\"dev\", \"gghistApp\",\n                                             package = \"msst2ap\"),\n                       height = 750, width = 1200)\n\n1  app_init_data &lt;- app$get_value(input = \"data-dataset\")\n  waldo::compare(app_init_data, \"BOD\")\n  expect_equal(\n    object = app_init_data,\n    expected = \"BOD\")\n\n2  app_init_var &lt;- app$get_value(input = \"var-var\")\n  waldo::compare(app_init_var, \"Time\")\n  expect_equal(\n    object = app_init_var,\n    expected = \"Time\")\n  \n3  app$set_inputs(`data-dataset` = \"mtcars\")\n  app_exp_x_01 &lt;- app$get_value(export = \"hist-x\")\n  waldo::compare(\n    x = app_exp_x_01,\n    y = mtcars[1])\n  expect_equal(\n    object = app_exp_x_01,\n    expected = mtcars[1])\n\n4  app$set_inputs(`var-var` = \"disp\")\n  app_exp_plot_obj_01 &lt;- app$get_value(export = \"hist-plot_obj\")\n  waldo::compare(\n    x = app_exp_plot_obj_01,\n    y = purrr::as_vector(mtcars['disp']))\n  expect_equal(\n    object = app_exp_plot_obj_01,\n    expected = purrr::as_vector(mtcars['disp']))\n\n5  app$set_inputs(`hist-bins` = 15)\n  app_set_bins_01 &lt;- app$get_value(input = \"hist-bins\")\n  waldo::compare(app_set_bins_01, 15L)\n  expect_equal(\n    object = app_set_bins_01,\n    expected = 15)\n\n  \n6  exp_values &lt;- app$get_values()$export\n\n7  expect_true(is.data.frame(exp_values$`hist-x`))\n8  expect_equal(exp_values$`hist-x`, mtcars['disp'])\n\n9  expect_true(is.numeric(exp_values$`hist-plot_obj`))\n10  expect_equal(\n    object = exp_values$`hist-plot_obj`,\n    expected = purrr::as_vector(mtcars['disp']))\n})\n\n\n1\n\nVerify initial data\n\n2\n\nVerify initial variable\n\n3\n\nVerify exported data\n\n4\n\nVerify exported var\n\n5\n\nVerify histogram changes\n\n6\n\nExport expected values\n\n7\n\nVerify hist-x is data.frame\n\n8\n\nVerify hist-x is correct column\n\n9\n\nVerify hist-plot_obj is numeric\n\n10\n\nVerify hist-plot_obj is vector\n\n\n\n\n\n\nVerify plot with vdiffr\nNow we verify the plot with the exported plot_obj (in the hist module) with expect_doppelganger() from the vdiffr package.\n\ngg2_plot &lt;- app$get_value(output = \"hist-hist\")\n1  expect_equal(gg2_plot$alt, \"Plot object\")\n2  vdiffr::expect_doppelganger(\n      title = \"mtcars_disp_plot\",\n      fig = ggplot2::ggplot(data = exp_values$`hist-x`,\n              mapping =\n              ggplot2::aes(x = disp)\n          ) +\n            ggplot2::geom_histogram(bins = exp_values$`hist-bins`) +\n            ggplot2::labs(\n              title = paste0(exp_values$`hist-title`,\n                             \" [bins = \",\n                             exp_values$`hist-bins`, \"]\"),\n              y = \"Count\",\n              x = names(exp_values$`hist-x`)\n            ) +\n            ggplot2::theme_minimal()\n      )\n\n\n1\n\nCheck the rendered plot object\n\n\n2\n\nggHistApp() renders a ggplot2 graph, which makes it easier to demonstrate this example of checking a plot from the shinytest2 package website.\n\n\n\n\nI saved the test file and ran the test to confirm the snapshot file was created in tests/testthat/_snaps/:\n\n── Warning (test-shinytest2-gghistApp.R:72:3): {shinytest2}: gghistApp ─────────\nAdding new file snapshot: 'tests/testthat/_snaps/mtcars-disp-plot.svg'\n\n\n\nSet, get, expect\nThe process above is repeated with new values passed to app$set_inputs() and verified with app$get_values():\n\nThe data-dataset, var-var, and hist-bins are updated again with new values.\n\n\n# verify usaarrests_plot ---- \napp$set_inputs(`data-dataset` = \"USArrests\")\napp$set_inputs(`var-var` = 'UrbanPop')\napp$set_inputs(`hist-bins` = 15)\n\n\nThe updated values are exported automatically with exportTestValues() and stored in exp_values:\n\n\n# export values \nexp_values &lt;- app$get_values()$export\n\n\nThe new plot is verified again with expect_doppelganger():\n\n\nvdiffr::expect_doppelganger(\n  title = \"usaarrests_plot\",\n  fig = ggplot2::ggplot(data = exp_values$`hist-x`,\n          mapping =\n          ggplot2::aes(x = UrbanPop)\n      ) + \n        ggplot2::geom_histogram(bins = exp_values$`hist-bins`) +\n        ggplot2::labs(\n          title = paste0(exp_values$`hist-title`, \n                         \" [bins = \",\n                         exp_values$`hist-bins`, \"]\"),\n          y = \"Count\",\n          x = names(exp_values$`hist-x`)\n        ) +\n        ggplot2::theme_minimal()\n  )\n\nNow that we have a template, we can set, get, and expect multiple plot snapshots:\n\n  ## SET -----\n  app$set_inputs(`data-dataset` = \"sleep\")\n  app$set_inputs(`var-var` = 'extra')\n  app$set_inputs(`hist-bins` = 8)\n  # GET ----\n  exp_values &lt;- app$get_values()$export\n  # EXPECT ----\n  vdiffr::expect_doppelganger(\n    title = \"sleep_extra_plot\",\n    fig = ggplot2::ggplot(data = exp_values$data,\n            mapping =\n            ggplot2::aes(x = extra)\n        ) + \n          ggplot2::geom_histogram(bins = exp_values$`hist-bins`) +\n          ggplot2::labs(\n            title = paste0(exp_values$`hist-title`, \n                           \" [bins = \",\n                           exp_values$`hist-bins`, \"]\"),\n            y = \"Count\",\n            x = names(exp_values$x)\n          ) +\n          ggplot2::theme_minimal()\n    )\n\nThe initial run of this test will save the snapshot file to tests/testthat/_snaps/:\ntests/testthat/_snaps/shinytest2-gghistApp\n├── mtcars-disp-plot.svg\n├── sleep-extra-plot.svg\n└── usaarrests-plot.svg\n\n1 directory, 3 files\n\n\nResults\nThe final results of devtools::test() in msst2ap are below:\n\ndevtools::test()\n\n==&gt; devtools::test()\n\nℹ Testing msst2ap\n✔ | F W  S  OK | Context\n✔ |          1 | shinytest2-datasetApp [4.8s]                                                   \n⠼ |          5 | shinytest2-gghistApp       \n⠋ |         11 | shinytest2-gghistApp                                   \n⠙ |         12 | shinytest2-gghistApp                       \n✔ |         13 | shinytest2-gghistApp [5.1s]                                \n✔ |          5 | shinytest2-histogramApp [3.6s]                                                 \n✔ |          2 | shinytest2-selectVarApp [2.2s]                                                 \n✔ |          1 | shinytest2 [4.2s]                                                              \n\n══ Results ══════════════════════════════════════════════════════════════════\nDuration: 19.9 s\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 22 ]"
  },
  {
    "objectID": "posts/p4-test-system-shiny/index.html#recap",
    "href": "posts/p4-test-system-shiny/index.html#recap",
    "title": "Shiny system tests with shinytest2",
    "section": "Recap",
    "text": "Recap\nThis post has covered creating tests with testthat and shinytest2 for an app-package containing a Shiny application. In general, shinytest2 is designed for end-to-end testing of Shiny applications. System tests (or regression testing) can capture the state of a Shiny app (input, output, and exported values) during user interactions and compare them with a previous state (i.e., snapshots). As we can see, shinytest2 makes it easier to test specific app behaviors and set expectations iteratively with the AppDriver.\nshinytest2 tests can also simulate user interaction in a way that testServer() tests can’t, such as waiting for reactive outputs to update after the input changes, clicking on action buttons, etc. shinytest2 can also be resource-intensive, so it’s recommended to write these tests after you’ve completed the standard testthat unit tests and testServer() tests.\nOther things to consider when writing shinytest2 tests include:\n\nDefine What to Test: Since Shiny apps are interactive, so shinytest2 tests should simulate user interaction as much as possible. The tests should focus on key user interactions and the output they should generate. shinytest2 provides functions for simulating user clicks, inputs, and other interactions. Not every interaction needs to be tested, but crucial ones and those that handle complex logic should be.\nOrganize Your Tests & Use Descriptive Test Names: Organize your tests into separate files based on the app or feature they test. Each test should have a descriptive name that clarifies what the test is for. Organizing your test files with unambiguous names will make it easier to manage multiple tests, and it will make it easier to understand what’s going wrong when a test fails.\nCreate snapshots for expected outputs: Use snapshot files to verify that an app’s output matches the expected results. AppDriver$expect_values() generates .json and .png snapshot files for the application. The .json file contains input, output, and export values, and the .png file is a debug screenshot, which records how the app looked when the values where captured. These files can then be compared to a baseline snapshot.\nExport app values: While snapshot files are great for detecting changes, it’s important to remember that “differences in the captured screenshot will never cause test failures.” Manually inspecting the snapshot .png files during test development can also be time-consuming and tedious. Wherever possible, export app values and compare them against expected reference values."
  },
  {
    "objectID": "posts/p4-test-system-shiny/index.html#footnotes",
    "href": "posts/p4-test-system-shiny/index.html#footnotes",
    "title": "Shiny system tests with shinytest2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“In some cases, it’s useful to snapshot some bits of internal state of an application – state that’s not reflected directly in the inputs or outputs. This can be done by exporting values.” - shinytest2 documentation↩︎\n“It cannot be recommended enough to use exportTestValues() to test your Shiny app’s reactive values.” - shinytest2 documentation↩︎\nRead more about exporting test values here.↩︎\nThis section replicates these test examples from shinytest2 using the ggHistApp().↩︎\nThis version is loaded from a inst/dev/histogramApp/R/modules.R file.↩︎\nThis version is loaded from a inst/dev/histogramApp/R/app.R file.↩︎"
  },
  {
    "objectID": "posts/p2-tests-nonpkg-unit-tests/index.html",
    "href": "posts/p2-tests-nonpkg-unit-tests/index.html",
    "title": "Testing Non-Package Shiny Apps",
    "section": "",
    "text": "packages\nlibrary(testthat)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(shiny)\nlibrary(vdiffr)\nlibrary(shinytest2)\nThis is the second post in a series on testing Shiny applications. I’ll cover testing Shiny module server functions using the testhat package outside of an R package structure. The noap branch of the sapkgs."
  },
  {
    "objectID": "posts/p2-tests-nonpkg-unit-tests/index.html#testing-module-server-functions",
    "href": "posts/p2-tests-nonpkg-unit-tests/index.html#testing-module-server-functions",
    "title": "Testing Non-Package Shiny Apps",
    "section": "Testing module server functions",
    "text": "Testing module server functions\nThis post covers how shiny::testServer() works using a simple Shiny application. The code for abcApp() is an RStudio project (i.e., there is a noap.Rproj file in the parent folder), but it’s not part of an R package. Developing shiny applications as R packages is highly recommended, but it’s possible to begin writing unit tests before your application is a fully developed shiny app-package.\nFor more information regarding performing tests outside of the package environment, see this issue on GitHub.\n\nABC App\ntestthat is designed to perform unit tests in R packages, but not all Shiny apps begin as R packages. The Shiny application we’ll be using for this demonstration has been written using Shiny modules and a single utility function.\nThe standalone application function (launchApp()) is stored in app.R, the modules are contained in modules.R, and the single utility function is stored in utils.R:\n├── README.md\n├── app.R\n├── modules.R\n├── sapkgs.Rproj\n├── tests/\n│   ├── testthat/\n│   │   ├── test-mod_abc_server.R\n│   │   └── test-num_super_script.R\n│   └── testthat.R\n└── utils.R\n\nThe tests/ folder contains the following:\ntests\n├── testthat\n│   ├── test-mod_abc_server.R\n│   └── test-num_super_script.R\n└── testthat.R\n\ntests/ has a testthat.R ‘test runner’ file\n\nNew test files should be placed in tests/testthat/ (see example test-mod_abc_server.R below):\n\n\n\nUI module function\nIn this small example app, both ui and server modules are stored in the modules.R file.\n\nUI module:\n\n\nmod_abc_ui() (example ui module function)\n# ui module\nmod_abc_ui &lt;- function(id) {\n  ns &lt;- NS(id)\n  tagList(\n    column(\n      width = 3,\n      offset = 2,\n      numericInput(\n        inputId = ns(\"num\"),\n        label = \"Alphabet Number\",\n        value = 5,\n        min = 1,\n        max = 26\n      )\n    ),\n    column(\n      width = 6,\n      br(),\n      uiOutput(\n        outputId = ns(\"txt\")\n      ),\n      verbatimTextOutput(ns(\"out\"))\n    )\n  )\n}\n\n\n\n\n\nServer module function\nThe counterpart to mod_abc_ui() is mod_abc_server():\n\nServer module:\n\n\nmod_abc_server() (example server module function)\n# server module\nmod_abc_server &lt;- function(id) {\n  moduleServer(id, function(input, output, session) {\n    # reactive\n    letter &lt;- reactive({\n      LETTERS[input$num]\n    })\n    # super script\n    sup_scrpt &lt;- reactive({\n      num_super_script(x = input$num)\n    })\n    # output\n    output$txt &lt;- renderUI({\n      HTML(\n        paste0(\n          em(\n            \"The \", code(input$num), code(sup_scrpt()),\n            \" letter in the alphabet is: \", code(letter())\n          )\n        )\n      )\n    })\n    output$out &lt;- renderPrint({\n      HTML(\n        paste0(\n          em(\n            \"The \", code(input$num), code(sup_scrpt()),\n            \" letter in the alphabet is: \", code(letter())\n          )\n        )\n      )\n    })\n  })\n}\n\n\n\n\n\nModule utility function\nThe mod_abc_server() function uses the num_super_script() function stored in utils.R:\n\nUtility function:\n\n\nnum_super_script() (example utility function)\n# utility function\nnum_super_script &lt;- function(x) {\n      num &lt;- as.numeric(x)\n      if (num &lt; 0) {\n        stop(\"not a valid number\")\n      } else if (num &gt; 26) {\n        stop(\"not a valid number\")\n      } else if (num == 0) {\n        super_script &lt;- \"\"\n      } else if (num == 1 | num == 21) {\n        super_script &lt;- \"st\"\n      } else if (num == 2 | num == 22) {\n        super_script &lt;- \"nd\"\n      } else if (num == 3 | num == 23) {\n        super_script &lt;- \"rd\"\n      } else {\n        super_script &lt;- \"th\"\n      }\n    return(super_script)\n}\n\n\n\n\n\nStandalone app function\n\nStandalone app functions include a call to shiny::shinyApp():\n\n\nlaunch() (example app with modules)\nlaunchApp &lt;- function() {\n  shinyApp(\n    ui = fluidPage(\n      h2(\"ABC App\"),\n      fluidRow(\n        mod_abc_ui(\"x\")\n      )\n    ),\n    server = function(input, output, session) {\n      mod_abc_server(\"x\")\n    }\n  )\n}\nlaunchApp()\n\n\n\nThe call to shiny::shinyApp() is placed inside the launchApp() function\nThe ui argument is wrapped in shiny::fluidPage() with the ui module function (mod_abc_ui()) placed inside fluidRow()\nThe server argument includes the standard function(input, output, session) and the module server companion function–mod_abc_server()–with a matching id arguments\n\n\nBecause launchApp() is not part of a package, shiny and testthat are loaded and the modules and utility function are sourced in the top of the app.R file.\n\n\nsource utils.R and modules.R in app.R\n# packages --------------------------------------------------------\nlibrary(shiny)\nlibrary(testthat)\n\n# utils ------------------------------------------------------------------\nsource(\"utils.R\")\n\n# modules ------------------------------------------------------------------\nsource(\"modules.R\")\n\n\n\n\n\nUsing testServer()\nIn the test-mod_abc_server.R file, I’ll add testServer() and include the module server function as the first argument:\n\napp is the module server function (mod_abc_server) or any shiny.appobj\n\n\napp = mod_abc_server\ntestServer(app = mod_abc_server, {\n\n})\n\n\n\n\nTesting input$s\n\nThe first test I’ll add will check the initial value of input$num\n\nI’ll also include a custom message with cat()\n\n\n\ntest initial value with custom message\ntestServer(mod_abc_server, {\n  # Test initial value\n  testthat::expect_equal(input$num, NULL)\n  cat(\"\\n Test 1 initial input$num = NULL: \", is.null(input$num), \"\\n\")\n})\n\n\n\ntestServer() allows me to set new input values with session$setInputs()\n\nUse session$setInputs() to set input$num to 3\n\nTest 2 confirms input$num has changed (we’ll also add another custom message with cat())\n\n\n\nsetInputs() and test inputs\ntestServer(mod_abc_server, {\n  # set inputs\n  session$setInputs(num = 3)\n  # Test set inputs\n  testthat::expect_equal(input$num, 3)\n  cat(\"\\n Test 2 setInputs(num = 3):\", input$num, \"\\n\")\n})\n\n\n\n\n\nTesting reactive values\nThe module’s reactive values are also available to in testServer().\n\nTest 3 adds a test for sup_scrpt() (given the changed value of input$num)\n\nThe expected value is what I’m expecting num_super_script() to return:\n\n\n\nCheck sup_scrpt() reactive value with expect_equal()\ntestServer(mod_abc_server, {\n  # Test super script\n  testthat::expect_equal(object = sup_scrpt(), expected = \"rd\")\n  cat(\"\\n Test 3 sup_scrpt(): = 'rd':\", sup_scrpt(), \"\\n\")\n})\n\n\n\nFor completeness we’ll add a test for letter()\n\n\n\nCheck letter() reactive value with expect_equal()\ntestServer(mod_abc_server, {\n  # Test letter\n  expect_equal(object = letter(), expected = \"C\")\n  cat(\"\\n Test 4 letter() = C:\", letter(), \"\\n\")\n})\n\n\n\n\n\nTesting output$s\nThe module output values are also available as output$&lt;value&gt;.\n\nThe final test will verify this object is a list and print the results to the Console\n\nOutput tests can verify that output$txt has been updated with input$num:\n\n\n\nCheck module output values\ntestServer(mod_abc_server, {\n  # Test output\n  expect_true(is.list(output$txt))\n  print(output$txt)\n})\n\n\n\nFinally, I’ll run the tests with test_file():\n\n\ntest_file(path = \"/path/to/app/tests/testthat/\")\n\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]\n Test 1 initial input$num = NULL:  TRUE \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ]\n Test 2 setInputs(num = 3): 3 \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 3 ]\n Test 3 sup_scrpt(): = 'rd': rd \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 4 ]\n Test 4 letter() = C: C \n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 5 ]$html\n&lt;em&gt;\n  The \n  &lt;code&gt;3&lt;/code&gt;\n  &lt;code&gt;rd&lt;/code&gt;\n   letter in the alphabet is: \n  &lt;code&gt;C&lt;/code&gt;\n&lt;/em&gt;\n\nThe results show the tests passed! Now I am confident inputs, reactive values (sup_scrpt() & letter()), outputs behave as expected.\n\n\n\nRecap\nThe example above provides a workflow for using testServer() with testthat outside a package environment. The checklist below summarizes the steps required to test your application’s module server functions:\n\nCreate test files (in tests/testthat/)\n\nAll test files should have the test- prefix\n\nVerify inputs with session$setInputs(inputId = &lt;value&gt;)\n\nAll input$ values should initially be NULL\n\nTest reactive values by referring to them as you would in the module server\n\nCompare expected values after changing inputs with session$setInputs()\n\nTest outputs using output$&lt;value&gt; to check changes to the inputs and reactives\n\nCheck output values with output$txt\n\n\nThis concludes running tests on noap. Ideally, Shiny applications are developed as an R package (which I’ll cover in future posts), but now you know how to perform tests if this isn’t the case. The files for this demonstration are located here..\nFor a more comprehensive review of testing, check out the chapters on testing in R packages and Mastering Shiny."
  },
  {
    "objectID": "posts/shiny-plumber/index.html",
    "href": "posts/shiny-plumber/index.html",
    "title": "Shiny (for R) & APIs",
    "section": "",
    "text": "I’ve been working my way through DevOps for Data Science by Alex K Gold (highly recommended) and the chapter on APIs includes an exercise using duckdb, vetiver, pins, plumber, and shiny. These packages work so well together I thought I’d write a blog post on the solution I developed."
  },
  {
    "objectID": "posts/shiny-plumber/index.html#suggested-reading",
    "href": "posts/shiny-plumber/index.html#suggested-reading",
    "title": "Shiny (for R) & APIs",
    "section": "Suggested reading",
    "text": "Suggested reading\nBelow are the packages you’ll need to reproduce the solution:\n\npkgs &lt;- c(\"vetiver\", \"pins\", \"plumber\", \"logger\", \"palmerpenguins\", \n          \"duckdb\",\"DBI\", \"dplyr\", \"bslib\", \"bsicons\", \"httr2\", \n          \"jsonlite\")\ninstall.packages(pkgs)\n\nIf this is your first time encountering APIs, I suggest watching the Expanding R horizons: Integrating R with Plumber APIs video and reading the Creating APIs for data science with plumber and RStudio and APIs blog posts. I’ll do my best to summarize the information in these resources, but they are excellent references worth reading from the original authors.\n\nWhat is an API?\nAn API, or Application Programming Interface, is like a shared language that lets different pieces of software talk to each other and exchange information or commands.\nAPIs provide a clear way for software programs to interact, allowing different apps and services to connect without needing to understand their internal workings.\nIn R, package APIs handle things like authentication (OAuth tokens, API keys, etc.), creating the correct query parameters, and parsing the JSON/XML responses into data frames or lists, which means we can focus on the higher-level data tasks rather than on the low-level networking details.\nThe lab exercise for this chapter involves 1) putting the palmerpenguins in a duckdb database,1 2) pointing a vetiver model to the database and converting it into an API,2 and 3) building a Shiny app that calls the model API to display predictions:3\n\n“…you’ll want to store input parameters in a reactive and then send a request to the API when the user presses a button.”"
  },
  {
    "objectID": "posts/shiny-plumber/index.html#the-api",
    "href": "posts/shiny-plumber/index.html#the-api",
    "title": "Shiny (for R) & APIs",
    "section": "The API",
    "text": "The API\nThe API code files I created for these lab exercises are displayed in the folder tree below:4\napi/\n├── api.Rproj\n├── model.R\n├── models/\n│   └── penguin_model/\n├── my-db.duckdb\n├── plumber.R\n├── renv/\n└── renv.lock\n\n6 directories, 7 files\n\nThe model\nThe model.R file creates our model (found in the models folder). After loading the necessary packages, we establish a connection to the duckdb database (con) and register the penguins dataset.\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), \"my-db.duckdb\")\n\nduckdb::duckdb_register(con, \"penguins_raw\", palmerpenguins::penguins)\n\nWe use SQL to create a persistent table in the database and extract a subset of columns and rows for the model (df).\n\nDBI::dbExecute(\n  con,\n  \"CREATE OR REPLACE TABLE penguins AS SELECT * FROM penguins_raw\"\n)\ndf &lt;- DBI::dbGetQuery(\n  con,\n  \"SELECT bill_length_mm, species, sex, body_mass_g \n   FROM penguins \n   WHERE body_mass_g IS NOT NULL \n   AND bill_length_mm BETWEEN 30 AND 60\n   AND sex IS NOT NULL\n   AND species IS NOT NULL\"\n)\n\nFinally, we disconnect from the database.\n\nDBI::dbDisconnect(con)\n\nFor modelling, we start by using the stats::lm() function to predict body mass using bill length, species, and sex.\n\nmodel &lt;- lm(body_mass_g ~ bill_length_mm + species + sex, data = df)\n\nWe then pass the model object to the vetiver_model() and provide a model_name and description.\n\nv &lt;- vetiver::vetiver_model(\n  model,\n  model_name = \"penguin_model\",\n  description = \"Linear model predicting penguin body mass from bill length, species, and sex\",\n  save_prototype = TRUE  \n)\n\nvetiver_pin_write() ‘pins’ a trained model, an input prototype for new data, and and other model metadata to a model board.\n\nmodel_board &lt;- pins::board_folder(\"models/\")\n\nThe board_folder() from the pins package allows us write model to a board inside a folder (for sharing on network drives like Dropbox).\n\nvetiver::vetiver_pin_write(model_board, v)\n\nNow we’ve creates a vetiver model and stored it in the board_folder named models/penguin_model. The model.R file only needs to run once to build the model.\n\n\nplumber API\nIn plumber.R, we read the model into our environment using board_folder() to connect to the pins board:\n\nmodel_board &lt;- pins::board_folder(\"models/\")\n\nAnd vetiver_pin_read() will return the vetiver model object ready for deployment:\n\nv &lt;- vetiver::vetiver_pin_read(model_board, \"penguin_model\")\n\nWith the model in our environment, we’ll print some attributes to the console when the plumber API is run:\n\ncat(\"\\n=== Model Loaded Successfully ===\\n\")\ncat(\"Model name:\", v$model_name, \"\\n\")\ncat(\"Model class:\", class(v$model), \"\\n\")\ncat(\"Prototype (expected input):\\n\")\nprint(v$prototype)\ncat(\"Factor levels:\\n\")\ncat(\"  species:\", paste(levels(v$prototype$species), collapse = \", \"), \"\\n\")\ncat(\"  sex:\", paste(levels(v$prototype$sex), collapse = \", \"), \"\\n\")\ncat(\"=================================\\n\\n\")\n\n=== Model Loaded Successfully ===\n\nModel name: penguin_model \n\nModel class: butchered_lm lm \n\nPrototype (expected input):\n# A tibble: 0 × 3\n# ℹ 3 variables: bill_length_mm &lt;dbl&gt;, species &lt;fct&gt;, sex &lt;fct&gt;\n\nFactor levels:\n\nspecies: Adelie, Chinstrap, Gentoo \n\nsex: female, male \n\n=================================\n\nHelper functions\nMost of the challenges I encountered with the Shiny/API lab was due to data formatting. APIs love JSON, and I’m used to working in data.frames/tibbles, specifically factors. So I wrote a a helper function for converting incoming JSON data (strings) to the proper R types (factors) that our model expects:\n\nprep_pred_data &lt;- function(input_data) {\n  species_levels &lt;- levels(v$prototype$species)\n  sex_levels &lt;- levels(v$prototype$sex)\n  \n  data.frame(\n    bill_length_mm = as.numeric(input_data$bill_length_mm),\n    species = factor(input_data$species, levels = species_levels),\n    sex = factor(input_data$sex, levels = sex_levels),\n    stringsAsFactors = FALSE\n  )\n}\n\nprep_pred_data() uses the prototype stored in the vetiver model to get correct factor levels. If we pass a data.frame with character values for species and sex:\n\nprep_pred_data(\n  data.frame(\n    bill_length_mm = 45,\n    species = \"Adelie\",\n    sex = \"male\" )\n  )\n\nprep_pred_data() converts the characters to factors with the appropriate levels:\n#&gt; 'data.frame':    1 obs. of  3 variables:\n#&gt;  $ bill_length_mm: num 45\n#&gt;  $ species       : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1\n#&gt;  $ sex           : Factor w/ 2 levels \"female\",\"male\": 2\n\n\nHandlers\nplumber allows us to create RESTful APIs5 in R by decorating regular R functions with special comments (#*) that define API endpoints and their HTTP methods (also called verbs). These methods are listed below:\n\n\n\n\n\n\n\n\nHTTP verb\nplumber tag\nDescription\n\n\n\n\nGET\n@get\nRequest data from a server without modifying anything\n\n\nPOST\n@post\nSend data to the server to create a new resource\n\n\nPUT\n@put\nReplace an entire resource with new data\n\n\nDELETE\n@delete\nDelete a specified resource from the server\n\n\nHEAD\n@head\nSame as GET but returns only headers (no body content)\n\n\n\n\nHealth Check\nThe first plumber handler function is a standard health check (or ping). This is a GET/@get endpoint, since it’s only returning requested information (without altering anything).\n\n#* Basic health check\n#*\n#* Simple endpoint to verify the API is running. Returns a minimal response\n#* with status and timestamp.\n#*\n#* @get /ping\n#* \n#* @serializer json\n#* \nhandle_ping &lt;- function() {\n  list(\n    status = \"alive\", \n    timestamp = Sys.time()\n  )\n}\n\nhandle_ping() creates a simple endpoint to verify our API is running without performing any complex operations or database queries. Below is an illustration of how a Client or (Shiny app) would communicate with the API using this endpoint:\n\n\n\n\n\n\n\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n  \nsequenceDiagram\n    participant Client\n    participant API as plumber&lt;br&gt;API\n    participant Handler as handle_ping()\n    \n    Note over Client,Handler: Health Check\n    \n    Client-&gt;&gt;API: GET /ping\n    activate API\n    \n    API-&gt;&gt;Handler: Execute function\n    activate Handler\n    \n    Handler-&gt;&gt;Handler: Get timestamp&lt;br/&gt;Build response list\n    \n    Handler--&gt;&gt;API: {status: \"alive\",&lt;br/&gt;timestamp: Sys.time()}\n    deactivate Handler\n    \n    API-&gt;&gt;API: Serialize to JSON\n    \n    API--&gt;&gt;Client: 200 OK&lt;br/&gt;{\"status\": \"alive\",&lt;br/&gt;\"timestamp\": \"...\"}\n    deactivate API\n    \n\n\n health check \n\n\n\nThe health check will be displayed in the application to let us know if the API is running.\n\n\nPredictions\nThe primary endpoint for predictions is created with handle_predict(). This function uses the prep_pred_data() helper and returns a single numeric predicted penguin body mass (g).\n\n#* Predict penguin body mass\n#*\n#* Main prediction endpoint that accepts penguin characteristics and returns\n#* predicted body mass in grams. Supports both single predictions and batch\n#* predictions (multiple penguins in one request).\n#*\n#* @post /predict\n#* \n#* @serializer json\nhandle_predict &lt;- function(req, res) {\n  cat(\"\\n=== /predict called ===\\n\")\n  cat(\"Raw body:\", req$postBody, \"\\n\")\n  \n  result &lt;- tryCatch({ \n1    body &lt;- jsonlite::fromJSON(req$postBody)\n    cat(\"Parsed body:\\n\")\n    print(body)\n    \n    if (is.list(body) && !is.data.frame(body)) {\n      body &lt;- as.data.frame(body)\n    }\n    \n2    pred_data &lt;- prep_pred_data(body)\n    cat(\"Prepared data:\\n\")\n    print(pred_data)\n    str(pred_data)\n    \n    cat(\"Calling predict...\\n\")\n3    prediction &lt;- predict(v, pred_data)\n    cat(\"Prediction result:\\n\")\n    print(prediction)\n    cat(\"Prediction class:\", class(prediction), \"\\n\")\n    \n4    if (is.data.frame(prediction) && \".pred\" %in% names(prediction)) {\n      response &lt;- list(.pred = prediction$.pred)\n    } else if (is.numeric(prediction)) {\n      response &lt;- list(.pred = as.numeric(prediction))\n    } else {\n      response &lt;- list(.pred = as.numeric(prediction))\n    }\n    \n    cat(\"Response:\\n\")\n    print(response)\n    cat(\"=== /predict complete ===\\n\\n\")\n    \n    return(response)\n    \n5  }, error = function(e) {\n    cat(\"\\n!!! ERROR !!!\\n\")\n    cat(\"Error message:\", conditionMessage(e), \"\\n\")\n    print(e)\n    cat(\"!!! END ERROR !!!\\n\\n\")\n    \n    res$status &lt;- 500\n    return(list(\n      error = conditionMessage(e),\n      timestamp = as.character(Sys.time())\n    ))\n  })\n  \n  return(result)\n}\n\n\n1\n\nParse JSON\n\n\n2\n\nPrep data (convert strings to factors)\n\n\n3\n\nMake prediction with predict() using the vetiver model and prep_data\n\n\n4\n\nHandle different return types from vetiver\n\n\n5\n\nError handling\n\n\n\n\nThe diagram below outlines the sequence from the Client request to the plumber API, the handle_predict() and prep_pred_data() functions, and the response from the vetiver API:\n\n\n\n\n\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\nsequenceDiagram\n    \n    participant Client\n    participant API as plumber&lt;br&gt;API\n    participant Handler as handle_predict()\n    participant Helper as prep_pred_data()\n    participant VetiverObj as vetiver&lt;br&gt;model (v)\n    \n    Client-&gt;&gt;API: POST /predict&lt;br/&gt;Body: {bill_length_mm, species, sex}\n    activate API\n    \n    API-&gt;&gt;Handler: Execute&lt;br&gt;function\n    activate Handler\n    \n    Handler-&gt;&gt;Handler: Parse JSON&lt;br&gt;from req$postBody\n    \n    Handler-&gt;&gt;Handler: Convert to&lt;br&gt;data.frame&lt;br&gt;(if needed)\n    \n    Handler-&gt;&gt;Helper: prep_pred_data(body)\n    activate Helper\n    Helper-&gt;&gt;Helper: Convert strings&lt;br&gt;to factors\n    Helper--&gt;&gt;Handler: Return prepared&lt;br&gt;data\n    deactivate Helper\n    \n    Handler-&gt;&gt;VetiverObj: predict(v, pred_data)\n    activate VetiverObj\n    VetiverObj-&gt;&gt;VetiverObj: Run model&lt;br&gt;prediction\n    VetiverObj--&gt;&gt;Handler: Return&lt;br&gt;prediction\n    deactivate VetiverObj\n    \n    Handler-&gt;&gt;Handler: Format response:&lt;br/&gt;{.pred = prediction}\n    \n    Handler--&gt;&gt;API: {.pred: [value]}\n    deactivate Handler\n    \n    API--&gt;&gt;Client: 200 OK + JSON\n    deactivate API\n    \n\n\n Predictions \n\n\n\nWhen launched, the API lists the endpoints and documentation:\n\n\n\n\n\n\n\nClick to enlarge\n\n\nThe shiny app below will access two of these endpoints (/health and /predict)."
  },
  {
    "objectID": "posts/shiny-plumber/index.html#the-shiny-app",
    "href": "posts/shiny-plumber/index.html#the-shiny-app",
    "title": "Shiny (for R) & APIs",
    "section": "The Shiny App",
    "text": "The Shiny App\nThis lab also includes a Shiny app, but we will use the application from the following chapter (because it also includes logs and monitoring):\nR/\n├── app.R\n├── R.Rproj\n├── README.md\n├── renv/\n├── renv.lock\n└── shiny_app.log\nThe UI is built using bslib and a few custom HTML functions with basic CSS styling. The application server is going to be making API calls, so we’ll be using httr2 to build the request and logger to monitor these requests.\n\nLogging\nLogging is configured with logger’s:\n\nlog_threshold() sets the default log level (set to \"INFO\")\n\nlog_appender() and appender_tee() specify the log file (shiny_app.log)\n\nlog_formatter() determines the format of the logs.\n\n\nlogger::log_threshold(level = \"INFO\")\nlogger::log_appender(appender = appender_tee(file = \"shiny_app.log\"))\nlogger::log_formatter(logger::formatter_glue_or_sprintf)\n\n\n\nURL\nWe set the api_url to an internal location with port 8080 and the /predict endpoint:\n\napi_url &lt;- \"http://127.0.0.1:8080/predict\"\n\n\n\nSession token\nWe’ll display the session token in the upper-right corner of the UI. This can be used for debugging (or to reference for testing).\n\nUI\nA div() is useful here because we want the token to be visible (but not distracting from the primary functions of the app).\n\n  div(\n    style = \"position: fixed; top: 10px; right: 10px; z-index: 1000; color: #fff;\",\n    strong(\"Session\", \n      textOutput(\"log_status\", inline = TRUE)\n      )\n  )\n\n\n\nServer\nDuring startup, we will log the session and user interactions:\n\nThe priority argument determines when an observer should be executed (higher values have higher priority).\n\nthrottle “delays invalidation if the throttled reactive recently (within the time window) invalidated.”6\n\n\n1observe({\n    logger::log_info(\n      \"Shiny app started - Session: {session$token} - Host: {session$clientData$url_hostname}\"\n    )\n  }, priority = 1000)\n\n2  observe({\n    logger::log_debug(\n      \"User input changed - Session: {session$token} - bill_length: {input$bill_length} - species: {input$species} - sex: {input$sex}\"\n    )\n  }) |&gt; \n    throttle(2000)\n\n3  output$log_status &lt;- renderText({\n    paste(\"Token:\", substr(session$token, 1, 8))\n  })\n\n\n1\n\nlog app startup is set to a high priority\n\n\n2\n\nUser interactions are throttled\n\n\n3\n\nToken display\n\n\n\n\nIn the Console, we see:\nINFO [2025-12-23 06:43:29] Shiny application initialized - timestamp: 2025-12-23 06:43:29.75396 - r_version: R version 4.5.2 (2025-10-31)\nINFO [2025-12-23 06:43:30] Shiny app started - Session: 8e0d4bd326098f9c2d2d01aeaab6b1db - Host: 127.0.0.1\nIn the app, we see:\n\n\n\n\n\n\n\nClick to enlarge\n\n\n\n\n\nAPI health check\nWhen the application is launched, we want to perform a GET request to the /health endpoint to make sure the API is available to make predictions.\n\nUI\nThe response from the /health endpoint is displayed under a System Status section using a simple textOutput():\n\ncard_header(\"System Status\"),\n  card_body(\n    h5(\"API Status:\"),\n    textOutput(\"api_health\")\n    # ...\n  )\n\n\n\nServer\nThe initial ping (health check) is sent using a httr2 pipeline:\n\nrequest(): include the API url with the /ping endpoint\n\nreq_timeout(): set the timeout to 5 (seconds)\n\nreq_perform(): perform the request\n\n\n# ping\n  api_health &lt;- reactive({\n1    tryCatch({\n      logger::log_debug(\"Checking API health - Session: {session$token}\")\n      \n2      response &lt;- httr2::request(\"http://127.0.0.1:8080/ping\") |&gt;\n3        httr2::req_timeout(5) |&gt;\n4        httr2::req_perform()\n      \n      if (httr2::resp_status(response) == 200) {\n        logger::log_info(\"API health check successful - Session: {session$token}\")\n        return(\"✅ API Online\")\n      } else {\n        logger::log_warn(\n          \"API health check returned non-200 status - Session: {session$token} - status: {httr2::resp_status(response)}\"\n        )\n        return(\"⚠️ API Issues\")\n      }\n5    }, error = function(e) {\n      logger::log_error(\n        \"API health check failed - Session: {session$token} - error: {conditionMessage(e)}\"\n      )\n      return(\"❌ API Offline\")\n    })\n  })\n# display\n6  output$api_health &lt;- renderText({\n    api_health()\n  })\n\n\n1\n\nPerform request safely\n\n\n2\n\nInclude the base_url to create the httr2 request object\n\n\n3\n\nSet time limit (before error is returned)\n\n\n4\n\nPerform the request\n\n\n5\n\nFall back safely to error messages\n\n6\n\nDisplay API health check response\n\n\n\n\nThe Console displays the successful (or failed) health check status:\nINFO [2025-12-23 06:43:30] API health check successful - Session: 8e0d4bd326098f9c2d2d01aeaab6b1db\nIn the UI, we see:\n\n\n\n\n\n\n\nClick to enlarge\n\n\n\n\n\nPredictions\nThe API has multiple options for making predictions, but we’re going to focus on the /predict endpoint because it’s relatively straighforward to implement in our application.\n\nUI\nThe model inputs and display in the sidebar (using the values we know are in the subset of penguins data we used to build the model).\n\n  sidebar = sidebar(\n    sliderInput(\n      inputId = \"bill_length\", \n      label = \"Bill Length (mm)\",\n      min = 30, \n      max = 60, \n      value = 45, \n      step = 1\n    ),\n    selectInput(\n      inputId = \"sex\", \n      label = \"Sex\", \n      choices = c(\"Male\", \"Female\"), \n      selected = \"Male\"\n    ),\n    selectInput(\n      inputId = \"species\",\n      label = \"Species\",\n      choices = c(\"Adelie\", \"Chinstrap\", \"Gentoo\"),\n      selected = \"Adelie\"\n    ),\n    actionButton(\n      inputId = \"predict\", \n      label = \"Predict\", \n      class = \"btn-primary\"\n    )\n  )\n\nThe prediction results are returned along with a display of the reactive values in the server. This gives us an idea of the data format in the application before it’s sent off to the API.\n\ncard(\n  card_header(\"Penguin Parameters\"),\n  card_body(\n    verbatimTextOutput(outputId = \"vals\")\n  )\n)\n\nThe predicted mass is displayed in a value_box() with a textOutput():\n\ncard(\n  card_header(\"Predicted Mass\"),\n  card_body(\n    value_box(\n      showcase_layout = \"left center\",\n      title = \"Grams\",\n      value = textOutput(outputId = \"pred\"),\n      showcase = bs_icon(\"graph-up\"),\n      max_height = \"200px\",\n      min_height = \"200px\"\n    )\n  )\n)\n\n\n\nServer\nIn the server, the reactive value are collected, converted to a data.frame, and displayed in a plain-text format.\n\n# values \n1vals &lt;- reactive({\n2    bill_length &lt;- input$bill_length\n    species &lt;- input$species\n    sex &lt;- input$sex\n    \n3    if (bill_length &lt; 30 || bill_length &gt; 60) {\n      logger::log_warn(\n        \"Bill length out of typical range - Session: {session$token} - bill_length: {bill_length}\"\n      )\n    }\n    \n    if (is.null(species) || is.null(sex)) {\n      logger::log_error(\n        \"Missing required inputs - Session: {session$token} - species_null: {is.null(species)} - sex_null: {is.null(sex)}\"\n      )\n      return(NULL)\n    }\n    \n4    data &lt;- data.frame(\n      bill_length_mm = bill_length,\n      species = species,\n      sex = tolower(sex)\n    )\n    \n    logger::log_debug(\n      \"Input data prepared - Session: {session$token} - data: {jsonlite::toJSON(data, auto_unbox = TRUE)}\"\n    )\n    \n    return(data)\n  })\n# display\n5  output$vals &lt;- renderPrint({\n    data &lt;- vals()\n    if (!is.null(data)) {\n      logger::log_debug(\"Displaying input values to user - Session: {session$token}\")\n      return(data)\n    } else {\n      return(\"Invalid inputs\")\n    }\n  })\n\n\n1\n\nReactive values from inputs\n\n\n2\n\nInputs (bill_length, species, and sex)\n\n3\n\nInput validation\n\n\n4\n\nPrepare data\n\n\n5\n\nDisplay structure of inputs\n\n\n\n\nIn the UI, we can see the default values displayed as a data.frame:\n\n\n\n\n\n\n\nClick to enlarge\n\n\nIf a user changes the inputs, the reactive values will also update. To make a prediction, we click the Predict button with the selected inputs.\n\n# prediction \n1  pred &lt;- reactive({\n2    request_start &lt;- Sys.time()\n3    request_data &lt;- vals()\n    \n4    if (is.null(request_data)) {\n      logger::log_error(\n        \"Cannot make prediction with invalid inputs - Session: {session$token}\"\n      )\n      return(\"❌ Invalid inputs\")\n    }\n    \n    logger::log_info(\n      \"Starting prediction request - Session: {session$token} - request_data: {jsonlite::toJSON(request_data, auto_unbox = TRUE)}\"\n    )\n    \n5    tryCatch({\n6      showNotification(\n        \"Predicting penguin mass...\", \n        type = \"default\", \n        duration = 3\n      )\n      \n7      response &lt;- httr2::request(api_url) |&gt;\n        httr2::req_method(\"POST\") |&gt;\n        httr2::req_body_json(request_data, auto_unbox = FALSE) |&gt;\n        httr2::req_timeout(30) |&gt;\n        httr2::req_perform()\n      \n8      response_time &lt;- as.numeric(\n        difftime(Sys.time(), request_start, units = \"secs\")\n      )\n9      response_data &lt;- httr2::resp_body_json(response)\n      \n      \n10      prediction_value &lt;- if (is.list(response_data$.pred)) {\n        # If .pred is a list, get first element\n        as.numeric(response_data$.pred[[1]])\n      } else {\n        # If .pred is already numeric\n        as.numeric(response_data$.pred[1])\n      }\n      \n      logger::log_info(\n        \"Prediction successful - Session: {session$token} - response_time_sec: {round(response_time, 3)} - prediction: {prediction_value}\"\n      )\n      \n11      if (response_time &gt; 5) {\n        logger::log_warn(\n          \"Slow API response - Session: {session$token} - response_time_sec: {response_time}\"\n        )\n      }\n      \n12      showNotification(\n        \"✅ Prediction successful!\", \n        type = \"message\", \n        duration = 3\n      )\n      \n      return(prediction_value)\n      \n    }, error = function(e) {\n      \n13      error_msg &lt;- conditionMessage(e)\n      response_time &lt;- as.numeric(\n        difftime(Sys.time(), request_start, units = \"secs\")\n      )\n      \n      logger::log_error(\n        \"Prediction request failed - Session: {session$token} - error: {error_msg} - response_time_sec: {round(response_time, 3)}\"\n      )\n      \n14      if (grepl(\"Connection refused|couldn't connect\", error_msg, ignore.case = TRUE)) {\n        user_msg &lt;- \"API not available - is the server running on port 8080?\"\n        logger::log_error(\"API connection refused - Session: {session$token}\")\n      } else if (grepl(\"timeout|timed out\", error_msg, ignore.case = TRUE)) {\n        user_msg &lt;- \"Request timed out - API may be overloaded\"\n        logger::log_warn(\"API timeout occurred - Session: {session$token}\")\n      } else {\n        user_msg &lt;- paste(\"API Error:\", substr(error_msg, 1, 50))\n        logger::log_error(\n          \"Unknown API error - Session: {session$token} - error: {error_msg}\"\n        )\n      }\n      \n15      showNotification(\n        paste(\"❌\", user_msg), \n        type = \"error\", \n        duration = 5\n      )\n      \n16      return(paste(\"❌\", user_msg))\n    })\n  }) |&gt; \n    bindEvent(input$predict, ignoreInit = TRUE)\n  \n  # outputs ----\n  output$pred &lt;- renderText({\n17    prediction &lt;- pred()\n    \n18    if (is.numeric(prediction)) {\n      result &lt;- paste(round(prediction, 1), \"grams\") \n      logger::log_info(\n        \"Displaying prediction to user - Session: {session$token} - display_value: {result}\"\n      )\n      return(result)\n    } else {\n      logger::log_debug(\n        \"Displaying error message to user - Session: {session$token} - message: {prediction}\"\n      )\n      return(as.character(prediction))\n    }\n  })\n\n\n1\n\nCreate reactive for predictions\n\n\n2\n\nRequest start time\n\n\n3\n\nRequest data converted to request_data\n\n\n4\n\nInput validation\n\n\n5\n\nSafely perform request\n\n\n6\n\nNotification for starting prediction\n\n\n7\n\nPerform POST request using request_data\n\n\n8\n\nCreate response time\n\n\n9\n\nConvert data to JSON\n\n\n10\n\nExtract prediction - handle different response formats\n\n\n11\n\nPerformance monitoring\n\n\n12\n\nNotification for successful prediction\n\n\n13\n\nConstruct and display error message\n\n\n14\n\nClassify error types by API response\n\n\n15\n\nNotification for failed prediction\n\n\n16\n\nError for failed prediction\n\n\n17\n\nCreate prediction from reactive pred()\n\n\n18\n\nFormat prediction for display\n\n\n\n\nIn the Console, we see the following:\nINFO [2025-12-23 08:32:56] Starting prediction request - Session: 8e0d4bd326098f9c2d2d01aeaab6b1db - request_data: [{\"bill_length_mm\":51,\"species\":\"Gentoo\",\"sex\":\"female\"}]\nINFO [2025-12-23 08:32:56] Prediction successful - Session: 8e0d4bd326098f9c2d2d01aeaab6b1db - response_time_sec: 0.293 - prediction: 4923.5183\nINFO [2025-12-23 08:32:56] Displaying prediction to user - Session: 8e0d4bd326098f9c2d2d01aeaab6b1db - display_value: 4923.5 grams\nIn the UI, we see the following:\n\n\n\n\n\n\n\nClick to enlarge\n\n\n\n\n\nLogs\nThe System Status section includes a reactive display of the log file (recent_logs) and a timestamp for the last time the application was run (log_timestamp).\n\nUI\n\nh5(\"Recent Logs:\"),\n  div(\n    style = \"font-family: 'Ubuntu Mono', monospace; font-size: 12px; background-color: #f8f9fa; padding: 10px; border-radius: 5px;\",\n    verbatimTextOutput(\"recent_logs\", placeholder = TRUE)\n  ),\nh6(\"Last updated:\", \n    textOutput(\"log_timestamp\", inline = TRUE)\n  )\n\n\n\nServer\nThe logs are created using reactiveFileReader() and the log file (shiny_app.log) to update the display in the UI. This is a handy way of viewing the log outputs in the UI (without having to open the log file).\nThe final output is the timestamp.\n\n# log file \n1log_file_content &lt;- reactiveFileReader(\n  intervalMillis = 1000,\n  session = session,\n2  filePath = \"shiny_app.log\",\n  readFunc = function(filePath) {\n    if (file.exists(filePath)) {\n      lines &lt;- readLines(filePath, warn = FALSE)\n      mod_time &lt;- file.mtime(filePath)\n3      list(\n        lines = lines,\n        last_mod = mod_time,\n        total_lines = length(lines)\n      )\n    } else {\n      list(\n        lines = character(0),\n        last_mod = Sys.time(),\n        total_lines = 0\n      )\n    }\n  }\n)\n# display\n  output$recent_logs &lt;- renderText({\n4    log_data &lt;- log_file_content()\n    \n5    if (length(log_data$lines) &gt; 0) {\n      recent_lines &lt;- if (log_data$total_lines &gt; 5) {\n        tail(log_data$lines, 5)\n      } else {\n        log_data$lines\n      }\n      \n6      logger::log_debug(\n        \"Updating recent logs display - Session: {session$token} - showing {length(recent_lines)} lines\"\n      )\n      paste(recent_lines, collapse = \"\\n\")\n    } else {\n      \"No logs available\"\n    }\n  })\n  \n7  output$log_timestamp &lt;- renderText({\n    log_data &lt;- log_file_content()\n    format(log_data$last_mod, \"%Y-%m-%d %H:%M:%S\")\n  })\n\n\n1\n\nReactive file reader for log monitoring\n\n\n2\n\nThe shiny_app.log file we specified in the log configuration\n\n\n3\n\nReturn as list\n\n\n4\n\nCreate log_data object\n\n\n5\n\nOnly return the top five lines of the log file\n\n\n6\n\nLog message for debugging log display\n\n\n7\n\nLog timestamp\n\n\n\n\nIn the UI, we see the top 5 lines of the shiny_app.log file and the timestamp.\n\n\n\n\n\n\n\nClick to enlarge\n\n\nThe app includes a log for the session ending, too:\nINFO [2025-12-23 08:53:16] User session ended - Session: 5f61a8ce042d21d5e6a6702127f24946"
  },
  {
    "objectID": "posts/shiny-plumber/index.html#recap",
    "href": "posts/shiny-plumber/index.html#recap",
    "title": "Shiny (for R) & APIs",
    "section": "Recap",
    "text": "Recap\nWe’ve covered how to create a vetiver model (with duckdb) with plumber and access this API using a shiny app. The httr2 package is used to make API requests and logger is used throughout the application to log behaviors and actions.\n\n\n\n\n\n\n\nClick to enlarge\n\n\nAccess the code for the API and app in my DO4DS: Lab Solutions."
  },
  {
    "objectID": "posts/shiny-plumber/index.html#footnotes",
    "href": "posts/shiny-plumber/index.html#footnotes",
    "title": "Shiny (for R) & APIs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDevOps for Data Science: Step 1: Put the data in DuckDB↩︎\nDevOps for Data Science: Step 2: Point the EDA and modeling scripts to the database↩︎\nDevOps for Data Science: Step 3: Build an app that calls the API↩︎\nThese files can also be found in this GitHub repo..↩︎\nWhat is a RESTful API? Appsilon has a great tutorial on using plumber. This is also a great tutorial (but is uses caret for modeling).↩︎\nRead more in the Shiny documentation on debounce/throttle.↩︎"
  },
  {
    "objectID": "series.html",
    "href": "series.html",
    "title": "Series",
    "section": "",
    "text": "These posts focus on testing Shiny applications with testthat, shiny’s testServer() function, and shinytest2.\n\n\n\n\n\n\nTitle\n\n\n\nSubtitle\n\n\n\n\n\n\n\n\nBehavior Driven Unit Tests\n\n\nPart 1 (series): testthat’s BDD testing functions\n\n\n\n\n\n\nTesting Non-Package Shiny Apps\n\n\nPart 2 (series): Using testthat with Shiny outside of a package\n\n\n\n\n\n\nTesting Shiny modules\n\n\nPart 3 (series): module server functions and testServer()\n\n\n\n\n\n\nShiny System Tests With shinytest2\n\n\nPart 4 (series): writing efficient system tests\n\n\n\n\n\n\nTesting rhino apps\n\n\nPart 5 (series): Testing with box modules\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nNoteTesting details\n\n\n\n\n\n\n\n\ntestthat is a popular unit testing framework that allows R package developers to create tests scripts for functions and logic systematically. In a shiny app-package, it’s used for testing the non-reactive components (i.e., utility functions). This includes functions for data processing, plots, modeling, and other code that’s part of the package. However, it is not designed to work with shiny’s reactive model.\n\nPost: Behavior Driven Unit Tests: This post covers unit testing a set of utility functions with testthat. You can also read the documentation from the package website, in R packages, and in Mastering Shiny. The app-package for this post is stored in this Github Repo.\nPost: Testing Non-Package Shiny Apps: Your shiny app should be developed as a package, but this isn’t always the case. If you’d like to test your application’s code without converting it to a package, check out the second post (and the GitHub repo).\n\n\n\n\ntestServer() comes from the shiny package and is designed to test the server-side logic of your app. These tests can be used to simulate user inputs and verify the corresponding outputs. testServer() can also test the functionality of module server functions (reactivity, outputs, and any returned values) in isolation from their UI function counterparts. However, testServer() doesn’t capture how UI elements are rendered or simulate key user interactions (i.e., execution paths) through the application.\n\nPost: Testing Shiny Modules: If you’ve built your shiny application as a package and it contains modules, this post covers testing module server functions using the examples from the ‘Modules’ chapter of Mastering Shiny. The code and examples are in this GitHub repo\n\n\n\n\nshinytest2 is designed to perform end-to-end testing of shiny apps. These tests can capture a shiny app’s current state (i.e., a snapshot) and compare it with a previously saved (or expected) states. Snapshots are useful for end-to-end testing because they can simulate key user interaction in a way that unit tests and testServer() can’t (i.e., the delay between input changes and rendering updated outputs, specific sequences of selections on action buttons, radio buttons, etc.). shinytest2 tests are resource-intensive, so it’s recommended to write these tests after writing testthat unit tests and testServer() tests.\n\nPost: Shiny system tests with shinytest2: This post picks up where the previous post left off with the shinytest2 package. The app-package used in the examples is stored in this GitHub repo.\n\nIn summary, use testthat for unit testing utility/helper functions, then testServer() for the server-side logic, and finish off with shinytest2 tests for end-to-end functionality of your shiny app. These tools complement each other to provide a comprehensive testing framework."
  },
  {
    "objectID": "series.html#testing-shiny-apps",
    "href": "series.html#testing-shiny-apps",
    "title": "Series",
    "section": "",
    "text": "These posts focus on testing Shiny applications with testthat, shiny’s testServer() function, and shinytest2.\n\n\n\n\n\n\nTitle\n\n\n\nSubtitle\n\n\n\n\n\n\n\n\nBehavior Driven Unit Tests\n\n\nPart 1 (series): testthat’s BDD testing functions\n\n\n\n\n\n\nTesting Non-Package Shiny Apps\n\n\nPart 2 (series): Using testthat with Shiny outside of a package\n\n\n\n\n\n\nTesting Shiny modules\n\n\nPart 3 (series): module server functions and testServer()\n\n\n\n\n\n\nShiny System Tests With shinytest2\n\n\nPart 4 (series): writing efficient system tests\n\n\n\n\n\n\nTesting rhino apps\n\n\nPart 5 (series): Testing with box modules\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nNoteTesting details\n\n\n\n\n\n\n\n\ntestthat is a popular unit testing framework that allows R package developers to create tests scripts for functions and logic systematically. In a shiny app-package, it’s used for testing the non-reactive components (i.e., utility functions). This includes functions for data processing, plots, modeling, and other code that’s part of the package. However, it is not designed to work with shiny’s reactive model.\n\nPost: Behavior Driven Unit Tests: This post covers unit testing a set of utility functions with testthat. You can also read the documentation from the package website, in R packages, and in Mastering Shiny. The app-package for this post is stored in this Github Repo.\nPost: Testing Non-Package Shiny Apps: Your shiny app should be developed as a package, but this isn’t always the case. If you’d like to test your application’s code without converting it to a package, check out the second post (and the GitHub repo).\n\n\n\n\ntestServer() comes from the shiny package and is designed to test the server-side logic of your app. These tests can be used to simulate user inputs and verify the corresponding outputs. testServer() can also test the functionality of module server functions (reactivity, outputs, and any returned values) in isolation from their UI function counterparts. However, testServer() doesn’t capture how UI elements are rendered or simulate key user interactions (i.e., execution paths) through the application.\n\nPost: Testing Shiny Modules: If you’ve built your shiny application as a package and it contains modules, this post covers testing module server functions using the examples from the ‘Modules’ chapter of Mastering Shiny. The code and examples are in this GitHub repo\n\n\n\n\nshinytest2 is designed to perform end-to-end testing of shiny apps. These tests can capture a shiny app’s current state (i.e., a snapshot) and compare it with a previously saved (or expected) states. Snapshots are useful for end-to-end testing because they can simulate key user interaction in a way that unit tests and testServer() can’t (i.e., the delay between input changes and rendering updated outputs, specific sequences of selections on action buttons, radio buttons, etc.). shinytest2 tests are resource-intensive, so it’s recommended to write these tests after writing testthat unit tests and testServer() tests.\n\nPost: Shiny system tests with shinytest2: This post picks up where the previous post left off with the shinytest2 package. The app-package used in the examples is stored in this GitHub repo.\n\nIn summary, use testthat for unit testing utility/helper functions, then testServer() for the server-side logic, and finish off with shinytest2 tests for end-to-end functionality of your shiny app. These tools complement each other to provide a comprehensive testing framework."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "@mjfrigaard",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nShiny (for R) & APIs\n\n\n\n\n\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Shiny Apps in R Packages\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPositron\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPython Apps\n\n\n\n\n\n\n\n\nJul 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVS Code, meet Quarto.\n\n\n\n\n\n\n\n\nJul 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nShiny system tests with shinytest2\n\n\n\n\n\n\n\n\nOct 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Shiny modules\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDebugging in RStudio\n\n\n\n\n\n\n\n\nSep 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Non-Package Shiny Apps\n\n\n\n\n\n\n\n\nAug 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBehavior Driven Unit Tests\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWriting modular code with box\n\n\n\n\n\n\n\n\nJun 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npurrr updates (v1.0.0)\n\n\n\n\n\n\n\n\nFeb 5, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "@mjfrigaard",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nShiny (for R) & APIs\n\n\n\nAPIs\n\nShiny\n\nPackages\n\n\n\n\n\n\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Shiny Apps in R Packages\n\n\n\nQuarto\n\nShiny\n\nPackages\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPositron\n\n\n\nPackages\n\nPositron\n\nShiny\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPython Apps\n\n\n\nPython\n\nVSCode\n\n\n\n\n\n\n\n\n\nJul 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVS Code, meet Quarto.\n\n\n\nPython\n\nVSCode\n\nQuarto\n\n\n\n\n\n\n\n\n\nJul 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nShiny system tests with shinytest2\n\n\n\nShiny\n\nTesting\n\n\n\n\n\n\n\n\n\nOct 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Shiny modules\n\n\n\nShiny\n\nTesting\n\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDebugging in RStudio\n\n\n\nShiny\n\nDebugging\n\n\n\n\n\n\n\n\n\nSep 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Non-Package Shiny Apps\n\n\n\nShiny\n\nTesting\n\n\n\n\n\n\n\n\n\nAug 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBehavior Driven Unit Tests\n\n\n\nShiny\n\nTesting\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWriting modular code with box\n\n\n\nPackages\n\nBox\n\n\n\n\n\n\n\n\n\nJun 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npurrr updates (v1.0.0)\n\n\n\nIteration\n\n\n\n\n\n\n\n\n\nFeb 5, 2023\n\n\n\n\n\nNo matching items"
  }
]