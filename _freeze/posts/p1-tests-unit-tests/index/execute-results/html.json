{
  "hash": "f595c4919d23a797752e53d2c278a262",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Behavior Driven Unit Tests\" \nsubtitle: \"Part 1: testthat's BDD testing functions\"\nauthor: \"Martin Frigaard\"\ndate: \"2023-05-01\"\ncategories: [shiny, testing]\nimage: \"image.png\"\ntoc: true\ntoc-depth: 5\ntoc-title: 'Contents'\ntoc-location: \"left\"\n# code-block-border-left: true\ncode-block-bg: \"#f8f8f8\"\ncode-block-border-left: \"#e8e8e8\"\ncode-fold: show\ncode-summary: 'show/hide'\ncallout-icon: false\n\nfreeze: true\n\nknitr:\n  opts_chunk: \n    collapse: true\n\nexecute:\n  echo: true\n  warning: false\n  eval: false\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"packages\"}\nlibrary(testthat)\nlibrary(lobstr)\nlibrary(dplyr)\nlibrary(shiny)\nlibrary(covr)\n```\n:::\n\n\n\n\nThis post is the first in a series on testing Shiny applications. We'll cover developing and testing a set of utility functions for a Shiny app-package using [`testhat`](https://testthat.r-lib.org/). If you'd like to follow along, all the code we'll be using is contained in the [`utap` branch](https://github.com/mjfrigaard/sapkgs/tree/utap) of the `sapkgs` repo on GitHub.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# renv::install(\"mjfrigaard/utap\")\nlibrary(utap)\n```\n:::\n\n\nTesting the code in Shiny app-packages can be more complicated than testing the code in a typical R package, because app-packages contain two types of code: \n\n1) **Application code**: functions designed to run the application  (i.e., the `ui` and `server` functions, modules, standalone app functions will a call to `shinyApp()`, etc.)\n\n2) **Everything else**: functions or code used for connecting to databases, uploading, importing, or manipulating data, building visualizations and/or tables, generating custom HTML layouts, etc. The non-application code and functions in app-packages are typically referred to as '[utility](https://engineering-shiny.org/build-app-golem.html?#submodules-and-utility-functions)' or '[helper](https://mastering-shiny.org/scaling-functions.html#file-organisation)' functions\n\nThese two types of code require different types of tests. Utility functions are usually accompanied by unit tests similar to the tests you'd find in a standard R package[^standard-r-pkg], while the application's reactive code can be tested using Shiny's [`testServer()`](https://shiny.posit.co/r/reference/shiny/1.7.0/testserver) function, and the system tests can be built using the [`shinytest2` package](https://rstudio.github.io/shinytest2/). \n\n[^standard-r-pkg]: Learn more about R packages in [R Packages, 2ed](https://r-pkgs.org/testing-basics.html)\n\nThis post will cover writing unit tests for a set of utility functions using [`testthat`](https://testthat.r-lib.org/) and [`covr`](https://covr.r-lib.org/). Any tips or time-savers I've found will be in green callout boxes:\n\n\n\n:::: {.callout-tip collapse='false' appearance='default' icon=false}\n\n## [TIP!]{style='font-weight: bold; font-size: 1.15em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\nThis is a tip!\n\n::: \n\n::::\n\n\n## What are unit tests?\n\n::: {.column-margin}\n![](testthat.png){width=40%}\n:::\n\n\n> \"*A unit test is a piece of code that invokes a unit of work and checks one specific end result of that unit of work. If the assumptions on the end result turn out to be wrong, the unit test has failed. A unit test’s scope can span as little as a method or as much as multiple classes.*\" - [The Art of Unit Testing, 2nd edition](https://www.manning.com/books/the-art-of-unit-testing-second-edition)\n\nThinking of functions as 'units of work' and their desired behavior as an 'end results' provides a useful mental model (especially during [behavior-driven development](https://en.wikipedia.org/wiki/Behavior-driven_development). These terms also align nicely with the testing advice offered by  [`testthat`](https://r-pkgs.org/testing-design.html#sec-testing-design-principles): \n\n> *Strive to test each behaviour in one and only one test. Then if that behaviour later changes you only need to update a single test.*\n\nIn app-packages, the `testthat` package provides a comprehensive and flexible framework for performing unit tests. \n\n\n### testthat\n\nGet started with `testthat` by running [`usethis::use_testthat()`](https://usethis.r-lib.org/reference/use_testthat.html). This function will create following files and folders: \n\n\n\n```{.default}\ntests/\n  ├── testthat/\n  └── testthat.R\n```\n\n\nTo create new tests, we'll run `usethis::use_test(\"<name>\")` (with `\"select_class\"` being the name of the function we'd like to test).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nusethis::use_test(\"select_class\")\n```\n:::\n\n\n```{.default}\n✔ Setting active project to '/projects/apps/utap'\n✔ Writing 'tests/testthat/test-select_class.R'\n• Modify 'tests/testthat/test-select_class.R'\n```\n\n\n\n#### Test files\n\nNew test files are be created and opened from the `tests/testthat/` folder (with a `test-` prefix). Each function we're testing should have it's own `.R` file the `R/` folder and a corresponding `test-` file in the `tests/testthat/` folder (we'll see how this helps with interactive testing in the IDE below). The initial contents of a new test file contains the boilerplate code below:\n\n:::: {layout=\"[50, 50]\"  layout-valign=\"top\"}\n\n``` r\ntest_that(\"multiplication works\", {\n  expect_equal(2 * 2, 4)\n})\n```\n\n![testthat test file](testthat-test-file.png){width=50%}\n\n::::\n\n\n#### Test structure \n\n`test_that()` sets the test \"scope\" or \"execution environment\", and encapsulates the test code and expectations. Note the use of curly brackets after the `code` argument:\n\n![`testthat` test](testthat-tests.png){#fig-tests width=90%}\n\n#### Expectations\n\nTest expectations are the code that comes into direct contact with the *unit of work* and *end result* for each function. It's likely we'll have multiple expectations for any given function, so we store these in **tests** and use the `desc`  to describe the test context (all `testthat` expectations have an `expect_*` prefix):\n\n:::: {layout=\"[50, 50]\"  layout-valign=\"center\"}\n\n![`expect_*` functions](testthat-test-expectations.png){width=90%}\n\n![expectations](testthat-expectation.png){width=50% height='50%'}\n    \n::::\n\n### Keyboard shortcuts \n\nI **highly** recommend using a shortcut while developing tests because it will improve your ability to iterate quickly.[^rpkgs-keyboard-shortcuts] \n\n[^rpkgs-keyboard-shortcuts]: R Packages, 2ed also [suggests](https://r-pkgs.org/testing-basics.html#run-tests) binding `test_active_file()` and `test_coverage_active_file()` to keyboard shortcuts. \n\n::: {layout=\"[54, -1, 45]\" layout-valign=\"bottom\"}\n\n#### **`devtools` function**\n\n[`test()`]{style=\"font-weight: bold; font-size: 0.95em\"}\n\n#### **Keyboard shortcut**\n\n[<kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>T</kbd>]{style=\"font-weight: bold; font-size: 0.80em\"}\n\n:::\n\n::: {layout=\"[54, -1, 45]\" layout-valign=\"bottom\"}\n\n[`test_active_file()`]{style=\"font-weight: bold; font-size: 0.95em\"}\n\n[<kbd>Ctrl/Cmd</kbd> + <kbd>T</kbd>]{style=\"font-weight: bold; font-size: 0.80em\"} \n\n:::\n\n::: {layout=\"[54, -1, 45]\" layout-valign=\"bottom\"}\n\n[`test_coverage_active_file()`]{style=\"font-weight: bold; font-size: 0.95em\"}\n\n[<kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>R</kbd>]{style=\"font-weight: bold; font-size: 0.80em\"} \n\n:::\n\n## Behavior-Driven Development\n\nBehavior-driven development (or behavior-driven testing) is helpful if you find yourself communicating with users and/or stakeholders while developing Shiny apps. BDD centers around  \"*conversation and examples to specify how you expect a system to behave*\"[^bdd-reference] and it's supported with `testthat`s `describe()` and `it()` functions.[^bdd-testthat]  \n\n[^bdd-reference]: Read more about behavior-driven development in [BDD in Action, 2ed](https://www.manning.com/books/bdd-in-action-second-edition)\n\n[^bdd-testthat]: `describe()` and `it()` are discussed in the [`testthat` documentation.](https://testthat.r-lib.org/reference/describe.html)\n\n\n\n:::: {.callout-note collapse='false' appearance='default' icon=false}\n\n## [BDD features & scenarios]{style='font-weight: bold; font-size: 1.15em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\n\nIn BDD, requirements are written plain language 'feature files' using a series of keywords:   \n\n```bash\nFeature:  \n  As a \n  I want \n  So that\n  \n  Background:\n    Given \n    And  \n    \n  Scenario:  \n    When \n    And  \n    Then \n    \n```\n\nThe `Feature` is a high-level description (usually with a title *and* description). `As a` describes the end user the feature is intended for, their needs (`I want`), and the desired result (`So that`). \n\nThe `Background` can include any steps or conditions that exist *before* each scenario. \n\nA `Scenario` is a series of steps outlining a concrete examples that illustrates a feature. `When` is used to describe an event, or an action. `Then` describes what will verify the expected outcome is observable by the user. `And` combines `Given` with `When` or `Then`.\n\nRead more about Gherkin on the [Cucumber website.](https://cucumber.io/docs/gherkin/reference/).\n\n::: \n\n::::\n\n\n### Specifications\n\nIn [R packages](https://r-pkgs.org/testing-basics.html#run-tests), micro-iteration is defined as, \"*the interactive phase where you initiate and refine a function and its tests in tandem.*\" In app development, this stage might after you've received needs or specifications by an end-user or stakeholder. \n\nIf we're using [BDD](https://en.wikipedia.org/wiki/Behavior-driven_development), we'll translate these specifications into functional requirements, then start writing test(s). After outlining the tests, we'll write the function(s) to pass the test.\n\n`testthat`'s `describe()` and `it()` functions and Gherkin syntax can clarify this process because we can *describe* what *it* is we want to test before getting stuck writing any test code.\n\nLet's assume we've been asked to design an application that automatically to populates the user drop-downs with variables based on their format: binary, numeric, categorical, and--a subset of categorical--facet.[^hypothetical-args]\n\n[^hypothetical-args]: The variable names would automatically populate the `choices` argument for  a `selectInput()`\n\n1. **Features & Background**: use the `description` (entered as a character string in the first argument of `describe()`) to capture the \"unit of work\" for each function. `Feature` and `Background` information can be included in nested `describe()` blocks. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n})\n```\n:::\n\n\n2. **Scenario**: Every new `Scenario` keyword should have a corresponding `it()` or `test_that()` call.[^it-test_that] Try to be as specific as possible (while staying short and sweet) when describing the scenarios. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n    it(\"Scenario: Given a data frame with a mix of columns\n      When I call pull_cols() with type 'binary'\n      Then I should receive a list of 'binary' column names\", code = {\n      \n    })\n  \n})\n```\n:::\n\n\n3. **Expectations**: The `Then` keywords capture our expectations (and `expect_*()` function). In this case, it's the '*list of column names that match the `\"<type>\"` criteria*'\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"\n  Feature: Pull column names by type from a data frame or tibble\n  Background: Given a data frame or tibble \n    And it has binary, character, and numeric columns\", code = {\n  \n    it(\"Scenario: Given a data frame with a mix of columns\n      When I call pull_cols() with type 'binary'\n      Then I should receive a list of 'binary' column names\", code = {\n      \n      expect_equal(is.logical(object))\n      \n    })\n  \n})\n```\n:::\n\n\n[^it-test_that]: `testthat`'s `it()` function is essentially identical to [`test_that()`](https://testthat.r-lib.org/reference/describe.html#details).\n\nIt's worth noting that, at least conceptually, scenarios and expectations arise first. We're usually working backwards from a desired \"end result\" a function is supposed to produce (i.e., compute a value, download a file, create a column, etc.).\n\n#### Requirements \n\nFor example, calling `pull_cols(df, \"bin\")` would 'pull' all the binary columns from an input `data.frame` or `tibble` (the example below uses `palmerpenguins::penguins`):\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npull_cols(palmerpenguins::penguins, type = \"bin\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n##  sex \n## \"sex\" \n```\n:::\n\n\nThe return values can be passed to `updateSelectInput()` in the `server` to provide column names by `type` (i.e., numeric, binary, etc). `pull_colls()` can be used to quickly group variables into groups for data visualizations or table displays. \n\nFor example, categorical variables with 3-5 levels can be mapped to a facet layer (if using `ggplot2`). See the hypothetical UI output example below:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# UI code\nselectInput(\n  inputId = ns(\"facet\"),\n  label = \"Select Facet Column\",\n  choices = c(\"\", NULL)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# pull facet columns from data\nfacet_cols <- reactive({\n  pull_cols(df = ds(), type = \"facet\")\n})\n# update facet inputs\nobserve({\n  updateSelectInput(\n    session = session,\n    inputId = \"facet\",\n    choices = facet_cols()\n  )\n}) |>\n  bindEvent(facet_cols())\n```\n:::\n\n\nIn the example above, `pull_cols()` is passed a reactive dataset (`data()`), and the output is used to update the `selectInput()`:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"form-group shiny-input-container\">\n<label class=\"control-label\" id=\"num_cols-label\" for=\"num_cols\">Select Facet Column</label>\n<div>\n<select id=\"num_cols\" class=\"shiny-input-select\"><option value=\"species\" selected>species</option>\n<option value=\"island\">island</option></select>\n<script type=\"application/json\" data-for=\"num_cols\" data-nonempty=\"\">{\"plugins\":[\"selectize-plugin-a11y\"]}</script>\n</div>\n</div>\n```\n\n:::\n:::\n\n\n<br>\n\nThe first step of `pull_cols()` will be to identify and extract columns based on their class, so we'll create a test for `select_class()`, a function with a `class` parameter that supports multiple column types. The `roxygen2` documentation for `select_class()` is below:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"show/hide roxygen2 documentation\"}\n#' Select Column Class\n#'\n#' `select_class()` selects columns from a data.frame based on the specified\n#' `class`. Options include logical, integer, double, character, factor, ordered,\n#' and list column types.\n#'\n#' @param df A `data.frame` from which columns will be selected.\n#' @param class Character vector specifying the class(es) of columns to select.\n#'   Supported values are:\n#'   * \"logical\" (\"lo\")  \n#'   * \"integer\" (\"in\")  \n#'   * \"double\" (\"do\")  \n#'   * \"character\" (\"ch\")  \n#'   * \"factor\" (\"fa\")   \n#'   * \"ordered\" (\"or\")   \n#'   * \"list\" (\"li\")\n#'   \n#' @param return_tbl Logical indicating whether to return the result as a\n#'   `data.frame`. If `FALSE`, a vector of selected column names is returned.\n#'\n#' @return A `data.frame` or vector of column names, depending on `return_tbl`.\n```\n:::\n\n\nWe've also included a `return_tbl` argument that allows `select_class()` to return the column names.\n\n#### Abstract folder trees\n\nWhile developing R functions, I've found the `ast()` function from the [`lobstr` package](https://lobstr.r-lib.org/reference/ast.html) can be great for keeping track of nested function calls.\n\n`select_class()` will have a nested `is_class()` function, which contains a series of test for objects (i.e., `is.logical()`, `is.integer()`, etc.). To keep track of nested functions in `R/` files, sometimes I'll outline the function in an abstract function tree and store this in a [vignette](https://github.com/mjfrigaard/sapkgs/blob/utap/vignettes/utap.Rmd).[^nested-test-location]\n\n[^nested-test-location]: Both functions are placed in `R/select_class.R`, and both unit tests are also in the `tests/testthat/test-select_class.R` file. \n\nBelow is an example tree for `select_class()`:\n\n::: {layout=\"[25,75]\" layout-valign=\"top\"}\n\n**Syntax**: \n\n``` r\nlobstr::ast(\n    select_class(\n      is_class()\n      )\n)\n```\n\n**Output**: \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n█─select_class \n└─█─is_class \n```\n\n\n:::\n:::\n\n\n:::\n\nThe tree above is simple--it only has two functions so far--but as packages grow these abstract displays become more important for tracking function calls (and tests!).\n\n\n\n:::: {.callout-tip collapse='false' appearance='default' icon=false}\n\n## [TIP! Function Names]{style='font-weight: bold; font-size: 1.15em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\nComing up with names for functions can be challenging. I like to follow the [`tidyverse` style guide](https://style.tidyverse.org/syntax.html#object-names) and use short verbs as a prefix (`make_`, `get_`, `check_` etc.) that will give 'future' me hints as to their behavior.\n  \nI like to stick to naming conventions I'm familiar with. For example, `select_class()` has similar behavior to `dplyr::select()`, and `pull_cols()` is more like `dplyr::pull()`.\n  \n\n::: \n\n::::\n\n\nOutlining functions with `lobstr::ast()` can helpful if we plan on iterating multiple, smaller functions. For example, before making a binary vector of column names, we need to verify the column has only two values. Binary variables can come in multiple flavors (logical, integer, character, factor, ordered, etc.), so `check_binary_vec()` will have a series of 'checks' for each column type. \n\nBelow is an abstract folder tree outlining `pull_binary_cols()`, the function called to extract a named character vector of binary column names:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n█─pull_binary_cols \n├─█─select_class \n│ └─█─is_class \n└─█─make_binary_vec \n  └─█─check_binary_vec \n    ├─█─check_log_binary \n    ├─█─check_int_binary \n    ├─█─check_chr_binary \n    ├─█─check_fct_binary \n    └─█─check_ord_binary \n```\n\n\n:::\n:::\n\n\n`pull_binary_cols()` calls `select_class()` then passes the selected columns to `make_binary_vec()`, where `check_binary_vec()` determines if it's one of the five types of possible binary variables.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npull_binary_cols(palmerpenguins::penguins)\n##   sex \n## \"sex\"\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npull_binary_cols(dplyr::starwars)\n##   gender \n## \"gender\"\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\nThe `pull_facet_cols()` outline is similar, except that it calls the `pull_binary_cols()` first, then selects the columns and determines if any remaining have 3-5 categorical levels:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n█─pull_facet_cols \n├─█─pull_binary_cols \n├─█─select_class \n│ └─█─is_class \n└─█─make_facet_vec \n  └─█─check_facet_vec \n    ├─█─check_chr_facet \n    └─█─check_fct_facet \n```\n\n\n:::\n:::\n\n\n## Test tools\n\nBefore we can start developing the tests for `pull_cols()`, we'll need data. We can define test data inside the `it()` call for `select_class()`:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"select_class() returned objects\", code = {\n  it(\"df returned\", {\n    # define test data\n    test_data <- data.frame(\n      log_var = c(TRUE, FALSE, TRUE),\n      int_var = c(1L, 2L, 3L),\n      dbl_var = c(1.1, 2.2, 3.3),\n      chr_var = paste0(rep(\"item:\", times = 3), 1:3))\n  })\n})\n```\n:::\n\n\nThis is helpful because it's clear what `test_data` contains, and many times a small dataset will suffice. However, larger, more complex test data should be stored as a test fixture. \n\n### Test fixtures \n\nCreating test fixtures is covered in [R packages](https://r-pkgs.org/testing-design.html#storing-test-data), but I'll summarize the key points: \n\n1. Test data (and other objects) can either be created within a test, or as a persistent [test fixture](https://r-pkgs.org/testing-advanced.html#sec-testing-advanced-concrete-fixture)  \n\n2. Test data fixtures should be stored in `tests/testthat/fixtures/<test_data.rds>`\n\n3. The code used to create any test data fixtures should be stored in the same folder with a `make_` prefix (i.e., `tests/testthat/fixtures/<make_test_data.R>`)\n\nThis is easier to picture with a demonstration: In the `tests/testthat/` folder, I'll create a new `fixtures` folder, and add a `make_test_data.R` file.[^fixture-folder-name] \n\n\n\n```{.default}\ntests/testthat/\n        └── fixtures/\n                └── make_test_data.R\n```\n\n\n[^fixture-folder-name]: The `fixtures` name is not required, but it always make sense to keep folder names explicit. \n\nIn `make_test_data.R`, I'll create `test_data` using the code above and save `test_data` in `tests/testthat/fixtures/` as `test_data.rds`: \n\n\n\n```{.default}\ntests/testthat/\n        └── fixtures/\n                ├── make_test_data.R\n                └── test_data.rds\n```\n\n\nTo load the data into my test, I'll add the following to the top of the test context: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"select_class() returned objects\", code = {\n  \n  test_data <- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n  \n})\n```\n:::\n\n\n`testthat::test_path()` will load the data from the testing directory when I'm ready to run my test.\n\nThe `select_class()` function should also be able to return a data.frame/tibble of the specified class, or a named vector of the column names. `testthat`'s `expect_`* functions have a lot of options for writing very specific tests.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"select_class() returned objects\", code = {\n  \n  it(\"df returned\", {\n    # define/load test data\n    expect_s3_class(object, \"data.frame\")\n  })\n  \n  it(\"tibble returned\", {\n    # define/load test data\n    expect_s3_class(object,\n      class = c(\"tbl_df\", \"tbl\", \"data.frame\")\n    )\n  })\n  \n  it(\"string returned\", {\n    # define/load test data\n    expect_type(object = object, type = \"character\")\n  })\n  \n  it(\"named vector returned\", {\n    # define/load test data\n    expect_named(object = object, expected = \"log_var\")\n  })\n})\n```\n:::\n\n\n\n`select_class()` should also return the columns according to the `class` argument. For the logical, integer, double, character, and list columns, we can assess each returned object with `expect_type()`. However, with the factor and ordered columns, we'll use the `expect_s3_class()`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show/hide select_class() tests\"}\n# check classes ----\ndescribe(\"select_class() return classes\", code = {\n  ## check logical ----\n    it(\"logical works\", {\n      test_data <- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n      # define obj\n      obj <- select_class(df = test_data, class = \"logical\")\n      # test type\n      expect_type(obj[[1]], type = \"logical\")\n    })\n    ## check integer ----\n    it(\"integer works\", {\n      # integer test code\n      })\n  ## check double ----\n    it(\"double works\", {\n      # double test code\n    })\n  ## check character ----\n    it(\"character works\", {\n      # character test code\n    })\n    ## check list ----\n    it(\"list works\", {\n      # list test code\n    })\n  ## check factor ----\n    it(\"factor works\", {\n      test_data <- readRDS(test_path(\"fixtures\", \"test_data.rds\"))\n      obj <- select_class(df = test_data, class = \"factor\")\n      expect_s3_class(obj[[1]], class = \"factor\")\n    })\n  ## check factor (ordered) ----\n    it(\"ordered works\", {\n      # ordered factor test code\n    })\n\n})\n```\n:::\n\n\nUsing `describe()` and `it()` allows us to outline tests for `select_class()`, and including test fixtures makes it easier to test all possible classes returned.\n\nWhen we've covered my intended 'end results' for `select_class()` (i.e., what we expect to happen when it works and we expect to happen when it doesn't), we cam write the function: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"select_column_class()\"}\nselect_class <- function(df, class, return_tbl = TRUE) {\n  if (!is.data.frame(df)) stop(\"df must be a dataframe\")\n\n  # define classes\n  valid_classes <- c(\"logical\", \"integer\", \"double\", \"numeric\", \"character\",\n                     \"factor\", \"ordered\", \"list\")\n  class <- match.arg(class, choices = valid_classes, several.ok = TRUE)\n\n  # helper function to check classes\n  is_class <- function(x, cls) {\n    cls <- match(cls, valid_classes)\n    cls_name <- valid_classes[cls]\n    switch(cls_name,\n           logical = is.logical(x),\n           integer = is.integer(x),\n           double = is.double(x),\n           numeric = is.numeric(x),\n           character = is.character(x),\n           factor = is.factor(x),\n           ordered = is.ordered(x),\n           list = is.list(x),\n           FALSE)\n  }\n\n  selected_cols <- sapply(df, function(x) any(sapply(class, is_class, x = x)))\n\n  col_names <- names(df)[selected_cols]\n\n  if (return_tbl) {\n    return(df[, col_names, drop = FALSE])\n  } else {\n    return(setNames(object = col_names, nm = col_names))\n  }\n}\n```\n:::\n\n\nBelow is a summary of tips for adding data your tests. \n\n::: {#fig-unit_test_dep_data}\n\n![Unit test fixtures](unit_test_dep_data.png){#fig-unit_test_dep_data width=90%}\n\nUnit test fixtures \n:::\n\n### Test helpers\n\nTest helpers can be stored in `tests/testthat/helper.R`. Test helpers are functions or code that 1) is too long to repeat with each test, and 2) doesn't take too much time or memory to run. Read more about test helpers [here.](https://r-pkgs.org/testing-advanced.html#sec-testing-advanced-fixture-helper).\n\nFor this application, I've created a [set of test helpers](https://github.com/mjfrigaard/utap/blob/main/tests/testthat/helper.R) to make different forms of test data (because we'll be repeatedly defining columns with *slightly* different attributes). \n\nFor example, `col_maker()` can be used to create a `tibble` with columns based on the `col_type`, `size`, and `missing`:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ncol_maker(col_type = c(\"log\", \"int\", \"dbl\", \n                       \"chr\", \"fct\", \"ord\"),\n          size = 3,\n          missing = TRUE)\n## # A tibble: 3 × 6\n##   log_var int_var dbl_var chr_var fct_var ord_var\n##   <lgl>     <int>   <dbl> <chr>   <fct>   <ord>  \n## 1 TRUE          1     0.1 item:1  group 1 level 1\n## 2 FALSE        20    NA   <NA>    <NA>    <NA>   \n## 3 NA           NA     0.1 item:1  group 1 level 1\n```\n:::\n\n\nI can also create tibbles with custom columns using individual helper `_maker()` functions: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ntibble::tibble(\n    log_var = log_maker(size = 3),\n    chr_var = chr_maker(size = 3, lvls = 3),\n    ord_var = ord_maker(size = 3, lvls = 2)\n)\n## # A tibble: 3 × 3\n##   log_var chr_var ord_var\n##   <lgl>   <chr>   <ord>  \n## 1 TRUE    item:1  level 1\n## 2 FALSE   item:2  level 2\n## 3 TRUE    item:3  level 1\n```\n:::\n\n\nThese helpers make it easier to iterate through the test expectations *and* function development, because `tibble`s like the one above can be developed *inside* each test. \n\nBelow is an example for testing if `pull_binary_cols()` will correctly identify the `logical` columns (for both return objects):\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"using test helpers\"}\ndescribe(\"pull_binary_cols() works\", {\n    it(\"logical tibble (with missing)\", code = {\n      test_data <- tibble::tibble(log = log_maker(size = 2, missing = TRUE))\n      expect_equal(pull_binary_cols(test_data),\n      expected = c(log = \"log\"))\n    })\n    it(\"logical tibble\", code = {\n      test_data <- tibble::tibble(log = log_maker(size = 2, missing = FALSE))\n      expect_equal(pull_binary_cols(test_data),\n      expected = c(log = \"log\"))\n    })\n})\n```\n:::\n\n\nSometimes it will still make sense to create the test data inside the test scope (i.e. inside the `it()` or `test_that()` call). For example, I was `pull_binary_cols()` to identify integer columns with binary values (`0`, `1`). I should make these test data explicit: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"using test helpers\"}\nit(\"test integer with binary values (0, 1, NA)\", code = {\n  test_data <- data.frame(int = c(0L, 1L))\n  expect_equal(pull_binary_cols(test_data),\n  expected = c(int = \"int\"))\n})\nit(\"test integer with binary values and missing (0, 1, NA)\", code = {\n  test_data <- data.frame(int = c(0L, 1L, NA_integer_))\n  expect_equal(pull_binary_cols(test_data),\n  expected = c(int = \"int\"))\n})\n```\n:::\n\n\n\nWhen I'm confident with the `pull_binary_cols()` function and it's tests, I'll run `devtools:::test_active_file()`.\n\n\n\n```{.default}\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 9 ]\n```\n\n\n\n### Test coverage \n\n*How many tests should I write?* \n\nIn `testthat` code coverage measures the extent to which the tests in the `tests/testthat/` folder cover the possible execution paths of the functions in the `R/` folder. \n\nCode test coverage is a way to confirm that the unit tests are robust enough to verify that your code behaves as expected. In R packages, code coverage is discussed in the [testing chapter](https://r-pkgs.org/testing-design.html#sec-testing-design-coverage) using the [`covr` package](https://covr.r-lib.org/).\n\nDuring development, check the code coverage of a test file with `devtools::test_coverage_active_file()`. Sometimes this function can be temperamental, so I use the combination of `covr` functions below: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ncovr::file_coverage(\n  source_files = \"R/<function_file.R>\", \n  test_files = \"tests/testthat/test-<function_file.R>\") |>\n  covr::report()\n```\n:::\n\n\n\nBelow is the test coverage for `make_binary_vec()`--a smaller helper function for `pull_binary_cols()`--in the **Viewer** when `devtools::test_coverage_active_file()` is entered in the **Console**:\n\n::: {#fig-make_binary_vec_coverage}\n\n![Test coverage](make_binary_vec_coverage.png){#fig-make_binary_vec_coverage width=90% fig-align=\"center\"}\n\nUnit test coverage interactively\n:::\n\n\nWe can see from the output we don't have 100% test coverage for `make_binary_vec()`. When we click on the file path in the table we can se what execution paths aren't being tested: \n\n::: {#fig-make_binary_vec_coverage_source}\n\n![Behavior not tested in `make_binary_vec()`](make_binary_vec_coverage_source.png){#fig-make_binary_vec_coverage_source width=90% fig-align=\"center\"}\n\n\nThe area in red is the untested portion of `make_binary_vec()`\n:::\n\nIt's probably not worth chasing down the remaining 17% on this function because I've outlined it's primary requirements in the BDD functions:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndescribe(\"make_binary_vec() works\", {\n    it(\"logical\", {\n      # test code\n    })\n  it(\"integer\", {\n      # test code\n    })\n  it(\"character\", {\n      # test code\n    })\n  it(\"factor\", {\n      # test code\n    })\n})\n```\n:::\n\n\n\nStriving for a high percentage of coverage is a good practice, it doesn't guarantee that the function always behaves as expected. Unit tests might execute a line of code, but still not catch a bug due to the design of the test (it's easy to have high coverage if the unit tests are shallow and don't check for any potential [edge cases](https://en.wikipedia.org/wiki/Edge_case)).\n\nAfter developing the functions in `utap`, the files in the `R/` folder are organized into names [based on the](https://r-pkgs.org/code.html#sec-code-organising) '*main function and its supporting helpers*': \n\n\n\n```{.default}\nR/\n├── check_binary_vec.R\n├── check_facet_vec.R\n├── make_binary_vec.R\n├── make_facet_vec.R\n├── nin.R\n├── pull_binary_cols.R\n├── pull_cat_cols.R\n├── pull_cols.R\n├── pull_facet_cols.R\n├── pull_numeric_cols.R\n├── select_class.R\n└── utap-package.R\n\n```\n\n\nThe `tests/testthat/` folder file names have identical names as the files in the `R/` folder.\n\n\n\n```{.default}\ntests\n├── testthat\n│   ├── _snaps\n│   ├── fixtures\n│   │   ├── make_test_data.R\n│   │   └── test_data.rds\n│   ├── helper.R\n│   ├── test-check_binary_vec.R\n│   ├── test-check_facet_vec.R\n│   ├── test-make_binary_vec.R\n│   ├── test-nin.R\n│   ├── test-pull_binary_cols.R\n│   ├── test-pull_cat_cols.R\n│   ├── test-pull_cols.R\n│   ├── test-pull_facet_cols.R\n│   ├── test-pull_numeric_cols.R\n│   └── test-select_class.R\n└── testthat.R\n\n4 directories, 14 files\n```\n\n\nIt's common for R packages to have a general `R/utils.R` file that defines the 'utility' functions, but these files *can* become a catch-all for any functions that don't have a clear home (read more [here](https://rud.is/b/2018/04/08/dissecting-r-package-utility-belts/)).\n\nFor example, I could stored the `%nin%` operator in `R/utils.R` (but it removes the ability to run `test_coverage_active_file()`:\n\nWhen I've completed a set of test files, I can use `devtools::test()` to check if they're passing.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndevtools::test()\n```\n:::\n\n\n```{.default}\n==> devtools::test()\n\nℹ Testing utap\n✔ | F W  S  OK | Context\n✔ |         23 | check_binary_vec\n✔ |          3 | check_facet_vec\n✔ |          4 | make_binary_vec\n✔ |          3 | nin          \n✔ |          9 | pull_binary_cols\n✔ |          4 | pull_cat_cols\n✔ |          4 | pull_cols    \n✔ |         15 | pull_facet_cols\n✔ |          2 | pull_numeric_cols\n✔ |         14 | select_class \n\n══ Results ═══════════════════\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 81 ]\n\n🎯 Your tests hit the mark 🎯\n```\n\n\nThe output above shows all tests are passing (and some helpful words of encouragement!). To check the code coverage for the utap package, I can run `devtools::test_coverage()` to view the output in the **Viewer**. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndevtools::test_coverage()\n```\n:::\n\n\n```{.default}\nℹ Computing test coverage for utap\n```\n\n\n\n::: {#fig-utap_coverage}\n\n![`test_coverage()` for entire package](utap_coverage.png){#fig-utap_coverage width=90% fig-align=\"center\"}\n\n`devtools::test_coverage()`\n:::\n\nClicking on any of the **Files** will open the **Source** tab and give a summary like the one above from `test_coverage_active_file()`. I can also use `covr::package_coverage()` in the **Console** for simpler output:\n\n::: {#fig-covr_package_coverage}\n\n![`package_coverage()` for entire package](covr_package_coverage.png){#fig-covr_package_coverage width=75% fig-align=\"center\"}\n\n`covr::package_coverage()`\n:::\n\n\n\n\n\n:::: {.callout-tip collapse='false' appearance='default' icon=false}\n\n## [TIPS: Unit tests]{style='font-weight: bold; font-size: 1.15em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\n\nThe advice on unit tests below (in **bold**) comes from [Effective Software Testing, 2022](https://www.manning.com/books/effective-software-testing). I've included descriptions of how `testthat` satisfies each recommendation:\n\n1) **Unit tests should be fast**: the text recommends unit tests take a '*couple of milliseconds*' to execute. `testthat` tests typically fall within this threshold (and provide time measurements to identify bottlenecks).\n\n2) **Unit tests are easy to control**: i.e., '*input values and the expected result value are easy to adapt or modify in the test*.' `testthat` expectations give us ample access to 1) the `expected` result and 2) the `observed` result. \n\n3) **Unit tests are easy to write**: i.e., '*do not require a complicated setup or additional work*'. When used combination with `usethis`, `testthat` unit tests can be set up, created, written, and run with a few lines of code.\n  \n\n\n::: \n\n::::\n\n\n## Other code metrics \n\nSometimes it's interesting to view the relationship between function size and number of tests using the [`cloc` package.](https://github.com/hrbrmstr/cloc).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(cloc)\n```\n:::\n\n\n`cloc` stands for *Count Lines of Code*, and it's a rough metric used to gauge code complexity. It's simple, but apparently provides \"*just as much predictive power as more elaborate constructs like cyclomatic complexity.*\"[source](https://www.oreilly.com/library/view/software-design-x-rays/9781680505795/)\n\nBelow is a count of the lines of code in each file in the `R` folder: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ncloc::cloc_by_file(\"R\")\n```\n:::\n\n\n```{.default}\n# A tibble: 13 × 6\n   source filename                language   loc blank_lines comment_lines\n   <chr>  <chr>                   <chr>    <int>       <int>         <int>\n 1 R      \"R/select_class.R\"      R           27           5            31\n 2 R      \"R/check_binary_vec.R\"  R           24           0            14\n 3 R      \"R/make_facet_vec.R\"    R           19           0            19\n 4 R      \"R/pull_numeric_cols.R\" R           19           1            23\n 5 R      \"R/pull_binary_cols.R\"  R           14           0            19\n 6 R      \"R/pull_facet_cols.R\"   R           14           0            37\n 7 R      \"R/check_facet_vec.R\"   R           13           0            14\n 8 R      \"R/pull_cat_cols.R\"     R           13           0            18\n 9 R      \"R/make_binary_vec.R\"   R           10           0            19\n10 R      \"R/pull_cols.R\"         R            8           0            15\n11 R      \"R/nin.R\"               R            3           0             9\n12 R      \"R/utap-package.R\"      R            2           0             6\n13 R      \"\"                      SUM        166           6           224\n```\n\n\nThis output also confirms the relationship between lines of code and tests.\n\n## Recap\n\nThis post has been an introduction to unit testing utility functions in a Shiny app-package. When I'm confident the utility functions are working, I'll start adding them into modules (and testing with `testServer()` or `shinytest2`). Files names can change a lot throughout the course of developing a Shiny app-package, so it's helpful to adopt (or create) a naming convention.[^golem-conventions]\n\n[^golem-conventions]: If you're using the `golem` framework to develop your shiny app-package, the `utils_` and `fct_` prefixes are used to define two different types of [utility/helper functions](https://engineering-shiny.org/structuring-project.html#conventions-matter). `utils_` files contain '*small helper functions* and '*top-level functions defining your user interface and your server function*'. `fct_` files contain '*the business logic, which are potentially large functions*...*the backbone of the application and may not be specific to a given module*'.\n\nWhich particular file naming convention you choose isn't as important as adopting a convention and implementing it.\n\n<!--\n\n\n\n```{.default}\ntest-column_classes.R:\n            │\n            └── select_column_class()\n                  │\n                  └── get_column_class() \n```\n\n\n```{.default}\ntree/\n  │\n  └── get_column_class()\n        │     │\n        │     └── select_column_class()\n        │\n        ├── pull_binary_cols()\n        │\n        ├── pull_facet_cols()\n        │\n        ├── pull_cat_cols()\n        │\n        └── pull_numeric_cols()\n```\n\n\n```{.default}\ntree/\n  │\n  └── get_column_class() # used in all pull_[type]_cols()\n        │     │\n        │     └── select_column_class()\n        │\n        ├── pull_binary_cols()\n        │        │\n        │        ├── check_binary_vec()\n        │        │      │\n        │        │      ├── check_log_binary()\n        │        │      ├── check_int_binary()\n        │        │      └── check_fct_binary()\n        │        │\n        │        └── make_binary_vec()\n        │\n        ├── pull_facet_cols() # custom definition\n        │        │\n        │        ├── check_facet_vec()\n        │        │      │\n        │        │      ├── check_chr_facet()\n        │        │      └── check_fct_facet()\n        │        │\n        │        └── make_facet_vec()\n        │\n        ├── pull_cat_cols() # is.character & is.factor\n        │\n        └── pull_numeric_cols() # is.integer & is.double\n```\n\n\n-->",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/selectize-0.15.2/css/selectize.bootstrap3.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/selectize-0.15.2/js/selectize.min.js\"></script>\n<script src=\"../../site_libs/selectize-0.15.2/accessibility/js/selectize-plugin-a11y.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}