{
  "hash": "3b19281719eeb9d6917b228bcd2cfd5b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Shiny (for Python) & APIs\" \nsubtitle: \"Using Vetiver, FastAPI and Shiny\"\nauthor: \"Martin Frigaard\"\ndate: \"2025-07-21\"\ncategories: [APIs, Python, Shiny]\n# image: \"img/image.png\"\ndraft: false\ntoc: true\ntoc-depth: 5\ntoc-title: 'Contents'\ntoc-location: \"left\"\n# code-block-border-left: true\ncode-block-bg: \"#f8f8f8\"\ncode-block-border-left: \"#e8e8e8\"\ncode-fold: show\ncode-summary: 'show/hide'\ncallout-icon: false\nengine: knitr\nfreeze: true\ncallout-appearance: simple\n\nexecute:\n  echo: false\n  message: false\n  warning: false\n  eval: true\n---\n\n\n\n\n\nThis is the second post demonstrating how to use Shiny apps with a database and an API (see previous post [here](https://mjfrigaard.github.io/posts/shiny-plumber/)). Both of these solutions are inspired by the exercises in the [Databases and APIs chapter](https://do4ds.com/chapters/sec1/1-3-data-access.html#lab-use-a-database-and-an-api) of [DevOps for Data Science](https://do4ds.com/).\n\nIn this post, I'll create a simple `sklearn` model as a RESTful API with `VetiverModel` and `FastAPI`, then use a Shiny for Python app for making requests. This production-ready architecture gives users an interactive interface to the model for making predictions.\n\nI'll touch on coding patterns, architecture decisions, and compare my Python solution to my previous implementation using R (with `plumber`, `logger`, and `shiny`).\n\n## Architecture\n\n```{=html}\n\n<style>\n\n.codeStyle span:not(.nodeLabel) {\n  font-family: monospace;\n  font-size: 1.5em;\n  font-weight: bold;\n  color: #9753b8 !important;\n  background-color: #f6f6f6;\n  padding: 0.2em;\n}\n\n</style>\n```\n\n```{mermaid}\n%%| fig-align: center\n%%| echo: false\n%%| fig-cap: 'Python APIs & Shiny Apps'\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\ngraph TB\n    subgraph Storage[\"<strong>Model</strong>\"]\n      subgraph Board[\"<strong>models</strong>\"]\n        Model(\"<strong>penguin_model</strong>\")\n      end\n    end\n    \n    style Storage fill:#fff,stroke:#E65100,color:#FF9800,stroke-width:3px\n    style Board fill:#FF9800,color:#000,stroke:#FF9800,stroke-width:1px\n    style Model text-align:left,fill:#FF9800,color:#000,stroke:#FF9800,stroke-width:1px\n\n    subgraph API[\"<strong>Vetiver API</strong>\"]\n        Vetiver(\"<strong><code>VetiverModel</code></strong>\")\n        FastAPI(\"<strong><code>FastAPI</code> server</strong>\")\n        Endpoints(\"<code>/predict</code><br/><code>/ping</code><br/><code>/metadata</code>\")\n    end\n    \n    style API fill:#fff,stroke:#2E7D32,color:#4CAF50\n    style Vetiver text-align:right,fill:#4CAF50,color:#000,stroke:#4CAF50,stroke-width:3px\n    style FastAPI text-align:right,fill:#4CAF50,color:#000,stroke:#4CAF50,stroke-width:3px\n    style Endpoints text-align:left,fill:#4CAF50,color:#000,stroke:#4CAF50,stroke-width:3px\n    \n    subgraph App[\"<strong>Shiny App</strong>\"]\n        UI(\"<strong>Shiny UI Inputs</strong>\")\n        Server(\"<strong>App Server</strong>\")\n        Logging(\"<strong>Logging<br>(file & console)</strong>\")\n    end\n    \n    style App fill:#fff,stroke:#1565C0,color:#2196F3\n    style UI fill:#2196F3,color:#000,stroke:#2196F3,stroke-width:3px\n    style Server fill:#2196F3,color:#000,stroke:#2196F3,stroke-width:3px\n    style Logging fill:#2196F3,color:#000,stroke:#2196F3,stroke-width:3px\n    \n    subgraph User[\"<strong>End Users</strong>\"]\n        Browser(\"<strong>Web Browser</strong>\")\n    end\n    \n    style User color:#000\n    style Browser fill:#fff,color:#000,stroke:#000,stroke-width:3px\n    \n    Model -->|<code>pins</code> board with <code>sklearn</code> model| Vetiver\n    Vetiver -->|Model wrapper| FastAPI\n    FastAPI --> |Port 8080|Endpoints\n    \n    Browser --> UI\n    UI --> Server\n    Server -->|HTTP POST| Endpoints\n    Endpoints -->|JSON Response| Server\n    Server --> Logging\n    Logging --> UI\n    \n```\n\n## Model\n\nThe files in the API folder are below:\n\n\n```{.default}\n_labs/lab4/Python/api/\n                  ├── api.Rproj\n                  ├── mod-api.py\n                  ├── model.py\n                  ├── models/\n                  │   └── penguin_model/\n                  ├── my-db.duckdb\n                  ├── README.md\n                  └── requirements.txt\n```\n\nWe'll first cover creating the model in `model.py`, then the API in `mod-api.py`.[^1]\n\n[^1]: The code below has been adapted from the [modeling section](https://vetiver.posit.co/get-started/#train-a-model) of the **ML Ops with vetiver** example.\n\n### Dependencies\n\nI'll start by importing the packages. In Python (and Positron), we want to manage our Python dependencies using [`venv`](https://docs.python.org/3/tutorial/venv.html).[^2] We can accomplish this by creating the `.venv/` (virtual environment) and reading the requirements from `requirements.txt`.\n\n[^2]: Similar to the [`renv` package in R](https://rstudio.github.io/renv/).\n\n\n```{.default}\n# check  Python version\nwhich python3\npython3 --version\n\n/usr/bin/python3 -m venv .venv \nsource .venv/bin/activate \n\npip install -r requirements.txt\n```\n\nAt the top of `model.R`, we will load the necessary packages:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nfrom palmerpenguins import load_penguins\nfrom pandas import get_dummies\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nimport duckdb\n```\n:::\n\n\nPython dependencies tend to more explicit than R dependencies, specifically the “import only specific things” style (i.e., `from pandas import get_dummies`). I'm still figuring out how to use the aliases, but I've found that this level of precision helps me plan better (and not import something I won't use).\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: Dependencies]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\nBelow is a collection of terms and concepts related to dependencies in Python and R:\n\n| Concept | Python | R | Notes |\n|----|----|----|----|\n| Package | Package | Package | Same word, different tooling. In Python its `pip`or`conda` and in R we use `install.packages()` or `pak`. |\n| Module | module | namespace | Python modules are files; R namespaces are package-scoped environments. |\n| Import | `import` or `from x import y` | `library()`,`require()`, `pkg::fun()` | Python encourages explicit imports while R encourages `pkg::fun()` for explicit usage |\n| Attach | imported into namespace | attached to search path | `library()` *attaches*; `pkg::fun()` doesn't |\n| Alias | `import numpy as np` |  | R doesn't use aliases for packages; explicit qualification is preferred. |\n\n  \n\n::: \n\n::::\n\n### Data\n\nThe data are imported from the [Python `palmerpenguins` package](https://pypi.org/project/palmerpenguins/) and used to create an embedded database connection (`con`). We then create a table from the [`pandas` DataFrame](https://pandas.pydata.org/), query and clean the data (drop missing), view the top three rows, and close the connection.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\npenguins_data = load_penguins()\ncon = duckdb.connect('my-db.duckdb')\ncon.execute(\"CREATE OR REPLACE TABLE penguins AS SELECT * FROM penguins_data\")\ndf = con.execute(\"SELECT * FROM penguins\").fetchdf().dropna()\nprint(df.head(3))\ncon.close()\n```\n:::\n\n\n\n```{.default}\n  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex  year\n0  Adelie  Torgersen            39.1           18.7              181.0       3750.0    male  2007\n1  Adelie  Torgersen            39.5           17.4              186.0       3800.0  female  2007\n2  Adelie  Torgersen            40.3           18.0              195.0       3250.0  female  2007\n```\n\n### Linear regression\n\nThe linear regression model uses one-hot encoding with `get_dummies()` by dropping the first category of each factor.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nX = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)\ny = df['body_mass_g']\nmodel = LinearRegression().fit(X, y)\n```\n:::\n\n\nWhat `get_dummies()` does is create a series of binary indicators for the categorical factors (dropped category becomes the *reference level*):\n\n| Original Data | After `get_dummies(drop_first=True)` |\n|-----------------------------|-------------------------------------------|\n| `bill_length_mm`: 39.1<br/>`species`: Adelie<br/>`sex`: male | `bill_length_mm`: 39.1<br/>`species_Chinstrap`: 0<br/>`species_Gentoo`: 0<br/>`sex_male`: 1 |\n| `bill_length_mm`: 46.5<br/>`species`: Gentoo<br/>`sex`: female | `bill_length_mm`: 46.5<br/>`species_Chinstrap`: 0<br/>`species_Gentoo`: 1<br/>`sex_male`: 0 |\n\n*If `species_Chinstrap=0` and `species_Gentoo=0`, the penguin is `Adelie`*\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: Dummy encoding]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\nIn Python, we have to explicitly call `get_dummies(..., drop_first = TRUE)` to perform one-hot encode the categorical variables. This drops the first level to avoid multicollinearity.\t\t\t\t\n\n```python\nX = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)\ny = df['body_mass_g']\nmodel = LinearRegression().fit(X, y)\n```\n\nIn R, `lm()` will automatically convert factors to dummy variables by dropping one level per factor (also called treatment contrasts). \n\n```r\nmodel <- lm(\n  body_mass_g ~ bill_length_mm + species + sex,\n  data = df\n)\n```\n\n  \n\n::: \n\n::::\n\nFor the [`LinearRegression` model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), the `.fit()` method trains the model in-place and returns `self`, enabling method chaining. We can print out the model attributes (R\\^2, intercept, coefficients, etc.) to confirm it's working:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# model attributes\nprint(f\"R^2 {model.score(X,y)}\") #<1>\nprint(f\"Intercept {model.intercept_}\") #<2>\nprint(f\"Coefficients {model.coef_}\") #<3>\n```\n:::\n\n\n1.  The `.score()` method computes R\\^2 (coefficient of determination) on the training data\\\n2.  The `model` intercept\\\n3.  The `model` coefficients\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: F strings]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\nPython uses F-strings (any string prefixed with `f` or `F`) are formatted string literals:\n\n```python\nprint(f\"R^2 {model.score(X,y)}\")\nprint(f\"Intercept {model.intercept_}\")\nprint(f\"Coefficients {model.coef_}\")\n```\n\nWe can put *any* valid Python expression inside the braces (`{``}`) and these are evaluated at runtime. The results are automatically converted to strings.\n\nIn R, we can do this using base R functions: \n\n```r\ncat(\"R^2\", summary(model)$r.squared, \"\\n\")\ncat(\"Intercept\", coef(model)[1], \"\\n\")\ncat(\"Coefficients\", coef(model)[-1], \"\\n\")\n```\n\nOr the `tidyverse`-friendly output and string interpolation, `glue`:\n\n```r\nglue(\"R^2 {summary(model)$r.squared}\")\nglue(\"Intercept {coef(model)[1]}\")\nglue(\"Coefficients {toString(coef(model)[-1])}\")\n```\n  \n\n::: \n\n::::\n\n\n```{.default}\nR^2 0.8555368759537614\nIntercept 2169.2697209393973\nCoefficients [  32.53688677 -298.76553447 1094.86739145  547.36692408]\n```\n\nThe prototype data shows the transformation from `get_dummies()`:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nprint(f\"prototype_data {X}\")\n```\n:::\n\n\n\n```{.default}\nprototype_data      bill_length_mm  species_Chinstrap  species_Gentoo  sex_male\n0              39.1              False           False      True\n1              39.5              False           False     False\n2              40.3              False           False     False\n4              36.7              False           False     False\n5              39.3              False           False      True\n..              ...                ...             ...       ...\n339            55.8               True           False      True\n340            43.5               True           False     False\n341            49.6               True           False      True\n342            50.8               True           False      True\n343            50.2               True           False     False\n\n[333 rows x 4 columns]\n```\n\nThe columns in `X` also let us know what kind of data this model will be expecting.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nprint(f\"Columns {X.columns}\")\n```\n:::\n\n\n\n```{.default}\nColumns Index(['bill_length_mm', 'species_Chinstrap', 'species_Gentoo', 'sex_male'], dtype='object')\n```\n\n### VetiverModel\n\nNow we can wrap the trained `sklearn.linear_model` with metadata as a `VetiverModel` and store it as `v`:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nfrom vetiver import VetiverModel\nv = VetiverModel(model, model_name='penguin_model', prototype_data=X)\n```\n:::\n\n\nThe `prototype_data` is set to `X` (which we created above).\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: vetiver]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\nThe `VetiverModel` Wrapper is essentially the same in Python and R: both end up with a Vetiver object that can make predictions and has some kind of prototype input structure:\n\n```python\nv = VetiverModel(model, model_name='penguin_model', prototype_data=X)\n```\n\nThe `prototype_data=X` will explicitly provide the pre-dummified data. \n\nIn R, `save_prototype=TRUE`, the prototype is based on the model terms/data structure and includes the raw columns (which is we'd want for an API expecting `species` and `sex` as inputs (not pre-dummified columns). The `description` has extra metadata for documentation).\n\n```r\nv <- vetiver::vetiver_model(\n  model,\n  model_name = 'penguin_model',\n  description = 'Linear model predicting penguin body mass from bill length, species, and sex',\n  save_prototype = TRUE\n)\n```\n\n\n\n::: \n\n::::\n\n### `pins` board\n\nWe'll use `pins` to create a `model/` board (i.e., the storage directory) and save our `vetiver` versioned model.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nimport os\nfrom pins import board_folder\nfrom vetiver import vetiver_pin_write\n\nmodel_board = board_folder(\"./models\", allow_pickle_read=True)\nvetiver_pin_write(model_board, v)\n```\n:::\n\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: pins]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\n\nThe `pins` board is also nearly identical, with the exception of deserializing Python-specific pickled objects (`allow_pickle_read=True`):\n\n```python\nmodel_board = board_folder('./models', allow_pickle_read=True)\nvetiver_pin_write(model_board, v)\n```\n\nIn R, serialization is via RDS/qs/etc., depending on implementation and `pins` board behavior:\n\n```r\nmodel_board <- pins::board_folder('models/')\nvetiver::vetiver_pin_write(model_board, v)\n```\n\n\n  \n\n::: \n\n::::\n\n```{mermaid}\n%%| fig-align: center\n%%| echo: false\n%%| fig-cap: 'vetiver_pin_write()'\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\ngraph LR\n    subgraph Board[\"<strong>./models/</strong>\"]\n        ModelDir[\"<strong>penguin_model/<strong>\"]\n        Version[\"<strong>20251224T142035Z-c115b/</strong>\"]\n        DataTxt[\"<code>data.txt</code>\"]\n        ModelFile[\"<code>penguin_model.joblib</code>\"]\n    end\n    \n    ModelDir -->|<em>timestamp with hash</em>|Version\n    Version --> |<em>pin metadata</em>|DataTxt\n    Version --> |<em>serialized model</em>|ModelFile\n    \n    style Board fill:#E8F5E9,stroke:#2E7D32\n    style Version fill:#BBDEFB,stroke:#1565C0\n    style ModelFile fill:#FF9800,stroke:#E65100,color:#fff\n```\n\nThe `models/` folder contains the following:\n\n\n```{.default}\nmodels/\n└── penguin_model #<1>\n    └── 20251224T142035Z-c115b #<2>\n        ├── data.txt #<3>\n        └── penguin_model.joblib #<4>\n\n3 directories, 2 files\n```\n\n1.  Model name\\\n2.  Version timestamp + hash\\\n3.  Pin metadata (JSON format)\\\n4.  Serialized sklearn model (joblib format)\n\n## API\n\nNow that we have a `Vetiver` model, we can build an API. At the top of the `mod-api.py` file, `warnings` and `os` are imported because we're going to ignore the OpenSSL warning and set the `PINS_ALLOW_PICKLE_READ` environment variable (because we know the files come from a trusted source lab):[^3]\n\n[^3]: The code below is adapted from the [Deploy section](https://vetiver.posit.co/get-started/deploy.html) of the **ML Ops with vetiver** example.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# pkgs\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\".*urllib3 v2 only supports OpenSSL.*\")\n\nimport os\nos.environ['PINS_ALLOW_PICKLE_READ'] = '1'\n```\n:::\n\n\n\n:::: {.callout-tip collapse='true' appearance='default' icon=false}\n\n## [PICKLE!]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\n***We previously set the `allow_pickle_read` to `True` when we created the `model_board`, and now we're specifying an environment variable. Why?***\n\n```python\nmodel_board = board_folder('./models', allow_pickle_read=True)\n```\n\n[Pickle](https://docs.python.org/3/library/pickle.html) is Python's way of saving complex objects to files (it can save almost ANY Python object - functions, classes, even entire programs). But this also means `pickle` can save malicious code. \n\nBecause of this, the Python `pins` package blocks `pickle` files. However, the R `vetiver` package saves files in the `pickle`/`joblib` format (for cross-language compatibility). \n\n```python\nos.environ['PINS_ALLOW_PICKLE_READ'] = '1'\n```\n\n\n\n::: \n\n::::\n\nAfter importing the libraries, we connect to the model board (that was created in `model.py`) and read the pinned model.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# dependencies \nimport vetiver\nimport pins\nimport uvicorn\nimport pandas as pd\n\nmodel_board = pins.board_folder(\"models/\")\n\nsklearn_model = model_board.pin_read(\"penguin_model\")\n```\n:::\n\n\nTo ensure the `sklearn_model` model has the correct input data, we validate the expected features by checking the `feature_names_in_` attribute:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# features \nif hasattr(sklearn_model, 'feature_names_in_'):\n    feature_names = sklearn_model.feature_names_in_\n    print(f\"Model expects features: {list(feature_names)}\")\n```\n:::\n\n\nThis attribute are the, \"*Names of features seen during [`fit`](https://scikit-learn.org/stable/glossary.html#term-fit). Defined only when X has feature names that are all strings.*\"\n\n### Prototype Data\n\nThe model prototype data--which is like a contract between the client and the API--defines the expected input schema. We define the prototype data using a `get_prototype_value()` function, which checks the column names and has some sensible validation rules (provided the model has the expected features (i.e., from `feature_names_in_` and `feature_names`)):\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\ndef get_prototype_value(column_name):\n    \"\"\"Get appropriate default value for each column type\"\"\"\n    if 'bill_length' in column_name:\n        return 45.0  #<1> \n    elif 'species_Gentoo' in column_name:\n        return 1     #<2>\n    elif 'sex_male' in column_name:\n        return 1     # <3>\n    else:\n        return 0     # <4>\n\nprototype_data = pd.DataFrame({ #<5>\n    name: [get_prototype_value(name)] for name in feature_names\n}) #<5>\n```\n:::\n\n\n1.  Realistic penguin bill length\\\n2.  Default to Gentoo species\\\n3.  Default to male\\\n4.  Default for other dummy variables\\\n5.  Create prototype data using the raw input column names the estimator saw at fit time\n\nIf the `sklearn_model` *doesn't contain or expose the `feature_names_in_` attribute*, we manually create `prototype_data` as a `pandas.DataFrame` with hard-coded columns:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nelse:\n    print(\"Model doesn't have feature_names_in_, using estimated prototype\")\n    prototype_data = pd.DataFrame({\n        \"bill_length_mm\": [45.0],\n        \"species_Chinstrap\": [0],\n        \"species_Gentoo\": [1], \n        \"sex_male\": [1]\n    })\n```\n:::\n\n\nThis method prevents runtime errors when the model structure doesn't match expectations.\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: Functions, conditions, and docstrings]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\n\n#### Functions\n\nIn Python, `def` is used to define the function, `get_prototype_value`. :\n\n```python\ndef get_prototype_value(column_name):\n    ...\n\n```\n\nIn R, functions are defined with `function()` (and include curly brackets if they extend past a single line):\n\n```r\nget_prototype_value <- function(column_name) {\n  ...\n}\n```\n\n#### Conditions\n\nIn Python, the `elif` means 'else if' and is evaluated only if the previous `if` condition was `FALSE`: \n\n```python\nif cond1:\n    ...\nelif cond2:\n    ...\nelse:\n    ...\n```\n\nIn R, `else if` is explicit and typically accompanied with curly brackets (like multi-line functions).\n\n```r\nif (cond1) {\n  ...\n} else if (cond2) {\n  ...\n} else {\n  ...\n}\n```\n\n\n#### Docstrings\n\nPython also uses [docstrings](https://www.geeksforgeeks.org/python/python-docstrings/) in their help tools (like IDEs, and documentation generators). \n\n```python\n\"\"\"Get appropriate default value for each column type\"\"\"\n```\n\nIn R, `roxygen2` is used to create documentation from special comment characters: \n\n```r\n#' Get appropriate default value for each column type\n```\n\n  \n\n::: \n\n::::\n\n### Wrapping and Serving\n\nAfter reading `sklearn_model` from the `pins` board, we still need to convert it to `VetiverModel`:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# model\nv = vetiver.VetiverModel( #<1>\n    model=sklearn_model, \n    model_name=\"penguin_model\",\n    prototype_data=prototype_data\n)#<1>\n```\n:::\n\n\n1.  Wrap as `VetiverModel` and specify our `prototype_data`.\n\n`VetiverAPI` uses the Vetiver model (`v`) to create the API (`vetiver_api`).\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# API\nvetiver_api = vetiver.VetiverAPI(v, check_prototype=True) \n```\n:::\n\n\nThe `check_prototype` is set to `True` because this ensures the prototype will be enforced. To view the API, we can use `vetiver_api.run()` to open the `VetiverAPI` in the browser.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# View\nvetiver_api.run(port = 8080) \n```\n:::\n\n\nWe can also extract `app` from `vetiver_api`, which is the *actual* app (i.e., `<class 'fastapi.applications.FastAPI'>`). To run `app`, we'll use `uvicorn.run()` (and include some finishing checks):\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# extract\napp = vetiver_api.app #<1>\n\nif __name__ == \"__main__\": #<2>\n    print(\":-] Starting Penguin Model API...\") #<3>\n    print(\":-] API Documentation: http://127.0.0.1:8080/docs\") \n    print(\":-] Health Check: http://127.0.0.1:8080/ping\") \n    print(\":-] Model Info: http://127.0.0.1:8080/metadata\") #<3>\n    uvicorn.run(app, host=\"127.0.0.1\", port=8080) #<4>\n```\n:::\n\n\n1.  Extract `FastAPI` API object\n2.  This ensures that server-starting code only runs when the file is executed directly\\\n3.  Documentation and API URLs\\\n4.  Run the API\n\nWhen `mod-api.py` is run directly, Python automatically sets a special variable called `__name__` (and it's value is `\"__main__\"`). This ensures the api only starts when we explicitly run the script.\n\n#### Console output\n\nTo run the API, we enter the following in the Terminal:\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"false\"}\npython3 mod-api.py\n```\n:::\n\n\n\n```{.default}\n:-] Starting Penguin Model API...\n:-] API Documentation: http://127.0.0.1:8080/docs\n:-] Health Check: http://127.0.0.1:8080/ping\n:-] Model Info: http://127.0.0.1:8080/metadata\nINFO:     Started server process [8825]\nINFO:     Waiting for application startup.\nINFO:     VetiverAPI starting...\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit)\n```\n\nClicking on `http://127.0.0.1:8080` will open the `Vetiver` interface,\n\n![Click to enlarge](img/vetiver_url.png){width=\"100%\" fig-align=\"center\"}\n\nGoing to `http://127.0.0.1:8080/docs` will open the `FastAPI` interface:\n\n![Click to enlarge](img/fastapi_url.png){width=\"100%\" fig-align=\"center\"}\n\n## App\n\nThe Shiny for Python app I created is in a separate [`app/` folder](https://github.com/mjfrigaard/do4ds-labs/tree/main/_labs/lab4/Python/app):\n\n\n```{.default}\n_labs/lab4/Python/app/\n                    ├── app.py\n                    ├── app.Rproj\n                    ├── logs\n                    │   └── shiny_app.log\n                    ├── README.md\n                    └── requirements.txt\n```\n\n### Dependencies\n\nThe `requirements.txt` is used to manage the `pip` dependencies (along with a virtual environment). The application modules are imported and loaded in the top of the `app.py` file:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nfrom shiny import App, render, ui, reactive\nimport requests\nimport json\nimport logging\nimport time\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\n```\n:::\n\n\n### Logging\n\nLogging is done using the [`logging` module](https://docs.python.org/3/library/logging.html):[^4]\n\n[^4]: In comparison to the `logger` package in the [previous post.](https://mjfrigaard.github.io/posts/shiny-plumber/)\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# config\ndef setup_logging(): #<1>\n    \"\"\"Configure logging with file and console output\"\"\" #<2>\n    log_dir = Path(\"logs\") #<3>\n    log_dir.mkdir(exist_ok=True) #<4>\n    \n    log_file = log_dir / \"shiny_app.log\" #<5>\n    \n    logging.basicConfig( #<6>\n        level=logging.INFO, #<7>\n        format='%(asctime)s - %(levelname)s - %(message)s', #<8>\n        handlers=[ #<9>\n            logging.FileHandler(log_file, mode='a'), #<10>\n            logging.StreamHandler() #<11>\n        ] #<9>\n    ) #<6>\n    \n    return str(log_file) #<12>\n\n# init\nlog_file_path = setup_logging() #<13>\n```\n:::\n\n\n1.  Function definition for `setup_logging()`\\\n2.  Docstring\\\n3.  Location of log files (`logs/`)\\\n4.  Create the directory\\\n5.  Full path to the log file (`logs/shiny_app.log`)\\\n6.  Configuration of the root logging system\\\n7.  The log `level` of the root logger\\\n8.  The `format` of the root logger\\\n9.  The `handlers` are added to the root logger (should include a `FileHandler` and `StreamHandler`)\\\n10. Sends logging output to a file\\\n11. Sends logging output to console\\\n12. Return log file\n13. Run `setup_logging()` function to create `log_file_path`\n\nThe trickiest part of the `logging` configuration was making sure the logs were sent to the console *and* the `log_file`,[^5] but after reading through the tutorial (and doing some troubleshooting) I was able to get both handlers set up.[^6]\n\n[^5]: Read more about 'logging to multiple destinations' in [Logging cookbook](https://docs.python.org/3/howto/logging-cookbook.html#logging-to-multiple-destinations)\n\n[^6]: Logging [handlers](https://docs.python.org/3/howto/logging.html#handlers) \"*are responsible for dispatching the appropriate log messages (based on the log messages’ severity) to the handler’s specified destination.*\"\n\nThe initial contents of the `logs/shiny_app.log` file are the first and last logs in the app:\n\n\n```{.default}\n2026-01-02 14:23:53,666 - INFO - Shiny for Python application initialized\n2026-01-02 14:23:53,733 - INFO - Shiny for Python application created successfully\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlogging.info(\"Shiny for Python application initialized\") #<1>\n```\n:::\n\n\n1.  Generate first log\n\nThe second line in the log file is created at the bottom of the `app.py` file and lets us know the application launched.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nlogging.info(\"Shiny for Python application created successfully\")\n```\n:::\n\n\n### URLS\n\nThe URLS for the API are defined as `api_url` (for making predictions) and `ping_url` (for health checks).\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\napi_url = 'http://127.0.0.1:8080/predict'\nping_url = 'http://127.0.0.1:8080/ping'\n```\n:::\n\n\n### Sessions\n\nThe UI displays the session ID in a `div()`:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n  ui.div(\n    ui.strong(\"Session: \"),\n    ui.output_text(id=\"session_display\"), #<1>\n    style=\"position: fixed; top: 10px; right: 10px; z-index: 1000; color: #333; background: #fff; padding: 5px; border-radius: 3px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\"\n    )\n```\n:::\n\n\n1.  The `id` in the `ui.output_text()` linked to the `@render.text` in the `server`\n\nIn the `server`, we generate a session ID and log the session start:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\ndef server(input, output, session):\n    session_id = f\"py_{int(time.time() * 1000) % 100000}\" #<1>\n    logging.info(f\"New session started - Session: {session_id}\") #<2>\n```\n:::\n\n\n1.  The `session_id` is a unique number based on `time.time()`\\\n2.  This new session is logged in the log file.\n\nIn the log file, we can see the `INFO` level log with the `session_id`:\n\n\n```{.default}\n2026-01-02 14:24:03,831 - INFO - New session started - Session: py_43831\n```\n\nThe output in the application is created using a the `@render` decorator and by defining a function (matching the `id` from the UI):\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n    @render.text #<1>\n    def session_display(): #<2>\n        return session_id[:8] #<3>\n```\n:::\n\n\n1.  Decorator for the text output\\\n2.  Function definition for output (matching `session_display` input `id`)\\\n3.  Return first 8 numbers of `session_id`\n\nThe result is a new session id in the upper right corner of the app:\n\n![Click to enlarge](img/session_id.png){width=\"100%\" fig-align=\"center\"}\n\n### Health check\n\nThe health check is performed using the same UI and server pattern as the session id, but it also includes the creation of a reactive (`@reactive.calc`).\n\nFirst we place the `output_` component in the UI:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nui.output_text(id=\"api_status\")\n```\n:::\n\n\nIn the server, we use a `@reactive.calc` decorator and define the `api_health_check()` function and implement **exception handling** for the health check:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"show/hide health check\"}\n    @reactive.calc\n    def api_health_check(): #<1>\n        \"\"\"Enhanced API health check with logging\"\"\" #<2>\n        try: #<3>\n            logging.debug(f\"Checking API health - Session: {session_id}\")\n            start_time = time.time()\n            r = requests.get(ping_url, timeout=5) #<4>\n            response_time = time.time() - start_time #<5>\n            if r.status_code == 200: #<6>\n                logging.info(f\"API health check successful - Session: {session_id} - response_time: {response_time:.3f}s\") #<6>\n                return f\"✅ API is running (ping: {r.json()}) - {response_time:.2f}s\"  #<6>\n              else: #<7>\n                logging.warning(f\"API ping failed - Session: {session_id} - status: {r.status_code}\")\n                return f\"⚠️ API ping failed: {r.status_code}\" #<7>\n              #<3>\n              \n        except requests.exceptions.ConnectionError as e: #<8>\n            logging.error(f\"API connection refused - Session: {session_id} - error: {str(e)}\")\n            return \"❌ Cannot connect to API - is it running on port 8080?\" #<8>\n        except requests.exceptions.Timeout: #<9>\n            logging.warning(f\"API health check timeout - Session: {session_id}\")\n            return \"⚠️ API health check timeout\" #<9>\n        except Exception as e: #<10>\n            logging.error(f\"API health check failed - Session: {session_id} - error: {str(e)}\")\n            return f\"❌ API health check failed: {str(e)}\" #<10>\n```\n:::\n\n\n1.  Function definition for reactive value\\\n2.  Docstring\n3.  The `try: ...` and `except ...` structure provide the exception handling\\\n4.  Request using `ping_url`\\\n5.  Calculated response time\\\n6.  Successful health check\\\n7.  Failed health check\\\n8.  Handles “cannot connect” (API down, wrong port/host, connection refused)\\\n9.  Handles request timeout specifically\\\n10. Catch-all for anything else (JSON parsing errors, unexpected runtime issues, etc.)\n\nThe diagram below illustrates how the `@reactive.calc`, `logging`, `time` and `requests` are used to send a `ping` to the API, get a response (`r`), calculate the response time (`response_time`), return the status code (`r.status_code`), and classify the response:\n\n```{mermaid}\n%%| fig-align: center\n%%| echo: false\n%%| fig-cap: 'Health check with logging'\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\nsequenceDiagram\n    participant Reactive as reactive.calc\n    participant Logger as logging\n    participant Timer as time\n    participant Client as requests\n    participant API as Vetiver API\n\n    Reactive->>Logger: debug(\"Checking API health (session_id)\")\n    Reactive->>Timer: start_time = time.time()\n\n    Reactive->>Client: GET ping_url (timeout=5)\n    Client->>API: HTTP GET /ping\n    API-->>Client: HTTP response\n    Client-->>Reactive: response r\n\n    Reactive->>Timer: response_time = time.time() - start_time\n\n    alt status_code == 200\n        Reactive->>Logger: info(\"Health check successful + response_time\")\n        Reactive-->>Reactive: return \"✅ API is running\"\n    else status_code != 200\n        Reactive->>Logger: warning(\"API ping failed (status_code)\")\n        Reactive-->>Reactive: return \"⚠️ API ping failed\"\n    end\n    \n```\n\n**Exception handling** is created with `try` and `except`: the `request,get()` in `try` runs normally, but if an error or exception occurs, the code will jump to the first matching `except` block:\n\n```{mermaid}\n%%| fig-align: center\n%%| echo: false\n%%| fig-cap: 'Health check with exception handling'\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\nsequenceDiagram\n    participant Reactive as reactive.calc\n    participant Logger as logging\n    participant Client as requests\n    participant API as Vetiver API\n\n    Reactive->>Logger: debug(\"Checking API health (session_id)\")\n    Reactive->>Client: GET ping_url (timeout=5)\n\n    alt Normal execution\n        Client->>API: HTTP GET /ping\n        API-->>Client: HTTP response\n        Client-->>Reactive: response r\n        Reactive-->>Reactive: continue normal flow\n    else ConnectionError\n        Client--x Reactive: Connection refused\n        Reactive->>Logger: error(\"Connection refused\")\n        Reactive-->>Reactive: return \"❌ Cannot connect to API\"\n    else Timeout\n        Client--x Reactive: Request timeout\n        Reactive->>Logger: warning(\"Health check timeout\")\n        Reactive-->>Reactive: return \"⚠️ API health check timeout\"\n    else Unexpected exception\n        Reactive--x Reactive: Runtime exception\n        Reactive->>Logger: error(\"Unexpected error\")\n        Reactive-->>Reactive: return \"❌ API health check failed\"\n    end\n\n```\n\nThese exceptions are *typed* (e.g., `equests.exceptions.ConnectionError`, `requests.exceptions.Timeout`, etc.), which means we can match them precisely in separate `except` clauses.\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [Python vs. R: Exception handling]{style='font-weight: bold; font-size: 1.20em;'}\n\n::: {style='font-size: 1.10em; color: #282b2d;'}\n\n\n\nIn R, exception handling can be performed using `tryCatch()`, and the errors are *conditions* (not types). We  catch them with handlers (i.e., `error = function(e) ...` or `warning = ...`, `message = ...`, etc.).\n\nBelow is the same example using `logger` and `httr2`.\n\n```r\napi_health_check <- reactive({\n    tryCatch({\n        log_debug(\"Checking API health\")\n        start_time <- Sys.time()\n\n        resp <- request(ping_url) |>\n          req_timeout(2) |>\n          req_perform()\n\n        response_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n        status <- resp_status(resp)\n\n        if (status == 200) {\n          log_info(\"API OK - {sprintf('%.3f', response_time)}s\")\n          sprintf(\"✅ API is running - %.2fs\", response_time)\n        } else {\n          log_warn(\"API ping failed - status={status}\")\n          sprintf(\"⚠️ API ping failed: %s\", status)\n        }\n      },\n      error = function(e) {\n        msg <- conditionMessage(e)\n\n        if (grepl(\"timed out|timeout\", msg, ignore.case = TRUE)) {\n          log_warn(\"API timeout\")\n          return(\"⚠️ API timeout\")\n        }\n\n        if (grepl(\"Couldn't connect|Connection refused|Failed to connect\", msg, ignore.case = TRUE)) {\n          log_error(\"API connection error: {msg}\")\n          return(\"❌ Cannot connect to API\")\n        }\n\n        log_error(\"Unexpected error: {msg}\")\n        sprintf(\"❌ Unexpected error: %s\", msg)\n      }\n    )\n  })\n```\n\n\n  \n\n::: \n\n::::\n\nBack in the API, we see the health check was sent from the Shiny app:\n\n\n```{.default}\nINFO:     127.0.0.1:63543 - \"GET /ping HTTP/1.1\" 200 OK\n```\n\nThe output is rendered in the app with the `@render.text` decorator (after defining a function the matches in input `id`).\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n    @render.text\n    def api_status():\n        return api_health_check()\n```\n:::\n\n\nIn the **System Status** section, we see the results of the `ping`:\n\n![Click to enlarge](img/health_check.png){width=\"80%\" fig-align=\"center\"}\n\n### Predictions\n\nIn the UI, the predictions get their own `div()` with some CSS styling:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\nui.div(\n    ui.output_text(\"pred_out\"),\n    style=\"font-size: 24px; font-weight: bold; text-align: center; padding: 15px; color: #0066cc;\"\n)\n```\n:::\n\n\nIn the server, the `@reactive.calc` for the prediction is tied to the action button input with `@reactive.event()`:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"show/hide predictions\"}\n@reactive.calc\n    @reactive.event(input.predict)\n    def pred():\n        \"\"\"Prediction with logging\"\"\"\n        request_start = time.time()#<1>\n        data_to_send = vals()#<2>\n        \n        logging.info(f\"Starting prediction request - Session: {session_id} - request_data: {json.dumps(data_to_send)}\")\n        \n        try:\n            print(f\"\\n=== PREDICTION REQUEST ===\")\n            print(f\"Sending data to API: {data_to_send}\")\n            \n            r = requests.post(api_url, json=data_to_send, timeout=30)#<3>\n            response_time = time.time() - request_start #<4>\n            \n            current_times = request_times()#<5>\n            current_times.append(response_time)\n            if len(current_times) > 10:\n                current_times = current_times[-10:]\n            request_times.set(current_times)#<5>\n            \n            print(f\"HTTP Status Code: {r.status_code}\")#<5>\n            print(f\"Raw response text: {r.text}\")#<5>\n            \n            if r.status_code == 200:#<6>\n                result = r.json()\n                print(f\"✅ Success! Parsed response: {result}\")#<6>\n                \n                if '.pred' in result:#<7>\n                    prediction = result['.pred'][0]\n                elif 'predict' in result:\n                    prediction = result['predict'][0]\n                else:\n                    logging.warning(f\"Unexpected response format - Session: {session_id} - response: {result}\")\n                    return f\"Unexpected response format: {result}\"#<7>\n                \n                logging.info(f\"Prediction successful - Session: {session_id} - response_time: {response_time:.3f}s - prediction: {prediction}\")#<8>\n                \n                if response_time > 5:#<9>\n                    logging.warning(f\"Slow API response - Session: {session_id} - response_time: {response_time:.3f}s\")\n                \n                return prediction#<9>\n            else:#<10>\n                error_msg = f\"API Error {r.status_code}: {r.text}\"\n                logging.error(f\"Prediction request failed - Session: {session_id} - status: {r.status_code} - response: {r.text[:200]}\")\n                error_count.set(error_count() + 1)\n                return error_msg#<10>\n                \n        except requests.exceptions.ConnectionError as e:#<11>\n            error_msg = f\"Connection Error: {str(e)}\"\n            logging.error(f\"API connection refused during prediction - Session: {session_id} - error: {str(e)}\")\n            connection_errors.set(connection_errors() + 1)\n            error_count.set(error_count() + 1)\n            print(f\"❌ Connection Error: {e}\")\n            return error_msg#<11>\n        except requests.exceptions.Timeout:#<12>\n            error_msg = \"Request timed out - API may be overloaded\"\n            logging.warning(f\"API timeout during prediction - Session: {session_id}\")\n            timeout_errors.set(timeout_errors() + 1)\n            error_count.set(error_count() + 1)\n            return error_msg#<12>\n        except Exception as e:#<13>\n            error_msg = f\"Error: {str(e)}\"\n            logging.error(f\"Unknown prediction error - Session: {session_id} - error: {str(e)}\")\n            error_count.set(error_count() + 1)\n            print(f\"❌ Error: {e}\")\n            return error_msg#<13>\n```\n:::\n\n\n1.  Post start time\\\n2.  Prediction data\\\n3.  Make a request\\\n4.  Response time\\\n5.  Update performance metrics\\\n6.  Successful request\\\n7.  Handle different possible response formats\\\n8.  Log successful request\\\n9.  Performance warning\\\n10. Failed request\\\n11. Connection error\\\n12. Timeout during request\\\n13. Unknown error\n\nThe `pred()` function includes the same error handling pattern as the health check, but includes defensive HTTP handling for the `POST` request:\n\n```{mermaid}\n%%| fig-align: center\n%%| echo: false\n%%| fig-cap: 'Python APIs & Shiny Apps'\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\ngraph TD\n    Request[\"<strong>HTTP<br>Request</strong\"]\n    Success{\"Status<br>200?\"}\n    Format{\"Valid<br>Format?\"}\n    Parse(\"<strong>Parse<br>Prediction</strong>\")\n    ConnErr{\"Connection<br>Error?\"}\n    TimeErr{\"Timeout<br>Error?\"}\n    OtherErr[\"Other<br>Error\"]\n    \n    Request --> Success\n    Success -->|Yes| Format\n    Success -->|No| LogHTTPErr(\"<strong>Log HTTP<br>Error</strong><br>(return<br>message)\")\n    \n    Format -->|Yes| Parse\n    Format -->|No| LogFormatErr[\"Log<br>Format<br>Warning<br>(return<br>message)\"]\n    \n    Parse --> CheckPerf{Response > 5s?}\n    CheckPerf -->|Yes| LogSlow[\"Log<br>Performance<br>Warning\"]\n    CheckPerf -->|No| Return[\"Return<br>Prediction\"]\n    LogSlow --> Return\n    \n    Success -->|Error| ConnErr\n    ConnErr -->|Yes| LogConn(\"<strong>Log<br>Connection<br>Error</strong><br>(increment<br>counter)\")\n    ConnErr -->|No| TimeErr\n    TimeErr -->|Yes| LogTimeout(\"<strong>Log<br>Timeout</strong><br>(increment<br>counter)\")\n    TimeErr -->|No| OtherErr\n    OtherErr --> LogOther[\"Log<br>Unknown<br>Error\"]\n    \n    style Request fill:#2986cc,stroke:#2E7D32,color:#fff\n    style Parse fill:#4CAF50,stroke:#2E7D32,color:#fff\n    style LogHTTPErr fill:#f44336,stroke:#c62828,color:#fff\n    style LogConn fill:#f44336,stroke:#c62828,color:#fff\n    style LogTimeout fill:#FF9800,stroke:#E65100,color:#fff\n    \n```\n\n**In the console running the app**, we see the logs with the prediction request (including the data that matches the reactive values in the UI):\n\n\n```{.default}\n2026-01-05 14:01:01,661 - INFO - Starting prediction request - Session: py_48954 \n- request_data: [{\"bill_length_mm\": 45.0, \"species_Chinstrap\": 0, \n  \"species_Gentoo\": 0, \"sex_male\": 1}]\n=== PREDICTION REQUEST ===\nSending data to API: [{'bill_length_mm': 45.0, 'species_Chinstrap': 0, \n  'species_Gentoo': 0, 'sex_male': 1}]\n```\n\nThe successful request and prediction value is returned:\n\n\n```{.default}\nHTTP Status Code: 200\nRaw response text: {\"predict\":[4180.796549720755]}\n✅ Success! Parsed response: {'predict': [4180.796549720755]}\n```\n\n**In the console running the API**, we can see the `POST` request hit `/predict` endpoint:\n\n\n```{.default}\nINFO:     127.0.0.1:64436 - \"POST /predict HTTP/1.1\" 200 OK\n```\n\nBack in the server, the output is rendered using `@render.text` and some checks to ensure the returned prediction is in the proper format:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n@render.text\ndef pred_out():\n    result = pred()\n    if isinstance(result, (int, float)):\n        display_value = f\"{round(result, 1)} grams\"\n        logging.info(f\"Displaying prediction to user - Session: {session_id} - display_value: {display_value}\")\n        return display_value\n    else:\n        return str(result)\n```\n:::\n\n\n**In the console running the app**, the successful prediction is returned and we get a preview of the predicted value to be displayed:\n\n\n```{.default}\n2026-01-05 14:01:02,049 - INFO - Prediction successful - Session: py_48954 \n  - response_time: 0.388s - prediction: 4180.796549720755\n2026-01-05 14:01:02,049 - INFO - Displaying prediction to user - Session: py_48954 \n  - display_value: 4180.8 grams\n```\n\nWe see the predicted value in the UI in the **Predicted Mass** section:\n\n![Click to enlarge](img/predictions_app_ui.png){width=\"100%\" fig-align=\"center\"}\n\nAll of the logs are captured in the `logs/shiny_app.log` file (and displayed in the app):\n\n![Click to enlarge](img/recent_logs.png){width=\"100%\" fig-align=\"center\"}\n\n## Recap\n\nAs we've seen with this post (and the [previous post](https://mjfrigaard.github.io/posts/shiny-plumber/)), Python and R offer equivalent capabilities, but with different syntactic approaches for modeling, logging, and Shiny app development:\n\nWe can convert a trained `sklearn` model to Vetiver, and wrap it in a `REST` API (with validated model inputs and prototype data). We can also add health checks and documentation endpoints for monitoring and features, and model APIs also immplement request timeouts to prevent hanging.\n\nPython's `logging` module makes it easy to configure structured logs with consistent formats and multiple destinations (file + console). Displaying the recent logs in the UI allow us to monitor logs in real-time. The Shiny for Python app is set up to log all user interactions (via session tracking), and it can handle all HTTP error cases (with user-friendly error messages). The UI also displays the API health and POST request data before being sent to the API.\n\nThe tables below compare Python and R methods for creating models, APIs, and shiny apps. \n\n### Model as Service\n\n| Feature                   | Python (Vetiver + pins)                                             | R (Vetiver + pins)                                      |\n| ------------------------- | ------------------------------------------------------------------- | ------------------------------------------------------- |\n| **Import Packages**       | `from vetiver import VetiverModel`, `from pins import board_folder` | `library(vetiver)`, `library(pins)`                     |\n| **Create Board**          | `board_folder(\"./models\", allow_pickle_read=True)`                  | `board_folder(\"./models\")`                              |\n| **Wrap Model**            | `v = VetiverModel(model, model_name=\"name\", prototype_data=X)`      | `v <- vetiver_model(model, model_name=\"name\")`          |\n| **Prototype Data**        | Explicitly passed: `prototype_data=X`                               | Auto-extracted from workflows/recipes                   |\n| **Write Model**           | `vetiver_pin_write(board, v)`                                       | `vetiver_pin_write(board, v)`                           |\n| **Read Model**            | `v = board.pin_read(\"name\")`                                        | `v <- vetiver_pin_read(board, \"name\")`                  |\n\n### Logging\n\n| Feature                  | Python (`logging` module)                                           | R (`logger` package)                               |\n| ------------------------ | ------------------------------------------------------------------- | -------------------------------------------------- |\n| **Setup**                | `logging.basicConfig()`                                             | `log_threshold()`                                  |\n| **File Output**          | `logging.FileHandler('app.log')`                                    | `log_appender(appender_file('app.log'))`           |\n| **Console + File**       | `handlers=[FileHandler()`, `StreamHandler()]`                       | `log_appender(appender_tee('app.log'))`            |\n| **Log Levels**           | `logging.DEBUG`, `logging.INFO`, `logging.WARNING`, `logging.ERROR` | `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, `FATAL` |\n| **Basic Logging**        | `logging.info(\"Message\")`                                           | `log_info(\"Message\")`                              |\n| **String Interpolation** | `logging.info(f\"Value: {x}\")`                                       | `log_info(\"Value: {x}\")` (glue syntax)             |\n\n### Shiny\n\n| Feature        | Python Shiny        | R Shiny                |\n|----------------|---------------------|------------------------|\n| **Reactivity** | `@reactive.calc`    | `reactive()`           |\n| **Rendering**  | `@render.text`      | `renderText()`         |\n| **Events**     | `@reactive.event()` | `bindEvent()`          |\n| **UI**         | `ui.input_slider()` | `sliderInput()`        |\n| **Layout**     | `ui.page_fluid()`   | `page_fluid()` (bslib) |\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}