{
  "hash": "038210f540f49c63c5c91932d0e1804e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Shiny (for Python) & APIs\" \nsubtitle: \"Using Vetiver, FastAPI and Shiny\"\nauthor: \"Martin Frigaard\"\ndate: \"2025-07-21\"\ncategories: [APIs, Python, Shiny]\n# image: \"img/image.png\"\ndraft: true\ntoc: true\ntoc-depth: 5\ntoc-title: 'Contents'\ntoc-location: \"left\"\n# code-block-border-left: true\ncode-block-bg: \"#f8f8f8\"\ncode-block-border-left: \"#e8e8e8\"\ncode-fold: show\ncode-summary: 'show/hide'\ncallout-icon: false\nengine: knitr\nfreeze: true\ncallout-appearance: simple\n\nexecute:\n  echo: false\n  message: false\n  warning: false\n  eval: true\n---\n\n\n\nIn this post, we'll explore a production-ready architecture for deploying `scikit-learn` models as RESTful APIs and building interactive interfaces to consume them. \n\nWe'll examine the coding patterns, architecture decisions, and compare this Python implementation to equivalent R workflows using `plumber`, `logger`, and `shiny`.\n\n## Architecture\n\n```{=html}\n\n<style>\n\n.codeStyle span:not(.nodeLabel) {\n  font-family: monospace;\n  font-size: 1.5em;\n  font-weight: bold;\n  color: #9753b8 !important;\n  background-color: #f6f6f6;\n  padding: 0.2em;\n}\n\n</style>\n```\n\n```{mermaid}\n%%| fig-align: center\n%%| echo: false\n%%| fig-cap: 'Python APIs & Shiny Apps'\n%%{init: {'theme': 'neutral', 'look': 'handDrawn', 'themeVariables': { 'fontFamily': 'monospace', \"fontSize\":\"18px\"}}}%%\n\ngraph TB\n    subgraph Storage[\"<strong>Model Storage</strong>\"]\n        Board(\"<code>pins</code> Board:<br/>File System Storage\")\n        Model(\"Trained sklearn Model:<br/><code>penguin_model</code>\")\n    end\n    \n    style Board fill:#fff,color:#000,stroke:#FF9800,stroke-width:3px\n    style Model fill:#fff,color:#000,stroke:#FF9800,stroke-width:3px\n\n    subgraph API[\"<strong>API Layer</strong>\"]\n        Vetiver[\"<code>VetiverModel</code><br/>Model Wrapper\"]\n        FastAPI[\"<code>FastAPI</code> Server<br/>Port 8080\"]\n        Endpoints[\"<code>/predict</code><br/><code>/ping</code><br/><code>/metadata</code>\"]\n    end\n    \n    style Vetiver fill:#fff,color:#000,stroke:#4CAF50,stroke-width:3px\n    style FastAPI fill:#fff,color:#000,stroke:#4CAF50,stroke-width:3px\n    style Endpoints fill:#fff,color:#000,stroke:#4CAF50,stroke-width:3px\n    \n    subgraph Client[\"<strong>Client Layer</strong>\"]\n        UI[Shiny UI<br/>Input Controls]\n        Server[Shiny Server<br/>Request Logic]\n        Logging[Logging System<br/>File + Console]\n    end\n    \n    style UI fill:#fff,color:#000,stroke:#2196F3,stroke-width:3px\n    style Server fill:#fff,color:#000,stroke:#2196F3,stroke-width:3px\n    style Logging fill:#fff,color:#000,stroke:#2196F3,stroke-width:3px\n    \n    subgraph User[\"<strong>End Users</strong>\"]\n        Browser[Web Browser]\n    end\n    \n    style User color:#000\n    style Browser fill:#fff,color:#000,stroke:#fff,stroke-width:3px\n    \n    Board --> Model\n    Model --> Vetiver\n    Vetiver --> FastAPI\n    FastAPI --> Endpoints\n    \n    Browser --> UI\n    UI --> Server\n    Server -->|HTTP POST| Endpoints\n    Endpoints -->|JSON Response| Server\n    Server --> Logging\n    Logging --> UI\n    \n    style API fill:#4CAF50,stroke:#2E7D32,color:#fff\n    style Client fill:#2196F3,stroke:#1565C0,color:#fff\n    style Storage fill:#FF9800,stroke:#E65100,color:#fff\n    \n```\n\n## API\n\n\n```{.default}\n_labs/lab4/Python/api/\n                    ├── api.Rproj\n                    ├── mod-api.py\n                    ├── README.md\n                    └── requirements.txt\n```\n\n### Model\n\nThe first critical pattern is defensive model loading with feature validation. Always validate that your model has the expected feature schema. This prevents runtime errors when the model structure doesn't match your expectations.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# connect to model board\nmodel_board = pins.board_folder(\"../../../lab2/model-vetiver/models/\")\n\n# read pinned model\nsklearn_model = model_board.pin_read(\"penguin_model\")\n\n# validate expected features\nif hasattr(sklearn_model, 'feature_names_in_'):\n    feature_names = sklearn_model.feature_names_in_\n    print(f\"Model expects features: {list(feature_names)}\")\n```\n:::\n\n\n\n### Prototype Data \n\nOne of Vetiver's most important features is **prototype data**, which is like a contract between the client and the API --it defines the expected input schema:\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\ndef get_prototype_value(column_name):\n    \"\"\"Get appropriate default value for each column type\"\"\"\n    if 'bill_length' in column_name:\n        return 45.0  # Realistic penguin bill length\n    elif 'species_Gentoo' in column_name:\n        return 1     # Default to Gentoo species\n    elif 'sex_male' in column_name:\n        return 1     # Default to male\n    else:\n        return 0     # Default for other dummy variables\n\n# create prototype data directly\nprototype_data = pd.DataFrame({\n    name: [get_prototype_value(name)] for name in feature_names\n})\n```\n:::\n\n\nThe prototype serves as an executable contract. Vetiver uses it to:\n- Validate incoming requests\n- Generate API documentation\n- Provide clear error messages when data doesn't match expectations\n\n### Wrapping and Serving\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"false\"}\n# wrap as VetiverModel\nv = vetiver.VetiverModel(\n    model=sklearn_model, \n    model_name=\"penguin_model\",\n    prototype_data=prototype_data\n)\n\n# create VetiverAPI and extract FastAPI app\nvetiver_api = vetiver.VetiverAPI(v, check_prototype=True)\napp = vetiver_api.app\n```\n:::\n\n\n**Architecture Decision**: Vetiver creates a FastAPI application under the hood, giving you:    \n- Automatic endpoint generation (`/predict`, `/ping`, `/metadata`)    \n- Interactive API documentation at `/docs`    \n- Request validation based on prototype data    \n- JSON serialization of predictions   \n    \n\n## App\n\n\n```{.default}\n_labs/lab4/Python/app/\n                    ├── app.py\n                    ├── app.Rproj\n                    ├── logs\n                    │   └── shiny_app.log\n                    ├── README.md\n                    └── requirements.txt\n```\n\n### Health check \n\n### Predictions \n\n### Logging",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}